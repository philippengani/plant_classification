I0403 02:30:27.977615 32196 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:27.978037 32196 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:27.978065 32196 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.893573 32196 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.895197 32196 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.896723 32196 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.005089 32196 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9756
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3252
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.034312 32196 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.043473 32196 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.043555 32196 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.044422 32196 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.046617 32196 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.047629 32196 net.cpp:91] Creating Layer data
I0403 02:30:37.047705 32196 net.cpp:399] data -> data
I0403 02:30:37.047842 32196 net.cpp:399] data -> label
I0403 02:30:37.047919 32196 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto
I0403 02:30:37.096025 32203 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-60-40/train_db
I0403 02:30:37.117033 32196 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.255220 32196 net.cpp:141] Setting up data
I0403 02:30:37.255321 32196 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.255347 32196 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.255365 32196 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.255403 32196 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.255453 32196 net.cpp:91] Creating Layer conv1
I0403 02:30:37.255480 32196 net.cpp:425] conv1 <- data
I0403 02:30:37.255517 32196 net.cpp:399] conv1 -> conv1
I0403 02:30:37.258755 32196 net.cpp:141] Setting up conv1
I0403 02:30:37.258795 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.258816 32196 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.258862 32196 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.258929 32196 net.cpp:91] Creating Layer relu1
I0403 02:30:37.258955 32196 net.cpp:425] relu1 <- conv1
I0403 02:30:37.258976 32196 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.259006 32196 net.cpp:141] Setting up relu1
I0403 02:30:37.259032 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.259049 32196 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.259068 32196 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.259093 32196 net.cpp:91] Creating Layer norm1
I0403 02:30:37.259153 32196 net.cpp:425] norm1 <- conv1
I0403 02:30:37.259179 32196 net.cpp:399] norm1 -> norm1
I0403 02:30:37.264772 32196 net.cpp:141] Setting up norm1
I0403 02:30:37.264804 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.264823 32196 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.264842 32196 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.264869 32196 net.cpp:91] Creating Layer pool1
I0403 02:30:37.264889 32196 net.cpp:425] pool1 <- norm1
I0403 02:30:37.264912 32196 net.cpp:399] pool1 -> pool1
I0403 02:30:37.264986 32196 net.cpp:141] Setting up pool1
I0403 02:30:37.265017 32196 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.265034 32196 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.265050 32196 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.265079 32196 net.cpp:91] Creating Layer conv2
I0403 02:30:37.265100 32196 net.cpp:425] conv2 <- pool1
I0403 02:30:37.265141 32196 net.cpp:399] conv2 -> conv2
I0403 02:30:37.266922 32206 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.281805 32196 net.cpp:141] Setting up conv2
I0403 02:30:37.281842 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.281862 32196 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.281889 32196 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.281915 32196 net.cpp:91] Creating Layer relu2
I0403 02:30:37.281935 32196 net.cpp:425] relu2 <- conv2
I0403 02:30:37.281957 32196 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.281981 32196 net.cpp:141] Setting up relu2
I0403 02:30:37.282003 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.282021 32196 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.282039 32196 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.282061 32196 net.cpp:91] Creating Layer norm2
I0403 02:30:37.282081 32196 net.cpp:425] norm2 <- conv2
I0403 02:30:37.282104 32196 net.cpp:399] norm2 -> norm2
I0403 02:30:37.282166 32196 net.cpp:141] Setting up norm2
I0403 02:30:37.282194 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.282213 32196 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.282232 32196 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.282255 32196 net.cpp:91] Creating Layer pool2
I0403 02:30:37.282275 32196 net.cpp:425] pool2 <- norm2
I0403 02:30:37.282297 32196 net.cpp:399] pool2 -> pool2
I0403 02:30:37.282351 32196 net.cpp:141] Setting up pool2
I0403 02:30:37.282379 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.282397 32196 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.282415 32196 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.282441 32196 net.cpp:91] Creating Layer conv3
I0403 02:30:37.282461 32196 net.cpp:425] conv3 <- pool2
I0403 02:30:37.282486 32196 net.cpp:399] conv3 -> conv3
I0403 02:30:37.324208 32196 net.cpp:141] Setting up conv3
I0403 02:30:37.324250 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.324271 32196 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.324300 32196 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.324324 32196 net.cpp:91] Creating Layer relu3
I0403 02:30:37.324347 32196 net.cpp:425] relu3 <- conv3
I0403 02:30:37.324368 32196 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.324393 32196 net.cpp:141] Setting up relu3
I0403 02:30:37.324414 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.324432 32196 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.324450 32196 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.324478 32196 net.cpp:91] Creating Layer conv4
I0403 02:30:37.324501 32196 net.cpp:425] conv4 <- conv3
I0403 02:30:37.324523 32196 net.cpp:399] conv4 -> conv4
I0403 02:30:37.355906 32196 net.cpp:141] Setting up conv4
I0403 02:30:37.355945 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.355965 32196 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.355986 32196 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.356031 32196 net.cpp:91] Creating Layer relu4
I0403 02:30:37.356052 32196 net.cpp:425] relu4 <- conv4
I0403 02:30:37.356076 32196 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.356101 32196 net.cpp:141] Setting up relu4
I0403 02:30:37.356122 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.356144 32196 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.356164 32196 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.356192 32196 net.cpp:91] Creating Layer conv5
I0403 02:30:37.356214 32196 net.cpp:425] conv5 <- conv4
I0403 02:30:37.356237 32196 net.cpp:399] conv5 -> conv5
I0403 02:30:37.377279 32196 net.cpp:141] Setting up conv5
I0403 02:30:37.377320 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.377339 32196 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.377367 32196 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.377395 32196 net.cpp:91] Creating Layer relu5
I0403 02:30:37.377418 32196 net.cpp:425] relu5 <- conv5
I0403 02:30:37.377440 32196 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.377465 32196 net.cpp:141] Setting up relu5
I0403 02:30:37.377485 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.377502 32196 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.377519 32196 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.377542 32196 net.cpp:91] Creating Layer pool5
I0403 02:30:37.377560 32196 net.cpp:425] pool5 <- conv5
I0403 02:30:37.377583 32196 net.cpp:399] pool5 -> pool5
I0403 02:30:37.377645 32196 net.cpp:141] Setting up pool5
I0403 02:30:37.377674 32196 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.377691 32196 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.377709 32196 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.377742 32196 net.cpp:91] Creating Layer fc6
I0403 02:30:37.377763 32196 net.cpp:425] fc6 <- pool5
I0403 02:30:37.377790 32196 net.cpp:399] fc6 -> fc6
I0403 02:30:38.942307 32196 net.cpp:141] Setting up fc6
I0403 02:30:38.942409 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.942427 32196 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.942451 32196 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.942476 32196 net.cpp:91] Creating Layer relu6
I0403 02:30:38.942492 32196 net.cpp:425] relu6 <- fc6
I0403 02:30:38.942512 32196 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.942535 32196 net.cpp:141] Setting up relu6
I0403 02:30:38.942553 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.942567 32196 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.942581 32196 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.942606 32196 net.cpp:91] Creating Layer drop6
I0403 02:30:38.942623 32196 net.cpp:425] drop6 <- fc6
I0403 02:30:38.942643 32196 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.942692 32196 net.cpp:141] Setting up drop6
I0403 02:30:38.942714 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.942729 32196 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.942744 32196 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.942765 32196 net.cpp:91] Creating Layer fc7
I0403 02:30:38.942781 32196 net.cpp:425] fc7 <- fc6
I0403 02:30:38.942800 32196 net.cpp:399] fc7 -> fc7
I0403 02:30:39.553808 32196 net.cpp:141] Setting up fc7
I0403 02:30:39.553905 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.553922 32196 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.553946 32196 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.553978 32196 net.cpp:91] Creating Layer relu7
I0403 02:30:39.553997 32196 net.cpp:425] relu7 <- fc7
I0403 02:30:39.554018 32196 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.554042 32196 net.cpp:141] Setting up relu7
I0403 02:30:39.554061 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.554076 32196 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.554091 32196 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.554155 32196 net.cpp:91] Creating Layer drop7
I0403 02:30:39.554175 32196 net.cpp:425] drop7 <- fc7
I0403 02:30:39.554193 32196 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.554234 32196 net.cpp:141] Setting up drop7
I0403 02:30:39.554260 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.554276 32196 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.554291 32196 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.554313 32196 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.554329 32196 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.554352 32196 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.560807 32196 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.560855 32196 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.560878 32196 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.560911 32196 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.560967 32196 net.cpp:91] Creating Layer loss
I0403 02:30:39.560988 32196 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.561022 32196 net.cpp:425] loss <- label
I0403 02:30:39.561069 32196 net.cpp:399] loss -> loss
I0403 02:30:39.561107 32196 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.561244 32196 net.cpp:141] Setting up loss
I0403 02:30:39.561288 32196 net.cpp:148] Top shape: (1)
I0403 02:30:39.561319 32196 net.cpp:151]     with loss weight 1
I0403 02:30:39.561395 32196 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.561430 32196 net.cpp:217] loss needs backward computation.
I0403 02:30:39.561472 32196 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.561488 32196 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.561517 32196 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.561537 32196 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.561568 32196 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.561607 32196 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.561641 32196 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.561672 32196 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.561687 32196 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.561718 32196 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.561756 32196 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.561777 32196 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.561808 32196 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.561846 32196 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.561887 32196 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.561908 32196 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.561947 32196 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.561983 32196 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.562012 32196 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.562047 32196 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.562082 32196 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.562115 32196 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.562167 32196 net.cpp:219] data does not need backward computation.
I0403 02:30:39.562206 32196 net.cpp:261] This network produces output loss
I0403 02:30:39.562232 32196 net.cpp:274] Network initialization done.
I0403 02:30:39.563607 32196 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.563765 32196 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.564831 32196 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.565402 32196 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.565714 32196 net.cpp:91] Creating Layer data
I0403 02:30:39.565798 32196 net.cpp:399] data -> data
I0403 02:30:39.565862 32196 net.cpp:399] data -> label
I0403 02:30:39.565960 32196 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto
I0403 02:30:39.586228 32209 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-60-40/test_db
I0403 02:30:39.594321 32196 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.736269 32196 net.cpp:141] Setting up data
I0403 02:30:39.825271 32196 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.825316 32196 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.825336 32196 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.825356 32196 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.825384 32196 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.825404 32196 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.825428 32196 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.825456 32196 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.825551 32196 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.825577 32196 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.825600 32196 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.825650 32196 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.825667 32196 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.825698 32196 net.cpp:91] Creating Layer conv1
I0403 02:30:39.825717 32196 net.cpp:425] conv1 <- data
I0403 02:30:39.825739 32196 net.cpp:399] conv1 -> conv1
I0403 02:30:39.827406 32196 net.cpp:141] Setting up conv1
I0403 02:30:39.827436 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.827452 32196 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.827478 32196 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.827502 32196 net.cpp:91] Creating Layer relu1
I0403 02:30:39.827522 32196 net.cpp:425] relu1 <- conv1
I0403 02:30:39.827541 32196 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.827563 32196 net.cpp:141] Setting up relu1
I0403 02:30:39.827586 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.827605 32196 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.827621 32196 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.827646 32196 net.cpp:91] Creating Layer norm1
I0403 02:30:39.827664 32196 net.cpp:425] norm1 <- conv1
I0403 02:30:39.827684 32196 net.cpp:399] norm1 -> norm1
I0403 02:30:39.827740 32196 net.cpp:141] Setting up norm1
I0403 02:30:39.827767 32196 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.827785 32196 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.827802 32196 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.827824 32196 net.cpp:91] Creating Layer pool1
I0403 02:30:39.827841 32196 net.cpp:425] pool1 <- norm1
I0403 02:30:39.827860 32196 net.cpp:399] pool1 -> pool1
I0403 02:30:39.827913 32196 net.cpp:141] Setting up pool1
I0403 02:30:39.827939 32196 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.827955 32196 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.828009 32196 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.828037 32196 net.cpp:91] Creating Layer conv2
I0403 02:30:39.828057 32196 net.cpp:425] conv2 <- pool1
I0403 02:30:39.828083 32196 net.cpp:399] conv2 -> conv2
I0403 02:30:39.842118 32196 net.cpp:141] Setting up conv2
I0403 02:30:39.842155 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.842175 32196 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.842197 32196 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.842219 32196 net.cpp:91] Creating Layer relu2
I0403 02:30:39.842236 32196 net.cpp:425] relu2 <- conv2
I0403 02:30:39.842255 32196 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.842277 32196 net.cpp:141] Setting up relu2
I0403 02:30:39.842295 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.842313 32196 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.842327 32196 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.842349 32196 net.cpp:91] Creating Layer norm2
I0403 02:30:39.842365 32196 net.cpp:425] norm2 <- conv2
I0403 02:30:39.842384 32196 net.cpp:399] norm2 -> norm2
I0403 02:30:39.842438 32196 net.cpp:141] Setting up norm2
I0403 02:30:39.842463 32196 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.842480 32196 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.842496 32196 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.842515 32196 net.cpp:91] Creating Layer pool2
I0403 02:30:39.842532 32196 net.cpp:425] pool2 <- norm2
I0403 02:30:39.842550 32196 net.cpp:399] pool2 -> pool2
I0403 02:30:39.842599 32196 net.cpp:141] Setting up pool2
I0403 02:30:39.842623 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.842639 32196 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.842654 32196 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.842679 32196 net.cpp:91] Creating Layer conv3
I0403 02:30:39.842696 32196 net.cpp:425] conv3 <- pool2
I0403 02:30:39.842717 32196 net.cpp:399] conv3 -> conv3
I0403 02:30:39.879349 32196 net.cpp:141] Setting up conv3
I0403 02:30:39.879418 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.879451 32196 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.879480 32196 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.879513 32196 net.cpp:91] Creating Layer relu3
I0403 02:30:39.879534 32196 net.cpp:425] relu3 <- conv3
I0403 02:30:39.879559 32196 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.879581 32196 net.cpp:141] Setting up relu3
I0403 02:30:39.879601 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.879616 32196 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.879633 32196 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.879658 32196 net.cpp:91] Creating Layer conv4
I0403 02:30:39.879676 32196 net.cpp:425] conv4 <- conv3
I0403 02:30:39.879698 32196 net.cpp:399] conv4 -> conv4
I0403 02:30:39.907817 32196 net.cpp:141] Setting up conv4
I0403 02:30:39.915041 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.915108 32196 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.915196 32196 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.915277 32196 net.cpp:91] Creating Layer relu4
I0403 02:30:39.915307 32196 net.cpp:425] relu4 <- conv4
I0403 02:30:39.915326 32196 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.915346 32196 net.cpp:141] Setting up relu4
I0403 02:30:39.915366 32196 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.915381 32196 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.915396 32196 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.915419 32196 net.cpp:91] Creating Layer conv5
I0403 02:30:39.915436 32196 net.cpp:425] conv5 <- conv4
I0403 02:30:39.915457 32196 net.cpp:399] conv5 -> conv5
I0403 02:30:39.934478 32196 net.cpp:141] Setting up conv5
I0403 02:30:39.934525 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.934542 32196 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.934602 32196 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.934625 32196 net.cpp:91] Creating Layer relu5
I0403 02:30:39.934643 32196 net.cpp:425] relu5 <- conv5
I0403 02:30:39.934661 32196 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.934681 32196 net.cpp:141] Setting up relu5
I0403 02:30:39.934700 32196 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.934715 32196 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.934728 32196 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.934751 32196 net.cpp:91] Creating Layer pool5
I0403 02:30:39.934768 32196 net.cpp:425] pool5 <- conv5
I0403 02:30:39.934788 32196 net.cpp:399] pool5 -> pool5
I0403 02:30:39.934846 32196 net.cpp:141] Setting up pool5
I0403 02:30:39.934870 32196 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.934885 32196 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.934903 32196 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.934937 32196 net.cpp:91] Creating Layer fc6
I0403 02:30:39.934962 32196 net.cpp:425] fc6 <- pool5
I0403 02:30:39.934994 32196 net.cpp:399] fc6 -> fc6
I0403 02:30:41.363801 32196 net.cpp:141] Setting up fc6
I0403 02:30:41.363899 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.363915 32196 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.363940 32196 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.363966 32196 net.cpp:91] Creating Layer relu6
I0403 02:30:41.363986 32196 net.cpp:425] relu6 <- fc6
I0403 02:30:41.364006 32196 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.364027 32196 net.cpp:141] Setting up relu6
I0403 02:30:41.364043 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.364058 32196 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.364071 32196 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.364090 32196 net.cpp:91] Creating Layer drop6
I0403 02:30:41.364106 32196 net.cpp:425] drop6 <- fc6
I0403 02:30:41.364132 32196 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.364174 32196 net.cpp:141] Setting up drop6
I0403 02:30:41.364197 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.364210 32196 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.364224 32196 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.364244 32196 net.cpp:91] Creating Layer fc7
I0403 02:30:41.364259 32196 net.cpp:425] fc7 <- fc6
I0403 02:30:41.364277 32196 net.cpp:399] fc7 -> fc7
I0403 02:30:41.965502 32196 net.cpp:141] Setting up fc7
I0403 02:30:41.965600 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.965616 32196 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.965639 32196 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.965667 32196 net.cpp:91] Creating Layer relu7
I0403 02:30:41.965687 32196 net.cpp:425] relu7 <- fc7
I0403 02:30:41.965706 32196 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.965728 32196 net.cpp:141] Setting up relu7
I0403 02:30:41.965746 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.965760 32196 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.965773 32196 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.965795 32196 net.cpp:91] Creating Layer drop7
I0403 02:30:41.965811 32196 net.cpp:425] drop7 <- fc7
I0403 02:30:41.965828 32196 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.965867 32196 net.cpp:141] Setting up drop7
I0403 02:30:41.965893 32196 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.965909 32196 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.965922 32196 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.965944 32196 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.965958 32196 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.965981 32196 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.972098 32196 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.972132 32196 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.972160 32196 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.972211 32196 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.972234 32196 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.972250 32196 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.972270 32196 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.972292 32196 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.972343 32196 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.972367 32196 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.972383 32196 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.972396 32196 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.972411 32196 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.972440 32196 net.cpp:91] Creating Layer loss
I0403 02:30:41.972455 32196 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.972470 32196 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.972488 32196 net.cpp:399] loss -> loss
I0403 02:30:41.972512 32196 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.972604 32196 net.cpp:141] Setting up loss
I0403 02:30:41.972628 32196 net.cpp:148] Top shape: (1)
I0403 02:30:41.972643 32196 net.cpp:151]     with loss weight 1
I0403 02:30:41.972666 32196 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.972681 32196 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.972703 32196 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.972719 32196 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.972736 32196 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.972754 32196 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.972810 32196 net.cpp:141] Setting up accuracy
I0403 02:30:41.972831 32196 net.cpp:148] Top shape: (1)
I0403 02:30:41.972844 32196 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.972858 32196 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.972873 32196 net.cpp:217] loss needs backward computation.
I0403 02:30:41.972888 32196 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.972903 32196 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.972916 32196 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.972930 32196 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.972944 32196 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.972959 32196 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.972972 32196 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.972986 32196 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.973001 32196 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.973014 32196 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.973028 32196 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.973042 32196 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.973055 32196 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.973068 32196 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.973083 32196 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.973096 32196 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.973110 32196 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.973124 32196 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.973150 32196 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.973165 32196 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.973179 32196 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.973194 32196 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.973208 32196 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.973237 32196 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.973253 32196 net.cpp:219] data does not need backward computation.
I0403 02:30:41.973266 32196 net.cpp:261] This network produces output accuracy
I0403 02:30:41.973280 32196 net.cpp:261] This network produces output loss
I0403 02:30:41.973311 32196 net.cpp:274] Network initialization done.
I0403 02:30:41.973415 32196 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.973878 32196 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.413033 32196 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.413130 32196 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.413166 32196 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.413221 32196 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.798732 32196 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.834780 32196 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.941015 32196 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.941108 32196 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.941141 32196 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.941198 32196 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.315129 32196 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.349927 32196 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.376113 32196 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.582497 32196 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.263974 32196 parallel.cpp:425] Starting Optimization
I0403 02:30:48.264189 32196 solver.cpp:279] Solving 
I0403 02:30:48.264212 32196 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.264353 32196 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:38.027158 32196 solver.cpp:404]     Test net output #0: accuracy = 0.0279724
I0403 02:31:38.033390 32196 solver.cpp:404]     Test net output #1: loss = 3.82245 (* 1 = 3.82245 loss)
I0403 02:31:38.617759 32196 solver.cpp:228] Iteration 0, loss = 4.19531
I0403 02:31:38.624075 32196 solver.cpp:244]     Train net output #0: loss = 4.19531 (* 1 = 4.19531 loss)
I0403 02:31:38.807711 32196 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:50.378689 32196 solver.cpp:228] Iteration 16, loss = 1.09179
I0403 02:31:50.384250 32196 solver.cpp:244]     Train net output #0: loss = 1.09179 (* 1 = 1.09179 loss)
I0403 02:31:50.556176 32196 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 02:32:01.950824 32196 solver.cpp:228] Iteration 32, loss = 0.55364
I0403 02:32:01.956903 32196 solver.cpp:244]     Train net output #0: loss = 0.55364 (* 1 = 0.55364 loss)
I0403 02:32:02.141170 32196 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 02:32:13.551290 32196 solver.cpp:228] Iteration 48, loss = 0.633912
I0403 02:32:13.557576 32196 solver.cpp:244]     Train net output #0: loss = 0.633912 (* 1 = 0.633912 loss)
I0403 02:32:13.735937 32196 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 02:32:25.133170 32196 solver.cpp:228] Iteration 64, loss = 0.475325
I0403 02:32:25.139536 32196 solver.cpp:244]     Train net output #0: loss = 0.475325 (* 1 = 0.475325 loss)
I0403 02:32:25.321161 32196 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 02:32:36.744987 32196 solver.cpp:228] Iteration 80, loss = 0.427891
I0403 02:32:36.753934 32196 solver.cpp:244]     Train net output #0: loss = 0.427891 (* 1 = 0.427891 loss)
I0403 02:32:36.923698 32196 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:32:48.267071 32196 solver.cpp:228] Iteration 96, loss = 0.259467
I0403 02:32:48.271885 32196 solver.cpp:244]     Train net output #0: loss = 0.259467 (* 1 = 0.259467 loss)
I0403 02:32:48.457077 32196 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 02:32:59.818840 32196 solver.cpp:228] Iteration 112, loss = 0.226114
I0403 02:32:59.827599 32196 solver.cpp:244]     Train net output #0: loss = 0.226114 (* 1 = 0.226114 loss)
I0403 02:32:59.999491 32196 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 02:33:11.390959 32196 solver.cpp:228] Iteration 128, loss = 0.348681
I0403 02:33:11.396335 32196 solver.cpp:244]     Train net output #0: loss = 0.348681 (* 1 = 0.348681 loss)
I0403 02:33:11.572965 32196 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 02:33:23.042953 32196 solver.cpp:228] Iteration 144, loss = 0.215415
I0403 02:33:23.049089 32196 solver.cpp:244]     Train net output #0: loss = 0.215415 (* 1 = 0.215415 loss)
I0403 02:33:23.249178 32196 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 02:33:34.747972 32196 solver.cpp:228] Iteration 160, loss = 0.34311
I0403 02:33:34.753998 32196 solver.cpp:244]     Train net output #0: loss = 0.34311 (* 1 = 0.34311 loss)
I0403 02:33:34.949765 32196 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:33:46.588151 32196 solver.cpp:228] Iteration 176, loss = 0.341089
I0403 02:33:46.594852 32196 solver.cpp:244]     Train net output #0: loss = 0.341089 (* 1 = 0.341089 loss)
I0403 02:33:46.764693 32196 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 02:33:58.123277 32196 solver.cpp:228] Iteration 192, loss = 0.0540711
I0403 02:33:58.128964 32196 solver.cpp:244]     Train net output #0: loss = 0.0540712 (* 1 = 0.0540712 loss)
I0403 02:33:58.394249 32196 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 02:34:09.878798 32196 solver.cpp:228] Iteration 208, loss = 0.215656
I0403 02:34:09.885311 32196 solver.cpp:244]     Train net output #0: loss = 0.215656 (* 1 = 0.215656 loss)
I0403 02:34:10.055027 32196 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:21.400498 32196 solver.cpp:228] Iteration 224, loss = 0.183532
I0403 02:34:21.407651 32196 solver.cpp:244]     Train net output #0: loss = 0.183532 (* 1 = 0.183532 loss)
I0403 02:34:21.604557 32196 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 02:34:33.129418 32196 solver.cpp:228] Iteration 240, loss = 0.189124
I0403 02:34:33.135673 32196 solver.cpp:244]     Train net output #0: loss = 0.189124 (* 1 = 0.189124 loss)
I0403 02:34:33.300334 32196 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:34:44.860376 32196 solver.cpp:228] Iteration 256, loss = 0.146714
I0403 02:34:44.866673 32196 solver.cpp:244]     Train net output #0: loss = 0.146714 (* 1 = 0.146714 loss)
I0403 02:34:45.137652 32196 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 02:34:56.682123 32196 solver.cpp:228] Iteration 272, loss = 0.110646
I0403 02:34:56.687170 32196 solver.cpp:244]     Train net output #0: loss = 0.110646 (* 1 = 0.110646 loss)
I0403 02:34:56.870806 32196 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 02:35:08.449676 32196 solver.cpp:228] Iteration 288, loss = 0.131725
I0403 02:35:08.456338 32196 solver.cpp:244]     Train net output #0: loss = 0.131725 (* 1 = 0.131725 loss)
I0403 02:35:08.633990 32196 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 02:35:20.158747 32196 solver.cpp:228] Iteration 304, loss = 0.135204
I0403 02:35:20.164294 32196 solver.cpp:244]     Train net output #0: loss = 0.135204 (* 1 = 0.135204 loss)
I0403 02:35:20.351419 32196 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 02:35:31.738306 32196 solver.cpp:228] Iteration 320, loss = 0.114682
I0403 02:35:31.743494 32196 solver.cpp:244]     Train net output #0: loss = 0.114682 (* 1 = 0.114682 loss)
I0403 02:35:31.936763 32196 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:35:34.917325 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_325.caffemodel
I0403 02:35:37.800227 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_325.solverstate
I0403 02:35:39.702030 32196 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 02:36:28.633635 32196 solver.cpp:404]     Test net output #0: accuracy = 0.964194
I0403 02:36:28.644345 32196 solver.cpp:404]     Test net output #1: loss = 0.111699 (* 1 = 0.111699 loss)
I0403 02:36:37.327142 32196 solver.cpp:228] Iteration 336, loss = 0.197156
I0403 02:36:37.333689 32196 solver.cpp:244]     Train net output #0: loss = 0.197156 (* 1 = 0.197156 loss)
I0403 02:36:37.507446 32196 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:36:49.094890 32196 solver.cpp:228] Iteration 352, loss = 0.127679
I0403 02:36:49.101193 32196 solver.cpp:244]     Train net output #0: loss = 0.127679 (* 1 = 0.127679 loss)
I0403 02:36:49.295725 32196 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 02:37:00.837311 32196 solver.cpp:228] Iteration 368, loss = 0.212091
I0403 02:37:00.843176 32196 solver.cpp:244]     Train net output #0: loss = 0.212092 (* 1 = 0.212092 loss)
I0403 02:37:01.023054 32196 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 02:37:12.496191 32196 solver.cpp:228] Iteration 384, loss = 0.0974958
I0403 02:37:12.501394 32196 solver.cpp:244]     Train net output #0: loss = 0.0974958 (* 1 = 0.0974958 loss)
I0403 02:37:12.698436 32196 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 02:37:24.472867 32196 solver.cpp:228] Iteration 400, loss = 0.176387
I0403 02:37:24.477701 32196 solver.cpp:244]     Train net output #0: loss = 0.176387 (* 1 = 0.176387 loss)
I0403 02:37:24.657788 32196 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:37:36.494375 32196 solver.cpp:228] Iteration 416, loss = 0.0260358
I0403 02:37:36.500654 32196 solver.cpp:244]     Train net output #0: loss = 0.0260359 (* 1 = 0.0260359 loss)
I0403 02:37:36.599105 32196 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:37:48.178977 32196 solver.cpp:228] Iteration 432, loss = 0.0531816
I0403 02:37:48.185351 32196 solver.cpp:244]     Train net output #0: loss = 0.0531816 (* 1 = 0.0531816 loss)
I0403 02:37:48.397289 32196 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 02:37:59.954821 32196 solver.cpp:228] Iteration 448, loss = 0.0318704
I0403 02:37:59.954924 32196 solver.cpp:244]     Train net output #0: loss = 0.0318705 (* 1 = 0.0318705 loss)
I0403 02:38:00.145500 32196 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 02:38:11.706480 32196 solver.cpp:228] Iteration 464, loss = 0.0368806
I0403 02:38:11.712697 32196 solver.cpp:244]     Train net output #0: loss = 0.0368807 (* 1 = 0.0368807 loss)
I0403 02:38:11.897162 32196 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 02:38:23.437008 32196 solver.cpp:228] Iteration 480, loss = 0.069534
I0403 02:38:23.443409 32196 solver.cpp:244]     Train net output #0: loss = 0.0695341 (* 1 = 0.0695341 loss)
I0403 02:38:23.639096 32196 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:38:35.178748 32196 solver.cpp:228] Iteration 496, loss = 0.029244
I0403 02:38:35.185705 32196 solver.cpp:244]     Train net output #0: loss = 0.029244 (* 1 = 0.029244 loss)
I0403 02:38:35.393393 32196 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 02:38:46.892917 32196 solver.cpp:228] Iteration 512, loss = 0.113124
I0403 02:38:46.893167 32196 solver.cpp:244]     Train net output #0: loss = 0.113124 (* 1 = 0.113124 loss)
I0403 02:38:47.071457 32196 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 02:38:58.476989 32196 solver.cpp:228] Iteration 528, loss = 0.155289
I0403 02:38:58.477952 32196 solver.cpp:244]     Train net output #0: loss = 0.155289 (* 1 = 0.155289 loss)
I0403 02:38:58.661226 32196 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 02:39:10.028666 32196 solver.cpp:228] Iteration 544, loss = 0.0352762
I0403 02:39:10.028769 32196 solver.cpp:244]     Train net output #0: loss = 0.0352763 (* 1 = 0.0352763 loss)
I0403 02:39:10.195197 32196 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 02:39:21.722144 32196 solver.cpp:228] Iteration 560, loss = 0.0536041
I0403 02:39:21.722482 32196 solver.cpp:244]     Train net output #0: loss = 0.0536042 (* 1 = 0.0536042 loss)
I0403 02:39:21.907245 32196 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:39:33.423822 32196 solver.cpp:228] Iteration 576, loss = 0.076348
I0403 02:39:33.423933 32196 solver.cpp:244]     Train net output #0: loss = 0.0763481 (* 1 = 0.0763481 loss)
I0403 02:39:33.676512 32196 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 02:39:45.201551 32196 solver.cpp:228] Iteration 592, loss = 0.020454
I0403 02:39:45.201658 32196 solver.cpp:244]     Train net output #0: loss = 0.0204541 (* 1 = 0.0204541 loss)
I0403 02:39:45.402771 32196 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 02:39:56.796152 32196 solver.cpp:228] Iteration 608, loss = 0.12681
I0403 02:39:56.796465 32196 solver.cpp:244]     Train net output #0: loss = 0.12681 (* 1 = 0.12681 loss)
I0403 02:39:57.024623 32196 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 02:40:08.528887 32196 solver.cpp:228] Iteration 624, loss = 0.0332817
I0403 02:40:08.528997 32196 solver.cpp:244]     Train net output #0: loss = 0.0332817 (* 1 = 0.0332817 loss)
I0403 02:40:08.746739 32196 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:40:20.202324 32196 solver.cpp:228] Iteration 640, loss = 0.035551
I0403 02:40:20.202441 32196 solver.cpp:244]     Train net output #0: loss = 0.035551 (* 1 = 0.035551 loss)
I0403 02:40:20.386265 32196 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:40:26.939838 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_650.caffemodel
I0403 02:40:29.790043 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_650.solverstate
I0403 02:40:31.683425 32196 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 02:41:20.613343 32196 solver.cpp:404]     Test net output #0: accuracy = 0.975024
I0403 02:41:20.623822 32196 solver.cpp:404]     Test net output #1: loss = 0.0770969 (* 1 = 0.0770969 loss)
I0403 02:41:25.506649 32196 solver.cpp:228] Iteration 656, loss = 0.0153935
I0403 02:41:25.512815 32196 solver.cpp:244]     Train net output #0: loss = 0.0153935 (* 1 = 0.0153935 loss)
I0403 02:41:25.686877 32196 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 02:41:37.326513 32196 solver.cpp:228] Iteration 672, loss = 0.0178634
I0403 02:41:37.334046 32196 solver.cpp:244]     Train net output #0: loss = 0.0178635 (* 1 = 0.0178635 loss)
I0403 02:41:37.533761 32196 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:41:49.107372 32196 solver.cpp:228] Iteration 688, loss = 0.026067
I0403 02:41:49.113908 32196 solver.cpp:244]     Train net output #0: loss = 0.026067 (* 1 = 0.026067 loss)
I0403 02:41:49.295522 32196 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 02:42:00.730273 32196 solver.cpp:228] Iteration 704, loss = 0.0484636
I0403 02:42:00.737282 32196 solver.cpp:244]     Train net output #0: loss = 0.0484637 (* 1 = 0.0484637 loss)
I0403 02:42:00.912113 32196 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 02:42:12.435973 32196 solver.cpp:228] Iteration 720, loss = 0.037574
I0403 02:42:12.442384 32196 solver.cpp:244]     Train net output #0: loss = 0.037574 (* 1 = 0.037574 loss)
I0403 02:42:12.621073 32196 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:42:24.089000 32196 solver.cpp:228] Iteration 736, loss = 0.0748674
I0403 02:42:24.095551 32196 solver.cpp:244]     Train net output #0: loss = 0.0748674 (* 1 = 0.0748674 loss)
I0403 02:42:24.284654 32196 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 02:42:35.917873 32196 solver.cpp:228] Iteration 752, loss = 0.0883181
I0403 02:42:35.924402 32196 solver.cpp:244]     Train net output #0: loss = 0.0883182 (* 1 = 0.0883182 loss)
I0403 02:42:36.120661 32196 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 02:42:47.528852 32196 solver.cpp:228] Iteration 768, loss = 0.0344375
I0403 02:42:47.543231 32196 solver.cpp:244]     Train net output #0: loss = 0.0344375 (* 1 = 0.0344375 loss)
I0403 02:42:47.728404 32196 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 02:42:59.097796 32196 solver.cpp:228] Iteration 784, loss = 0.0590567
I0403 02:42:59.104296 32196 solver.cpp:244]     Train net output #0: loss = 0.0590567 (* 1 = 0.0590567 loss)
I0403 02:42:59.272373 32196 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 02:43:10.752302 32196 solver.cpp:228] Iteration 800, loss = 0.0554743
I0403 02:43:10.758939 32196 solver.cpp:244]     Train net output #0: loss = 0.0554744 (* 1 = 0.0554744 loss)
I0403 02:43:10.910521 32196 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:43:22.570063 32196 solver.cpp:228] Iteration 816, loss = 0.0487128
I0403 02:43:22.577247 32196 solver.cpp:244]     Train net output #0: loss = 0.0487128 (* 1 = 0.0487128 loss)
I0403 02:43:22.777434 32196 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 02:43:34.238211 32196 solver.cpp:228] Iteration 832, loss = 0.0674674
I0403 02:43:34.244607 32196 solver.cpp:244]     Train net output #0: loss = 0.0674675 (* 1 = 0.0674675 loss)
I0403 02:43:34.414723 32196 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:43:45.909906 32196 solver.cpp:228] Iteration 848, loss = 0.0252466
I0403 02:43:45.915679 32196 solver.cpp:244]     Train net output #0: loss = 0.0252466 (* 1 = 0.0252466 loss)
I0403 02:43:46.100596 32196 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 02:43:57.573804 32196 solver.cpp:228] Iteration 864, loss = 0.0804866
I0403 02:43:57.579762 32196 solver.cpp:244]     Train net output #0: loss = 0.0804866 (* 1 = 0.0804866 loss)
I0403 02:43:57.757028 32196 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 02:44:09.249238 32196 solver.cpp:228] Iteration 880, loss = 0.0214956
I0403 02:44:09.255597 32196 solver.cpp:244]     Train net output #0: loss = 0.0214956 (* 1 = 0.0214956 loss)
I0403 02:44:09.420445 32196 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:44:20.943979 32196 solver.cpp:228] Iteration 896, loss = 0.0338027
I0403 02:44:20.950706 32196 solver.cpp:244]     Train net output #0: loss = 0.0338027 (* 1 = 0.0338027 loss)
I0403 02:44:21.128933 32196 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 02:44:32.569980 32196 solver.cpp:228] Iteration 912, loss = 0.0701282
I0403 02:44:32.576869 32196 solver.cpp:244]     Train net output #0: loss = 0.0701283 (* 1 = 0.0701283 loss)
I0403 02:44:32.794203 32196 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 02:44:44.248523 32196 solver.cpp:228] Iteration 928, loss = 0.0566205
I0403 02:44:44.254624 32196 solver.cpp:244]     Train net output #0: loss = 0.0566205 (* 1 = 0.0566205 loss)
I0403 02:44:44.446213 32196 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 02:44:55.951119 32196 solver.cpp:228] Iteration 944, loss = 0.0120425
I0403 02:44:55.957656 32196 solver.cpp:244]     Train net output #0: loss = 0.0120425 (* 1 = 0.0120425 loss)
I0403 02:44:56.132519 32196 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 02:45:07.815162 32196 solver.cpp:228] Iteration 960, loss = 0.0312774
I0403 02:45:07.821683 32196 solver.cpp:244]     Train net output #0: loss = 0.0312774 (* 1 = 0.0312774 loss)
I0403 02:45:08.016139 32196 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:45:18.144335 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_975.caffemodel
I0403 02:45:20.926620 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_975.solverstate
I0403 02:45:22.825788 32196 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 02:46:11.762975 32196 solver.cpp:404]     Test net output #0: accuracy = 0.965023
I0403 02:46:11.769737 32196 solver.cpp:404]     Test net output #1: loss = 0.123256 (* 1 = 0.123256 loss)
I0403 02:46:12.983330 32196 solver.cpp:228] Iteration 976, loss = 0.0351971
I0403 02:46:12.989961 32196 solver.cpp:244]     Train net output #0: loss = 0.0351971 (* 1 = 0.0351971 loss)
I0403 02:46:13.210753 32196 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 02:46:24.707782 32196 solver.cpp:228] Iteration 992, loss = 0.123759
I0403 02:46:24.713676 32196 solver.cpp:244]     Train net output #0: loss = 0.123759 (* 1 = 0.123759 loss)
I0403 02:46:24.915081 32196 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 02:46:36.431309 32196 solver.cpp:228] Iteration 1008, loss = 0.0737168
I0403 02:46:36.437458 32196 solver.cpp:244]     Train net output #0: loss = 0.0737168 (* 1 = 0.0737168 loss)
I0403 02:46:36.617419 32196 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:46:48.022766 32196 solver.cpp:228] Iteration 1024, loss = 0.0229282
I0403 02:46:48.047979 32196 solver.cpp:244]     Train net output #0: loss = 0.0229282 (* 1 = 0.0229282 loss)
I0403 02:46:48.188920 32196 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 02:46:59.879257 32196 solver.cpp:228] Iteration 1040, loss = 0.00483526
I0403 02:46:59.885922 32196 solver.cpp:244]     Train net output #0: loss = 0.00483528 (* 1 = 0.00483528 loss)
I0403 02:47:00.025861 32196 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:47:11.675796 32196 solver.cpp:228] Iteration 1056, loss = 0.164529
I0403 02:47:11.682246 32196 solver.cpp:244]     Train net output #0: loss = 0.164529 (* 1 = 0.164529 loss)
I0403 02:47:11.869746 32196 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 02:47:23.460239 32196 solver.cpp:228] Iteration 1072, loss = 0.0199155
I0403 02:47:23.467197 32196 solver.cpp:244]     Train net output #0: loss = 0.0199155 (* 1 = 0.0199155 loss)
I0403 02:47:23.642760 32196 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 02:47:35.231171 32196 solver.cpp:228] Iteration 1088, loss = 0.0546813
I0403 02:47:35.237053 32196 solver.cpp:244]     Train net output #0: loss = 0.0546813 (* 1 = 0.0546813 loss)
I0403 02:47:35.422688 32196 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 02:47:47.042171 32196 solver.cpp:228] Iteration 1104, loss = 0.0228923
I0403 02:47:47.048820 32196 solver.cpp:244]     Train net output #0: loss = 0.0228923 (* 1 = 0.0228923 loss)
I0403 02:47:47.231351 32196 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 02:47:58.657385 32196 solver.cpp:228] Iteration 1120, loss = 0.0107206
I0403 02:47:58.663635 32196 solver.cpp:244]     Train net output #0: loss = 0.0107206 (* 1 = 0.0107206 loss)
I0403 02:47:58.906642 32196 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:48:10.351604 32196 solver.cpp:228] Iteration 1136, loss = 0.0312015
I0403 02:48:10.358317 32196 solver.cpp:244]     Train net output #0: loss = 0.0312015 (* 1 = 0.0312015 loss)
I0403 02:48:10.581398 32196 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 02:48:22.057781 32196 solver.cpp:228] Iteration 1152, loss = 0.037039
I0403 02:48:22.064294 32196 solver.cpp:244]     Train net output #0: loss = 0.037039 (* 1 = 0.037039 loss)
I0403 02:48:22.251695 32196 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 02:48:33.654949 32196 solver.cpp:228] Iteration 1168, loss = 0.0641679
I0403 02:48:33.660436 32196 solver.cpp:244]     Train net output #0: loss = 0.0641679 (* 1 = 0.0641679 loss)
I0403 02:48:33.778645 32196 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 02:48:45.416311 32196 solver.cpp:228] Iteration 1184, loss = 0.0362216
I0403 02:48:45.422832 32196 solver.cpp:244]     Train net output #0: loss = 0.0362216 (* 1 = 0.0362216 loss)
I0403 02:48:45.629632 32196 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 02:48:57.118844 32196 solver.cpp:228] Iteration 1200, loss = 0.0166521
I0403 02:48:57.123760 32196 solver.cpp:244]     Train net output #0: loss = 0.0166521 (* 1 = 0.0166521 loss)
I0403 02:48:57.336032 32196 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:49:08.823603 32196 solver.cpp:228] Iteration 1216, loss = 0.0705832
I0403 02:49:08.829581 32196 solver.cpp:244]     Train net output #0: loss = 0.0705832 (* 1 = 0.0705832 loss)
I0403 02:49:09.015697 32196 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 02:49:20.351356 32196 solver.cpp:228] Iteration 1232, loss = 0.0753421
I0403 02:49:20.357444 32196 solver.cpp:244]     Train net output #0: loss = 0.0753421 (* 1 = 0.0753421 loss)
I0403 02:49:20.533838 32196 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 02:49:32.132923 32196 solver.cpp:228] Iteration 1248, loss = 0.0280687
I0403 02:49:32.139449 32196 solver.cpp:244]     Train net output #0: loss = 0.0280688 (* 1 = 0.0280688 loss)
I0403 02:49:32.338270 32196 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:49:43.934489 32196 solver.cpp:228] Iteration 1264, loss = 0.00939862
I0403 02:49:43.940606 32196 solver.cpp:244]     Train net output #0: loss = 0.00939863 (* 1 = 0.00939863 loss)
I0403 02:49:44.148655 32196 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 02:49:55.638149 32196 solver.cpp:228] Iteration 1280, loss = 0.0721948
I0403 02:49:55.644775 32196 solver.cpp:244]     Train net output #0: loss = 0.0721948 (* 1 = 0.0721948 loss)
I0403 02:49:55.852170 32196 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:50:07.329303 32196 solver.cpp:228] Iteration 1296, loss = 0.114926
I0403 02:50:07.333905 32196 solver.cpp:244]     Train net output #0: loss = 0.114926 (* 1 = 0.114926 loss)
I0403 02:50:07.531873 32196 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 02:50:09.711521 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1300.caffemodel
I0403 02:50:12.476348 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1300.solverstate
I0403 02:50:14.291793 32196 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 02:51:03.259452 32196 solver.cpp:404]     Test net output #0: accuracy = 0.980185
I0403 02:51:03.266952 32196 solver.cpp:404]     Test net output #1: loss = 0.0659948 (* 1 = 0.0659948 loss)
I0403 02:51:12.500394 32196 solver.cpp:228] Iteration 1312, loss = 0.0174066
I0403 02:51:12.506592 32196 solver.cpp:244]     Train net output #0: loss = 0.0174066 (* 1 = 0.0174066 loss)
I0403 02:51:12.684172 32196 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 02:51:24.026976 32196 solver.cpp:228] Iteration 1328, loss = 0.00146466
I0403 02:51:24.033218 32196 solver.cpp:244]     Train net output #0: loss = 0.00146467 (* 1 = 0.00146467 loss)
I0403 02:51:24.211376 32196 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 02:51:35.710173 32196 solver.cpp:228] Iteration 1344, loss = 0.0126193
I0403 02:51:35.716863 32196 solver.cpp:244]     Train net output #0: loss = 0.0126193 (* 1 = 0.0126193 loss)
I0403 02:51:35.864011 32196 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:51:47.283321 32196 solver.cpp:228] Iteration 1360, loss = 0.0366248
I0403 02:51:47.290182 32196 solver.cpp:244]     Train net output #0: loss = 0.0366248 (* 1 = 0.0366248 loss)
I0403 02:51:47.475848 32196 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:51:58.838243 32196 solver.cpp:228] Iteration 1376, loss = 0.0865155
I0403 02:51:58.843485 32196 solver.cpp:244]     Train net output #0: loss = 0.0865155 (* 1 = 0.0865155 loss)
I0403 02:51:59.027168 32196 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 02:52:10.376162 32196 solver.cpp:228] Iteration 1392, loss = 0.0884963
I0403 02:52:10.384399 32196 solver.cpp:244]     Train net output #0: loss = 0.0884963 (* 1 = 0.0884963 loss)
I0403 02:52:10.547231 32196 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 02:52:21.918467 32196 solver.cpp:228] Iteration 1408, loss = 0.0124557
I0403 02:52:21.923840 32196 solver.cpp:244]     Train net output #0: loss = 0.0124557 (* 1 = 0.0124557 loss)
I0403 02:52:22.114104 32196 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 02:52:33.523494 32196 solver.cpp:228] Iteration 1424, loss = 0.0377462
I0403 02:52:33.529973 32196 solver.cpp:244]     Train net output #0: loss = 0.0377462 (* 1 = 0.0377462 loss)
I0403 02:52:33.705037 32196 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 02:52:45.056485 32196 solver.cpp:228] Iteration 1440, loss = 0.00340065
I0403 02:52:45.062531 32196 solver.cpp:244]     Train net output #0: loss = 0.00340063 (* 1 = 0.00340063 loss)
I0403 02:52:45.225203 32196 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:52:56.603796 32196 solver.cpp:228] Iteration 1456, loss = 0.00527731
I0403 02:52:56.609735 32196 solver.cpp:244]     Train net output #0: loss = 0.0052773 (* 1 = 0.0052773 loss)
I0403 02:52:56.795613 32196 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:53:08.227959 32196 solver.cpp:228] Iteration 1472, loss = 0.123304
I0403 02:53:08.234494 32196 solver.cpp:244]     Train net output #0: loss = 0.123304 (* 1 = 0.123304 loss)
I0403 02:53:08.392532 32196 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 02:53:20.076236 32196 solver.cpp:228] Iteration 1488, loss = 0.0128044
I0403 02:53:20.083123 32196 solver.cpp:244]     Train net output #0: loss = 0.0128044 (* 1 = 0.0128044 loss)
I0403 02:53:20.318454 32196 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 02:53:31.819031 32196 solver.cpp:228] Iteration 1504, loss = 0.014909
I0403 02:53:31.824602 32196 solver.cpp:244]     Train net output #0: loss = 0.014909 (* 1 = 0.014909 loss)
I0403 02:53:32.002898 32196 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 02:53:43.481309 32196 solver.cpp:228] Iteration 1520, loss = 0.0308717
I0403 02:53:43.488292 32196 solver.cpp:244]     Train net output #0: loss = 0.0308717 (* 1 = 0.0308717 loss)
I0403 02:53:43.659765 32196 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:53:55.127830 32196 solver.cpp:228] Iteration 1536, loss = 0.0266981
I0403 02:53:55.132719 32196 solver.cpp:244]     Train net output #0: loss = 0.0266981 (* 1 = 0.0266981 loss)
I0403 02:53:55.311681 32196 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 02:54:06.775583 32196 solver.cpp:228] Iteration 1552, loss = 0.00578662
I0403 02:54:06.780704 32196 solver.cpp:244]     Train net output #0: loss = 0.00578661 (* 1 = 0.00578661 loss)
I0403 02:54:06.956652 32196 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 02:54:18.449172 32196 solver.cpp:228] Iteration 1568, loss = 0.00229877
I0403 02:54:18.455757 32196 solver.cpp:244]     Train net output #0: loss = 0.00229876 (* 1 = 0.00229876 loss)
I0403 02:54:18.648046 32196 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 02:54:30.132385 32196 solver.cpp:228] Iteration 1584, loss = 0.0812189
I0403 02:54:30.138824 32196 solver.cpp:244]     Train net output #0: loss = 0.0812189 (* 1 = 0.0812189 loss)
I0403 02:54:30.320972 32196 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 02:54:41.982921 32196 solver.cpp:228] Iteration 1600, loss = 0.0399583
I0403 02:54:41.989483 32196 solver.cpp:244]     Train net output #0: loss = 0.0399583 (* 1 = 0.0399583 loss)
I0403 02:54:42.165732 32196 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 02:54:53.686939 32196 solver.cpp:228] Iteration 1616, loss = 0.0521203
I0403 02:54:53.693156 32196 solver.cpp:244]     Train net output #0: loss = 0.0521203 (* 1 = 0.0521203 loss)
I0403 02:54:53.870659 32196 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 02:54:59.727313 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1625.caffemodel
I0403 02:55:02.510372 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1625.solverstate
I0403 02:55:04.370378 32196 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 02:55:53.318178 32196 solver.cpp:404]     Test net output #0: accuracy = 0.982213
I0403 02:55:53.325731 32196 solver.cpp:404]     Test net output #1: loss = 0.0601669 (* 1 = 0.0601669 loss)
I0403 02:55:59.022819 32196 solver.cpp:228] Iteration 1632, loss = 0.0037364
I0403 02:55:59.028851 32196 solver.cpp:244]     Train net output #0: loss = 0.0037364 (* 1 = 0.0037364 loss)
I0403 02:55:59.223337 32196 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 02:56:10.746971 32196 solver.cpp:228] Iteration 1648, loss = 0.00575692
I0403 02:56:10.753118 32196 solver.cpp:244]     Train net output #0: loss = 0.00575692 (* 1 = 0.00575692 loss)
I0403 02:56:10.940327 32196 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 02:56:22.455199 32196 solver.cpp:228] Iteration 1664, loss = 0.00874708
I0403 02:56:22.462103 32196 solver.cpp:244]     Train net output #0: loss = 0.00874707 (* 1 = 0.00874707 loss)
I0403 02:56:22.640029 32196 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:56:34.070395 32196 solver.cpp:228] Iteration 1680, loss = 0.00160403
I0403 02:56:34.076896 32196 solver.cpp:244]     Train net output #0: loss = 0.00160402 (* 1 = 0.00160402 loss)
I0403 02:56:34.253049 32196 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:56:45.724968 32196 solver.cpp:228] Iteration 1696, loss = 0.0141087
I0403 02:56:45.731256 32196 solver.cpp:244]     Train net output #0: loss = 0.0141087 (* 1 = 0.0141087 loss)
I0403 02:56:45.907908 32196 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 02:56:57.509001 32196 solver.cpp:228] Iteration 1712, loss = 0.0428753
I0403 02:56:57.515434 32196 solver.cpp:244]     Train net output #0: loss = 0.0428753 (* 1 = 0.0428753 loss)
I0403 02:56:57.715854 32196 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 02:57:09.152504 32196 solver.cpp:228] Iteration 1728, loss = 0.00784023
I0403 02:57:09.157912 32196 solver.cpp:244]     Train net output #0: loss = 0.00784023 (* 1 = 0.00784023 loss)
I0403 02:57:09.352989 32196 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 02:57:20.910754 32196 solver.cpp:228] Iteration 1744, loss = 0.00382529
I0403 02:57:20.916679 32196 solver.cpp:244]     Train net output #0: loss = 0.00382529 (* 1 = 0.00382529 loss)
I0403 02:57:21.090951 32196 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 02:57:32.540838 32196 solver.cpp:228] Iteration 1760, loss = 0.00721244
I0403 02:57:32.547320 32196 solver.cpp:244]     Train net output #0: loss = 0.00721245 (* 1 = 0.00721245 loss)
I0403 02:57:32.726871 32196 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 02:57:44.279464 32196 solver.cpp:228] Iteration 1776, loss = 0.00607807
I0403 02:57:44.285742 32196 solver.cpp:244]     Train net output #0: loss = 0.00607807 (* 1 = 0.00607807 loss)
I0403 02:57:44.464943 32196 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 02:57:55.864392 32196 solver.cpp:228] Iteration 1792, loss = 0.00294916
I0403 02:57:55.870132 32196 solver.cpp:244]     Train net output #0: loss = 0.00294917 (* 1 = 0.00294917 loss)
I0403 02:57:56.072564 32196 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 02:58:07.623309 32196 solver.cpp:228] Iteration 1808, loss = 0.0126712
I0403 02:58:07.630259 32196 solver.cpp:244]     Train net output #0: loss = 0.0126712 (* 1 = 0.0126712 loss)
I0403 02:58:07.803036 32196 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 02:58:19.297725 32196 solver.cpp:228] Iteration 1824, loss = 0.0591028
I0403 02:58:19.304842 32196 solver.cpp:244]     Train net output #0: loss = 0.0591028 (* 1 = 0.0591028 loss)
I0403 02:58:19.474632 32196 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 02:58:31.106143 32196 solver.cpp:228] Iteration 1840, loss = 0.00373803
I0403 02:58:31.111454 32196 solver.cpp:244]     Train net output #0: loss = 0.00373804 (* 1 = 0.00373804 loss)
I0403 02:58:31.288192 32196 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 02:58:42.928130 32196 solver.cpp:228] Iteration 1856, loss = 0.0273377
I0403 02:58:42.933737 32196 solver.cpp:244]     Train net output #0: loss = 0.0273377 (* 1 = 0.0273377 loss)
I0403 02:58:43.127118 32196 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 02:58:54.556846 32196 solver.cpp:228] Iteration 1872, loss = 0.0029287
I0403 02:58:54.563438 32196 solver.cpp:244]     Train net output #0: loss = 0.0029287 (* 1 = 0.0029287 loss)
I0403 02:58:54.755376 32196 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 02:59:06.217737 32196 solver.cpp:228] Iteration 1888, loss = 0.00381593
I0403 02:59:06.224292 32196 solver.cpp:244]     Train net output #0: loss = 0.00381594 (* 1 = 0.00381594 loss)
I0403 02:59:06.405520 32196 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 02:59:18.000102 32196 solver.cpp:228] Iteration 1904, loss = 0.0525687
I0403 02:59:18.006217 32196 solver.cpp:244]     Train net output #0: loss = 0.0525687 (* 1 = 0.0525687 loss)
I0403 02:59:18.208474 32196 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 02:59:29.723728 32196 solver.cpp:228] Iteration 1920, loss = 0.012239
I0403 02:59:29.730536 32196 solver.cpp:244]     Train net output #0: loss = 0.0122391 (* 1 = 0.0122391 loss)
I0403 02:59:29.951490 32196 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 02:59:41.542362 32196 solver.cpp:228] Iteration 1936, loss = 0.0581843
I0403 02:59:41.549554 32196 solver.cpp:244]     Train net output #0: loss = 0.0581843 (* 1 = 0.0581843 loss)
I0403 02:59:41.758378 32196 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 02:59:51.220731 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1950.caffemodel
I0403 02:59:53.970126 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_1950.solverstate
I0403 02:59:55.875905 32196 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 03:00:44.798573 32196 solver.cpp:404]     Test net output #0: accuracy = 0.983365
I0403 03:00:44.805371 32196 solver.cpp:404]     Test net output #1: loss = 0.0569265 (* 1 = 0.0569265 loss)
I0403 03:00:46.777850 32196 solver.cpp:228] Iteration 1952, loss = 0.00690107
I0403 03:00:46.786092 32196 solver.cpp:244]     Train net output #0: loss = 0.00690108 (* 1 = 0.00690108 loss)
I0403 03:00:46.968814 32196 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 03:00:58.728914 32196 solver.cpp:228] Iteration 1968, loss = 0.0292435
I0403 03:00:58.735435 32196 solver.cpp:244]     Train net output #0: loss = 0.0292435 (* 1 = 0.0292435 loss)
I0403 03:00:58.932037 32196 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 03:01:10.354357 32196 solver.cpp:228] Iteration 1984, loss = 0.0351439
I0403 03:01:10.359877 32196 solver.cpp:244]     Train net output #0: loss = 0.0351439 (* 1 = 0.0351439 loss)
I0403 03:01:10.557598 32196 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 03:01:22.150800 32196 solver.cpp:228] Iteration 2000, loss = 0.00246301
I0403 03:01:22.160614 32196 solver.cpp:244]     Train net output #0: loss = 0.00246303 (* 1 = 0.00246303 loss)
I0403 03:01:22.345172 32196 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:01:33.969952 32196 solver.cpp:228] Iteration 2016, loss = 0.00160065
I0403 03:01:33.976764 32196 solver.cpp:244]     Train net output #0: loss = 0.00160068 (* 1 = 0.00160068 loss)
I0403 03:01:34.152946 32196 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 03:01:45.759325 32196 solver.cpp:228] Iteration 2032, loss = 0.0197838
I0403 03:01:45.765422 32196 solver.cpp:244]     Train net output #0: loss = 0.0197838 (* 1 = 0.0197838 loss)
I0403 03:01:45.943022 32196 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 03:01:57.410055 32196 solver.cpp:228] Iteration 2048, loss = 0.0223237
I0403 03:01:57.415935 32196 solver.cpp:244]     Train net output #0: loss = 0.0223237 (* 1 = 0.0223237 loss)
I0403 03:01:57.595154 32196 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 03:02:09.258236 32196 solver.cpp:228] Iteration 2064, loss = 0.033591
I0403 03:02:09.264864 32196 solver.cpp:244]     Train net output #0: loss = 0.0335911 (* 1 = 0.0335911 loss)
I0403 03:02:09.434686 32196 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 03:02:21.138242 32196 solver.cpp:228] Iteration 2080, loss = 0.0273802
I0403 03:02:21.144713 32196 solver.cpp:244]     Train net output #0: loss = 0.0273802 (* 1 = 0.0273802 loss)
I0403 03:02:21.334488 32196 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:02:32.766507 32196 solver.cpp:228] Iteration 2096, loss = 0.0291733
I0403 03:02:32.773025 32196 solver.cpp:244]     Train net output #0: loss = 0.0291733 (* 1 = 0.0291733 loss)
I0403 03:02:33.009436 32196 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 03:02:44.605008 32196 solver.cpp:228] Iteration 2112, loss = 0.0341742
I0403 03:02:44.611038 32196 solver.cpp:244]     Train net output #0: loss = 0.0341742 (* 1 = 0.0341742 loss)
I0403 03:02:44.799219 32196 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 03:02:56.291467 32196 solver.cpp:228] Iteration 2128, loss = 0.00341795
I0403 03:02:56.298233 32196 solver.cpp:244]     Train net output #0: loss = 0.00341797 (* 1 = 0.00341797 loss)
I0403 03:02:56.487071 32196 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 03:03:08.127858 32196 solver.cpp:228] Iteration 2144, loss = 0.00529805
I0403 03:03:08.134176 32196 solver.cpp:244]     Train net output #0: loss = 0.00529806 (* 1 = 0.00529806 loss)
I0403 03:03:08.330461 32196 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 03:03:19.854588 32196 solver.cpp:228] Iteration 2160, loss = 0.0447373
I0403 03:03:19.860069 32196 solver.cpp:244]     Train net output #0: loss = 0.0447374 (* 1 = 0.0447374 loss)
I0403 03:03:19.971099 32196 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:03:31.423305 32196 solver.cpp:228] Iteration 2176, loss = 0.0283307
I0403 03:03:31.429558 32196 solver.cpp:244]     Train net output #0: loss = 0.0283307 (* 1 = 0.0283307 loss)
I0403 03:03:31.611332 32196 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 03:03:43.062296 32196 solver.cpp:228] Iteration 2192, loss = 0.0576796
I0403 03:03:43.068424 32196 solver.cpp:244]     Train net output #0: loss = 0.0576796 (* 1 = 0.0576796 loss)
I0403 03:03:43.236603 32196 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 03:03:54.875318 32196 solver.cpp:228] Iteration 2208, loss = 0.0224106
I0403 03:03:54.882225 32196 solver.cpp:244]     Train net output #0: loss = 0.0224106 (* 1 = 0.0224106 loss)
I0403 03:03:55.016993 32196 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 03:04:06.617884 32196 solver.cpp:228] Iteration 2224, loss = 0.00647801
I0403 03:04:06.624788 32196 solver.cpp:244]     Train net output #0: loss = 0.00647801 (* 1 = 0.00647801 loss)
I0403 03:04:06.780709 32196 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 03:04:18.345489 32196 solver.cpp:228] Iteration 2240, loss = 0.00665249
I0403 03:04:18.351820 32196 solver.cpp:244]     Train net output #0: loss = 0.00665249 (* 1 = 0.00665249 loss)
I0403 03:04:18.578243 32196 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 03:04:30.103569 32196 solver.cpp:228] Iteration 2256, loss = 0.00667208
I0403 03:04:30.110000 32196 solver.cpp:244]     Train net output #0: loss = 0.00667209 (* 1 = 0.00667209 loss)
I0403 03:04:30.281558 32196 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 03:04:41.761770 32196 solver.cpp:228] Iteration 2272, loss = 0.0488499
I0403 03:04:41.768008 32196 solver.cpp:244]     Train net output #0: loss = 0.0488499 (* 1 = 0.0488499 loss)
I0403 03:04:41.959839 32196 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 03:04:43.447118 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2275.caffemodel
I0403 03:04:46.216107 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2275.solverstate
I0403 03:04:48.133514 32196 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 03:05:37.065474 32196 solver.cpp:404]     Test net output #0: accuracy = 0.982028
I0403 03:05:37.072720 32196 solver.cpp:404]     Test net output #1: loss = 0.0644814 (* 1 = 0.0644814 loss)
I0403 03:05:47.155908 32196 solver.cpp:228] Iteration 2288, loss = 0.0127955
I0403 03:05:47.162753 32196 solver.cpp:244]     Train net output #0: loss = 0.0127955 (* 1 = 0.0127955 loss)
I0403 03:05:47.341995 32196 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:05:58.859313 32196 solver.cpp:228] Iteration 2304, loss = 0.00193696
I0403 03:05:58.864359 32196 solver.cpp:244]     Train net output #0: loss = 0.00193696 (* 1 = 0.00193696 loss)
I0403 03:05:59.012718 32196 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 03:06:10.640022 32196 solver.cpp:228] Iteration 2320, loss = 0.0345845
I0403 03:06:10.646244 32196 solver.cpp:244]     Train net output #0: loss = 0.0345845 (* 1 = 0.0345845 loss)
I0403 03:06:10.816959 32196 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 03:06:22.409795 32196 solver.cpp:228] Iteration 2336, loss = 0.00353003
I0403 03:06:22.415755 32196 solver.cpp:244]     Train net output #0: loss = 0.00353003 (* 1 = 0.00353003 loss)
I0403 03:06:22.574498 32196 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 03:06:34.151053 32196 solver.cpp:228] Iteration 2352, loss = 0.0139898
I0403 03:06:34.157088 32196 solver.cpp:244]     Train net output #0: loss = 0.0139898 (* 1 = 0.0139898 loss)
I0403 03:06:34.303356 32196 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:06:45.894534 32196 solver.cpp:228] Iteration 2368, loss = 0.0628916
I0403 03:06:45.899349 32196 solver.cpp:244]     Train net output #0: loss = 0.0628916 (* 1 = 0.0628916 loss)
I0403 03:06:46.073292 32196 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 03:06:57.633162 32196 solver.cpp:228] Iteration 2384, loss = 0.0028777
I0403 03:06:57.639191 32196 solver.cpp:244]     Train net output #0: loss = 0.00287771 (* 1 = 0.00287771 loss)
I0403 03:06:57.833423 32196 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 03:07:09.322394 32196 solver.cpp:228] Iteration 2400, loss = 0.0109103
I0403 03:07:09.329483 32196 solver.cpp:244]     Train net output #0: loss = 0.0109103 (* 1 = 0.0109103 loss)
I0403 03:07:09.504796 32196 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 03:07:20.923171 32196 solver.cpp:228] Iteration 2416, loss = 0.00653869
I0403 03:07:20.929808 32196 solver.cpp:244]     Train net output #0: loss = 0.0065387 (* 1 = 0.0065387 loss)
I0403 03:07:21.110710 32196 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 03:07:32.764803 32196 solver.cpp:228] Iteration 2432, loss = 0.00434416
I0403 03:07:32.770635 32196 solver.cpp:244]     Train net output #0: loss = 0.00434417 (* 1 = 0.00434417 loss)
I0403 03:07:32.922251 32196 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 03:07:44.528314 32196 solver.cpp:228] Iteration 2448, loss = 0.00695728
I0403 03:07:44.534631 32196 solver.cpp:244]     Train net output #0: loss = 0.00695729 (* 1 = 0.00695729 loss)
I0403 03:07:44.767519 32196 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 03:07:56.252471 32196 solver.cpp:228] Iteration 2464, loss = 0.0076441
I0403 03:07:56.259157 32196 solver.cpp:244]     Train net output #0: loss = 0.0076441 (* 1 = 0.0076441 loss)
I0403 03:07:56.406316 32196 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 03:08:08.067744 32196 solver.cpp:228] Iteration 2480, loss = 0.0028299
I0403 03:08:08.074051 32196 solver.cpp:244]     Train net output #0: loss = 0.00282991 (* 1 = 0.00282991 loss)
I0403 03:08:08.269665 32196 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 03:08:19.896000 32196 solver.cpp:228] Iteration 2496, loss = 0.022444
I0403 03:08:19.904959 32196 solver.cpp:244]     Train net output #0: loss = 0.022444 (* 1 = 0.022444 loss)
I0403 03:08:20.120199 32196 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:08:31.711860 32196 solver.cpp:228] Iteration 2512, loss = 0.00744478
I0403 03:08:31.717129 32196 solver.cpp:244]     Train net output #0: loss = 0.0074448 (* 1 = 0.0074448 loss)
I0403 03:08:31.914965 32196 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 03:08:43.431463 32196 solver.cpp:228] Iteration 2528, loss = 0.0871492
I0403 03:08:43.437698 32196 solver.cpp:244]     Train net output #0: loss = 0.0871492 (* 1 = 0.0871492 loss)
I0403 03:08:43.622539 32196 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 03:08:55.072386 32196 solver.cpp:228] Iteration 2544, loss = 0.00257891
I0403 03:08:55.079058 32196 solver.cpp:244]     Train net output #0: loss = 0.00257891 (* 1 = 0.00257891 loss)
I0403 03:08:55.262122 32196 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 03:09:06.712803 32196 solver.cpp:228] Iteration 2560, loss = 0.0631065
I0403 03:09:06.717911 32196 solver.cpp:244]     Train net output #0: loss = 0.0631065 (* 1 = 0.0631065 loss)
I0403 03:09:06.908573 32196 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 03:09:18.344866 32196 solver.cpp:228] Iteration 2576, loss = 0.00368619
I0403 03:09:18.350750 32196 solver.cpp:244]     Train net output #0: loss = 0.0036862 (* 1 = 0.0036862 loss)
I0403 03:09:18.516813 32196 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 03:09:30.078685 32196 solver.cpp:228] Iteration 2592, loss = 0.0477556
I0403 03:09:30.085316 32196 solver.cpp:244]     Train net output #0: loss = 0.0477556 (* 1 = 0.0477556 loss)
I0403 03:09:30.314826 32196 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 03:09:35.360127 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2600.caffemodel
I0403 03:09:38.097568 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2600.solverstate
I0403 03:09:39.929167 32196 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 03:10:28.875073 32196 solver.cpp:404]     Test net output #0: accuracy = 0.975715
I0403 03:10:28.882040 32196 solver.cpp:404]     Test net output #1: loss = 0.081539 (* 1 = 0.081539 loss)
I0403 03:10:35.271481 32196 solver.cpp:228] Iteration 2608, loss = 0.00331551
I0403 03:10:35.277079 32196 solver.cpp:244]     Train net output #0: loss = 0.00331552 (* 1 = 0.00331552 loss)
I0403 03:10:35.453604 32196 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 03:10:46.971544 32196 solver.cpp:228] Iteration 2624, loss = 0.0179383
I0403 03:10:46.977830 32196 solver.cpp:244]     Train net output #0: loss = 0.0179383 (* 1 = 0.0179383 loss)
I0403 03:10:47.217999 32196 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 03:10:58.748879 32196 solver.cpp:228] Iteration 2640, loss = 0.00633282
I0403 03:10:58.755293 32196 solver.cpp:244]     Train net output #0: loss = 0.00633284 (* 1 = 0.00633284 loss)
I0403 03:10:58.944805 32196 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 03:11:10.644150 32196 solver.cpp:228] Iteration 2656, loss = 0.0228617
I0403 03:11:10.651535 32196 solver.cpp:244]     Train net output #0: loss = 0.0228617 (* 1 = 0.0228617 loss)
I0403 03:11:10.779069 32196 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 03:11:22.447726 32196 solver.cpp:228] Iteration 2672, loss = 0.00188562
I0403 03:11:22.455009 32196 solver.cpp:244]     Train net output #0: loss = 0.00188564 (* 1 = 0.00188564 loss)
I0403 03:11:22.625727 32196 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 03:11:34.246479 32196 solver.cpp:228] Iteration 2688, loss = 0.0153094
I0403 03:11:34.252655 32196 solver.cpp:244]     Train net output #0: loss = 0.0153094 (* 1 = 0.0153094 loss)
I0403 03:11:34.382797 32196 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:11:45.928684 32196 solver.cpp:228] Iteration 2704, loss = 0.00039725
I0403 03:11:45.934608 32196 solver.cpp:244]     Train net output #0: loss = 0.000397277 (* 1 = 0.000397277 loss)
I0403 03:11:46.094913 32196 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 03:11:57.651150 32196 solver.cpp:228] Iteration 2720, loss = 0.00896915
I0403 03:11:57.655982 32196 solver.cpp:244]     Train net output #0: loss = 0.00896918 (* 1 = 0.00896918 loss)
I0403 03:11:57.859268 32196 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 03:12:09.412894 32196 solver.cpp:228] Iteration 2736, loss = 0.000841723
I0403 03:12:09.419342 32196 solver.cpp:244]     Train net output #0: loss = 0.00084175 (* 1 = 0.00084175 loss)
I0403 03:12:09.596598 32196 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 03:12:21.024452 32196 solver.cpp:228] Iteration 2752, loss = 0.00268566
I0403 03:12:21.030995 32196 solver.cpp:244]     Train net output #0: loss = 0.00268569 (* 1 = 0.00268569 loss)
I0403 03:12:21.206650 32196 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 03:12:32.675266 32196 solver.cpp:228] Iteration 2768, loss = 0.0235209
I0403 03:12:32.681659 32196 solver.cpp:244]     Train net output #0: loss = 0.023521 (* 1 = 0.023521 loss)
I0403 03:12:32.858254 32196 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 03:12:44.420658 32196 solver.cpp:228] Iteration 2784, loss = 0.0413622
I0403 03:12:44.426858 32196 solver.cpp:244]     Train net output #0: loss = 0.0413622 (* 1 = 0.0413622 loss)
I0403 03:12:44.614544 32196 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 03:12:56.237184 32196 solver.cpp:228] Iteration 2800, loss = 0.00998286
I0403 03:12:56.243680 32196 solver.cpp:244]     Train net output #0: loss = 0.0099829 (* 1 = 0.0099829 loss)
I0403 03:12:56.389611 32196 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 03:13:07.922648 32196 solver.cpp:228] Iteration 2816, loss = 0.00193933
I0403 03:13:07.927785 32196 solver.cpp:244]     Train net output #0: loss = 0.00193937 (* 1 = 0.00193937 loss)
I0403 03:13:08.154156 32196 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 03:13:19.554312 32196 solver.cpp:228] Iteration 2832, loss = 0.0055868
I0403 03:13:19.560372 32196 solver.cpp:244]     Train net output #0: loss = 0.00558684 (* 1 = 0.00558684 loss)
I0403 03:13:19.751063 32196 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 03:13:31.214118 32196 solver.cpp:228] Iteration 2848, loss = 0.00562757
I0403 03:13:31.220149 32196 solver.cpp:244]     Train net output #0: loss = 0.00562761 (* 1 = 0.00562761 loss)
I0403 03:13:31.396427 32196 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 03:13:42.901242 32196 solver.cpp:228] Iteration 2864, loss = 0.0186335
I0403 03:13:42.907197 32196 solver.cpp:244]     Train net output #0: loss = 0.0186335 (* 1 = 0.0186335 loss)
I0403 03:13:43.083217 32196 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 03:13:54.813650 32196 solver.cpp:228] Iteration 2880, loss = 0.00115126
I0403 03:13:54.820103 32196 solver.cpp:244]     Train net output #0: loss = 0.00115129 (* 1 = 0.00115129 loss)
I0403 03:13:55.011884 32196 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 03:14:06.482134 32196 solver.cpp:228] Iteration 2896, loss = 0.0171147
I0403 03:14:06.488680 32196 solver.cpp:244]     Train net output #0: loss = 0.0171147 (* 1 = 0.0171147 loss)
I0403 03:14:06.661283 32196 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 03:14:18.410229 32196 solver.cpp:228] Iteration 2912, loss = 0.000146817
I0403 03:14:18.415807 32196 solver.cpp:244]     Train net output #0: loss = 0.00014685 (* 1 = 0.00014685 loss)
I0403 03:14:18.576288 32196 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 03:14:27.471904 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2925.caffemodel
I0403 03:14:30.244635 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_2925.solverstate
I0403 03:14:32.130925 32196 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 03:15:21.063053 32196 solver.cpp:404]     Test net output #0: accuracy = 0.98636
I0403 03:15:21.070858 32196 solver.cpp:404]     Test net output #1: loss = 0.0511514 (* 1 = 0.0511514 loss)
I0403 03:15:23.750946 32196 solver.cpp:228] Iteration 2928, loss = 0.0160601
I0403 03:15:23.757786 32196 solver.cpp:244]     Train net output #0: loss = 0.0160602 (* 1 = 0.0160602 loss)
I0403 03:15:23.941882 32196 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 03:15:35.368512 32196 solver.cpp:228] Iteration 2944, loss = 0.0115667
I0403 03:15:35.374697 32196 solver.cpp:244]     Train net output #0: loss = 0.0115668 (* 1 = 0.0115668 loss)
I0403 03:15:35.617141 32196 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 03:15:47.342917 32196 solver.cpp:228] Iteration 2960, loss = 0.00510933
I0403 03:15:47.348870 32196 solver.cpp:244]     Train net output #0: loss = 0.00510936 (* 1 = 0.00510936 loss)
I0403 03:15:47.524004 32196 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 03:15:58.992471 32196 solver.cpp:228] Iteration 2976, loss = 0.0130197
I0403 03:15:58.998601 32196 solver.cpp:244]     Train net output #0: loss = 0.0130197 (* 1 = 0.0130197 loss)
I0403 03:15:59.176163 32196 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 03:16:10.894772 32196 solver.cpp:228] Iteration 2992, loss = 0.000308545
I0403 03:16:10.900221 32196 solver.cpp:244]     Train net output #0: loss = 0.000308576 (* 1 = 0.000308576 loss)
I0403 03:16:11.047255 32196 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 03:16:22.667573 32196 solver.cpp:228] Iteration 3008, loss = 0.00151828
I0403 03:16:22.675873 32196 solver.cpp:244]     Train net output #0: loss = 0.00151831 (* 1 = 0.00151831 loss)
I0403 03:16:22.866592 32196 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 03:16:34.384385 32196 solver.cpp:228] Iteration 3024, loss = 0.000820176
I0403 03:16:34.392273 32196 solver.cpp:244]     Train net output #0: loss = 0.000820207 (* 1 = 0.000820207 loss)
I0403 03:16:34.573820 32196 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:16:46.221415 32196 solver.cpp:228] Iteration 3040, loss = 0.000580354
I0403 03:16:46.226737 32196 solver.cpp:244]     Train net output #0: loss = 0.000580384 (* 1 = 0.000580384 loss)
I0403 03:16:46.416999 32196 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 03:16:57.963695 32196 solver.cpp:228] Iteration 3056, loss = 0.000443366
I0403 03:16:57.969720 32196 solver.cpp:244]     Train net output #0: loss = 0.000443397 (* 1 = 0.000443397 loss)
I0403 03:16:58.153091 32196 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 03:17:09.663172 32196 solver.cpp:228] Iteration 3072, loss = 0.00983723
I0403 03:17:09.669107 32196 solver.cpp:244]     Train net output #0: loss = 0.00983726 (* 1 = 0.00983726 loss)
I0403 03:17:09.843183 32196 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 03:17:21.455329 32196 solver.cpp:228] Iteration 3088, loss = 0.000434559
I0403 03:17:21.461000 32196 solver.cpp:244]     Train net output #0: loss = 0.000434586 (* 1 = 0.000434586 loss)
I0403 03:17:21.594703 32196 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 03:17:33.451715 32196 solver.cpp:228] Iteration 3104, loss = 0.0124595
I0403 03:17:33.459343 32196 solver.cpp:244]     Train net output #0: loss = 0.0124595 (* 1 = 0.0124595 loss)
I0403 03:17:33.635776 32196 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 03:17:44.962721 32196 solver.cpp:228] Iteration 3120, loss = 0.00597398
I0403 03:17:44.971065 32196 solver.cpp:244]     Train net output #0: loss = 0.00597401 (* 1 = 0.00597401 loss)
I0403 03:17:45.144791 32196 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 03:17:56.638757 32196 solver.cpp:228] Iteration 3136, loss = 0.0678455
I0403 03:17:56.645181 32196 solver.cpp:244]     Train net output #0: loss = 0.0678455 (* 1 = 0.0678455 loss)
I0403 03:17:56.820818 32196 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 03:18:08.414875 32196 solver.cpp:228] Iteration 3152, loss = 0.00243859
I0403 03:18:08.421147 32196 solver.cpp:244]     Train net output #0: loss = 0.00243862 (* 1 = 0.00243862 loss)
I0403 03:18:08.566804 32196 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 03:18:20.278566 32196 solver.cpp:228] Iteration 3168, loss = 0.000957333
I0403 03:18:20.285212 32196 solver.cpp:244]     Train net output #0: loss = 0.00095736 (* 1 = 0.00095736 loss)
I0403 03:18:20.456310 32196 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 03:18:32.060101 32196 solver.cpp:228] Iteration 3184, loss = 0.00471731
I0403 03:18:32.066196 32196 solver.cpp:244]     Train net output #0: loss = 0.00471734 (* 1 = 0.00471734 loss)
I0403 03:18:32.222885 32196 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 03:18:43.866271 32196 solver.cpp:228] Iteration 3200, loss = 0.0133946
I0403 03:18:43.872014 32196 solver.cpp:244]     Train net output #0: loss = 0.0133946 (* 1 = 0.0133946 loss)
I0403 03:18:44.056864 32196 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 03:18:55.622705 32196 solver.cpp:228] Iteration 3216, loss = 0.0087373
I0403 03:18:55.629269 32196 solver.cpp:244]     Train net output #0: loss = 0.00873733 (* 1 = 0.00873733 loss)
I0403 03:18:55.832723 32196 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 03:19:07.428721 32196 solver.cpp:228] Iteration 3232, loss = 0.0271434
I0403 03:19:07.435210 32196 solver.cpp:244]     Train net output #0: loss = 0.0271435 (* 1 = 0.0271435 loss)
I0403 03:19:07.616858 32196 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 03:19:19.598345 32196 solver.cpp:228] Iteration 3248, loss = 0.0252079
I0403 03:19:19.605434 32196 solver.cpp:244]     Train net output #0: loss = 0.0252079 (* 1 = 0.0252079 loss)
I0403 03:19:19.780267 32196 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 03:19:20.511345 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3250.caffemodel
I0403 03:19:23.271775 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3250.solverstate
I0403 03:19:25.169795 32196 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 03:20:14.099666 32196 solver.cpp:404]     Test net output #0: accuracy = 0.9853
I0403 03:20:14.106364 32196 solver.cpp:404]     Test net output #1: loss = 0.0524653 (* 1 = 0.0524653 loss)
I0403 03:20:24.915148 32196 solver.cpp:228] Iteration 3264, loss = 0.0632573
I0403 03:20:24.921457 32196 solver.cpp:244]     Train net output #0: loss = 0.0632573 (* 1 = 0.0632573 loss)
I0403 03:20:25.086963 32196 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 03:20:36.662051 32196 solver.cpp:228] Iteration 3280, loss = 0.00121784
I0403 03:20:36.667521 32196 solver.cpp:244]     Train net output #0: loss = 0.00121786 (* 1 = 0.00121786 loss)
I0403 03:20:36.859050 32196 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:20:48.392071 32196 solver.cpp:228] Iteration 3296, loss = 0.00399847
I0403 03:20:48.398658 32196 solver.cpp:244]     Train net output #0: loss = 0.00399849 (* 1 = 0.00399849 loss)
I0403 03:20:48.574494 32196 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 03:21:00.165416 32196 solver.cpp:228] Iteration 3312, loss = 0.0120469
I0403 03:21:00.170765 32196 solver.cpp:244]     Train net output #0: loss = 0.0120469 (* 1 = 0.0120469 loss)
I0403 03:21:00.361615 32196 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 03:21:11.837399 32196 solver.cpp:228] Iteration 3328, loss = 0.0013074
I0403 03:21:11.844066 32196 solver.cpp:244]     Train net output #0: loss = 0.00130742 (* 1 = 0.00130742 loss)
I0403 03:21:12.044641 32196 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:21:23.635053 32196 solver.cpp:228] Iteration 3344, loss = 0.000431282
I0403 03:21:23.641098 32196 solver.cpp:244]     Train net output #0: loss = 0.000431305 (* 1 = 0.000431305 loss)
I0403 03:21:23.829728 32196 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 03:21:35.389508 32196 solver.cpp:228] Iteration 3360, loss = 0.00210287
I0403 03:21:35.410506 32196 solver.cpp:244]     Train net output #0: loss = 0.00210289 (* 1 = 0.00210289 loss)
I0403 03:21:35.592550 32196 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:21:47.214730 32196 solver.cpp:228] Iteration 3376, loss = 0.00113852
I0403 03:21:47.219904 32196 solver.cpp:244]     Train net output #0: loss = 0.00113855 (* 1 = 0.00113855 loss)
I0403 03:21:47.355732 32196 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 03:21:59.298686 32196 solver.cpp:228] Iteration 3392, loss = 0.000313555
I0403 03:21:59.304085 32196 solver.cpp:244]     Train net output #0: loss = 0.000313582 (* 1 = 0.000313582 loss)
I0403 03:21:59.497534 32196 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 03:22:10.913209 32196 solver.cpp:228] Iteration 3408, loss = 0.00320031
I0403 03:22:10.919877 32196 solver.cpp:244]     Train net output #0: loss = 0.00320034 (* 1 = 0.00320034 loss)
I0403 03:22:11.108700 32196 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 03:22:22.629312 32196 solver.cpp:228] Iteration 3424, loss = 0.00202708
I0403 03:22:22.634043 32196 solver.cpp:244]     Train net output #0: loss = 0.00202711 (* 1 = 0.00202711 loss)
I0403 03:22:22.810040 32196 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 03:22:34.297569 32196 solver.cpp:228] Iteration 3440, loss = 0.010643
I0403 03:22:34.308043 32196 solver.cpp:244]     Train net output #0: loss = 0.010643 (* 1 = 0.010643 loss)
I0403 03:22:34.501929 32196 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:22:45.947933 32196 solver.cpp:228] Iteration 3456, loss = 0.000778035
I0403 03:22:45.970962 32196 solver.cpp:244]     Train net output #0: loss = 0.000778062 (* 1 = 0.000778062 loss)
I0403 03:22:46.129760 32196 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 03:22:57.581490 32196 solver.cpp:228] Iteration 3472, loss = 0.00306667
I0403 03:22:57.587155 32196 solver.cpp:244]     Train net output #0: loss = 0.0030667 (* 1 = 0.0030667 loss)
I0403 03:22:57.811030 32196 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 03:23:09.311627 32196 solver.cpp:228] Iteration 3488, loss = 0.00341995
I0403 03:23:09.318030 32196 solver.cpp:244]     Train net output #0: loss = 0.00341997 (* 1 = 0.00341997 loss)
I0403 03:23:09.505059 32196 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 03:23:20.984947 32196 solver.cpp:228] Iteration 3504, loss = 0.00335629
I0403 03:23:20.993196 32196 solver.cpp:244]     Train net output #0: loss = 0.00335632 (* 1 = 0.00335632 loss)
I0403 03:23:21.206764 32196 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 03:23:32.711752 32196 solver.cpp:228] Iteration 3520, loss = 0.00100317
I0403 03:23:32.717955 32196 solver.cpp:244]     Train net output #0: loss = 0.0010032 (* 1 = 0.0010032 loss)
I0403 03:23:32.894467 32196 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:23:44.481885 32196 solver.cpp:228] Iteration 3536, loss = 0.000667478
I0403 03:23:44.488489 32196 solver.cpp:244]     Train net output #0: loss = 0.000667506 (* 1 = 0.000667506 loss)
I0403 03:23:44.672291 32196 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:23:56.332521 32196 solver.cpp:228] Iteration 3552, loss = 0.000501987
I0403 03:23:56.338191 32196 solver.cpp:244]     Train net output #0: loss = 0.000502016 (* 1 = 0.000502016 loss)
I0403 03:23:56.502058 32196 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 03:24:07.987939 32196 solver.cpp:228] Iteration 3568, loss = 0.000100338
I0403 03:24:07.994179 32196 solver.cpp:244]     Train net output #0: loss = 0.000100367 (* 1 = 0.000100367 loss)
I0403 03:24:08.189831 32196 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 03:24:12.575672 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3575.caffemodel
I0403 03:24:15.288069 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3575.solverstate
I0403 03:24:17.192240 32196 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 03:25:06.107779 32196 solver.cpp:404]     Test net output #0: accuracy = 0.989493
I0403 03:25:06.113909 32196 solver.cpp:404]     Test net output #1: loss = 0.0373319 (* 1 = 0.0373319 loss)
I0403 03:25:13.267412 32196 solver.cpp:228] Iteration 3584, loss = 0.00934223
I0403 03:25:13.273516 32196 solver.cpp:244]     Train net output #0: loss = 0.00934226 (* 1 = 0.00934226 loss)
I0403 03:25:13.424242 32196 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 03:25:24.910994 32196 solver.cpp:228] Iteration 3600, loss = 0.000768644
I0403 03:25:24.919366 32196 solver.cpp:244]     Train net output #0: loss = 0.000768674 (* 1 = 0.000768674 loss)
I0403 03:25:25.154791 32196 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:25:36.790846 32196 solver.cpp:228] Iteration 3616, loss = 0.00105573
I0403 03:25:36.796478 32196 solver.cpp:244]     Train net output #0: loss = 0.00105576 (* 1 = 0.00105576 loss)
I0403 03:25:37.004329 32196 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 03:25:48.505977 32196 solver.cpp:228] Iteration 3632, loss = 0.00024747
I0403 03:25:48.511721 32196 solver.cpp:244]     Train net output #0: loss = 0.0002475 (* 1 = 0.0002475 loss)
I0403 03:25:48.720402 32196 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 03:26:00.317735 32196 solver.cpp:228] Iteration 3648, loss = 0.00252988
I0403 03:26:00.323914 32196 solver.cpp:244]     Train net output #0: loss = 0.00252991 (* 1 = 0.00252991 loss)
I0403 03:26:00.514190 32196 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 03:26:12.049576 32196 solver.cpp:228] Iteration 3664, loss = 0.0026692
I0403 03:26:12.056557 32196 solver.cpp:244]     Train net output #0: loss = 0.00266923 (* 1 = 0.00266923 loss)
I0403 03:26:12.274351 32196 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 03:26:23.784674 32196 solver.cpp:228] Iteration 3680, loss = 0.0143301
I0403 03:26:23.790371 32196 solver.cpp:244]     Train net output #0: loss = 0.0143302 (* 1 = 0.0143302 loss)
I0403 03:26:23.987301 32196 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:26:35.378736 32196 solver.cpp:228] Iteration 3696, loss = 0.00162522
I0403 03:26:35.383973 32196 solver.cpp:244]     Train net output #0: loss = 0.00162524 (* 1 = 0.00162524 loss)
I0403 03:26:35.586318 32196 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 03:26:47.153704 32196 solver.cpp:228] Iteration 3712, loss = 0.0138127
I0403 03:26:47.158691 32196 solver.cpp:244]     Train net output #0: loss = 0.0138128 (* 1 = 0.0138128 loss)
I0403 03:26:47.338295 32196 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 03:26:58.845072 32196 solver.cpp:228] Iteration 3728, loss = 0.000629308
I0403 03:26:58.850854 32196 solver.cpp:244]     Train net output #0: loss = 0.000629334 (* 1 = 0.000629334 loss)
I0403 03:26:59.096887 32196 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 03:27:10.502332 32196 solver.cpp:228] Iteration 3744, loss = 0.0011116
I0403 03:27:10.508770 32196 solver.cpp:244]     Train net output #0: loss = 0.00111162 (* 1 = 0.00111162 loss)
I0403 03:27:10.737139 32196 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:27:22.144309 32196 solver.cpp:228] Iteration 3760, loss = 0.00559347
I0403 03:27:22.150948 32196 solver.cpp:244]     Train net output #0: loss = 0.0055935 (* 1 = 0.0055935 loss)
I0403 03:27:22.367451 32196 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:27:33.780344 32196 solver.cpp:228] Iteration 3776, loss = 0.00140829
I0403 03:27:33.788365 32196 solver.cpp:244]     Train net output #0: loss = 0.00140832 (* 1 = 0.00140832 loss)
I0403 03:27:33.971314 32196 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 03:27:45.593804 32196 solver.cpp:228] Iteration 3792, loss = 0.00139249
I0403 03:27:45.600024 32196 solver.cpp:244]     Train net output #0: loss = 0.00139252 (* 1 = 0.00139252 loss)
I0403 03:27:45.746403 32196 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 03:27:57.240486 32196 solver.cpp:228] Iteration 3808, loss = 0.0020497
I0403 03:27:57.246510 32196 solver.cpp:244]     Train net output #0: loss = 0.00204973 (* 1 = 0.00204973 loss)
I0403 03:27:57.420845 32196 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 03:28:09.093449 32196 solver.cpp:228] Iteration 3824, loss = 0.000989041
I0403 03:28:09.099890 32196 solver.cpp:244]     Train net output #0: loss = 0.000989071 (* 1 = 0.000989071 loss)
I0403 03:28:09.275446 32196 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 03:28:20.842429 32196 solver.cpp:228] Iteration 3840, loss = 0.000221259
I0403 03:28:20.847641 32196 solver.cpp:244]     Train net output #0: loss = 0.000221288 (* 1 = 0.000221288 loss)
I0403 03:28:21.024591 32196 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:28:32.644443 32196 solver.cpp:228] Iteration 3856, loss = 0.00203819
I0403 03:28:32.650956 32196 solver.cpp:244]     Train net output #0: loss = 0.00203822 (* 1 = 0.00203822 loss)
I0403 03:28:32.835640 32196 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 03:28:44.287071 32196 solver.cpp:228] Iteration 3872, loss = 0.000805574
I0403 03:28:44.293038 32196 solver.cpp:244]     Train net output #0: loss = 0.000805605 (* 1 = 0.000805605 loss)
I0403 03:28:44.517210 32196 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 03:28:56.018681 32196 solver.cpp:228] Iteration 3888, loss = 0.00037694
I0403 03:28:56.025668 32196 solver.cpp:244]     Train net output #0: loss = 0.00037697 (* 1 = 0.00037697 loss)
I0403 03:28:56.201338 32196 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 03:29:04.313894 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3900.caffemodel
I0403 03:29:07.101017 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_3900.solverstate
I0403 03:29:08.892982 32196 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 03:29:57.846118 32196 solver.cpp:404]     Test net output #0: accuracy = 0.989908
I0403 03:29:57.853610 32196 solver.cpp:404]     Test net output #1: loss = 0.0358334 (* 1 = 0.0358334 loss)
I0403 03:30:01.308912 32196 solver.cpp:228] Iteration 3904, loss = 0.00357294
I0403 03:30:01.344785 32196 solver.cpp:244]     Train net output #0: loss = 0.00357297 (* 1 = 0.00357297 loss)
I0403 03:30:01.533360 32196 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 03:30:12.958091 32196 solver.cpp:228] Iteration 3920, loss = 0.000255574
I0403 03:30:12.964759 32196 solver.cpp:244]     Train net output #0: loss = 0.000255603 (* 1 = 0.000255603 loss)
I0403 03:30:13.175065 32196 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:30:24.707800 32196 solver.cpp:228] Iteration 3936, loss = 0.0009657
I0403 03:30:24.713804 32196 solver.cpp:244]     Train net output #0: loss = 0.000965729 (* 1 = 0.000965729 loss)
I0403 03:30:24.882719 32196 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 03:30:36.565958 32196 solver.cpp:228] Iteration 3952, loss = 0.0315654
I0403 03:30:36.574440 32196 solver.cpp:244]     Train net output #0: loss = 0.0315655 (* 1 = 0.0315655 loss)
I0403 03:30:36.746896 32196 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:30:48.177857 32196 solver.cpp:228] Iteration 3968, loss = 0.000603871
I0403 03:30:48.183517 32196 solver.cpp:244]     Train net output #0: loss = 0.000603901 (* 1 = 0.000603901 loss)
I0403 03:30:48.350227 32196 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 03:31:00.090987 32196 solver.cpp:228] Iteration 3984, loss = 0.00037943
I0403 03:31:00.097844 32196 solver.cpp:244]     Train net output #0: loss = 0.00037946 (* 1 = 0.00037946 loss)
I0403 03:31:00.290104 32196 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 03:31:12.038064 32196 solver.cpp:228] Iteration 4000, loss = 0.00194142
I0403 03:31:12.043809 32196 solver.cpp:244]     Train net output #0: loss = 0.00194145 (* 1 = 0.00194145 loss)
I0403 03:31:12.220175 32196 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:31:23.829409 32196 solver.cpp:228] Iteration 4016, loss = 0.000332154
I0403 03:31:23.836010 32196 solver.cpp:244]     Train net output #0: loss = 0.000332183 (* 1 = 0.000332183 loss)
I0403 03:31:24.034426 32196 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 03:31:35.603622 32196 solver.cpp:228] Iteration 4032, loss = 0.00120808
I0403 03:31:35.611270 32196 solver.cpp:244]     Train net output #0: loss = 0.00120811 (* 1 = 0.00120811 loss)
I0403 03:31:35.786731 32196 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 03:31:47.164471 32196 solver.cpp:228] Iteration 4048, loss = 0.000358212
I0403 03:31:47.170539 32196 solver.cpp:244]     Train net output #0: loss = 0.000358242 (* 1 = 0.000358242 loss)
I0403 03:31:47.350325 32196 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 03:31:58.832896 32196 solver.cpp:228] Iteration 4064, loss = 5.96015e-05
I0403 03:31:58.838812 32196 solver.cpp:244]     Train net output #0: loss = 5.96309e-05 (* 1 = 5.96309e-05 loss)
I0403 03:31:59.066469 32196 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 03:32:10.721226 32196 solver.cpp:228] Iteration 4080, loss = 0.000115708
I0403 03:32:10.728540 32196 solver.cpp:244]     Train net output #0: loss = 0.000115736 (* 1 = 0.000115736 loss)
I0403 03:32:10.887347 32196 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:32:22.407924 32196 solver.cpp:228] Iteration 4096, loss = 7.12977e-05
I0403 03:32:22.414558 32196 solver.cpp:244]     Train net output #0: loss = 7.13266e-05 (* 1 = 7.13266e-05 loss)
I0403 03:32:22.628170 32196 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 03:32:34.428061 32196 solver.cpp:228] Iteration 4112, loss = 0.00532036
I0403 03:32:34.434397 32196 solver.cpp:244]     Train net output #0: loss = 0.00532038 (* 1 = 0.00532038 loss)
I0403 03:32:34.602404 32196 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 03:32:46.083395 32196 solver.cpp:228] Iteration 4128, loss = 0.00039203
I0403 03:32:46.089797 32196 solver.cpp:244]     Train net output #0: loss = 0.00039206 (* 1 = 0.00039206 loss)
I0403 03:32:46.263447 32196 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 03:32:57.841758 32196 solver.cpp:228] Iteration 4144, loss = 0.00135086
I0403 03:32:57.848492 32196 solver.cpp:244]     Train net output #0: loss = 0.00135089 (* 1 = 0.00135089 loss)
I0403 03:32:58.051203 32196 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 03:33:09.681840 32196 solver.cpp:228] Iteration 4160, loss = 0.000585401
I0403 03:33:09.688362 32196 solver.cpp:244]     Train net output #0: loss = 0.000585431 (* 1 = 0.000585431 loss)
I0403 03:33:09.853309 32196 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:33:21.548861 32196 solver.cpp:228] Iteration 4176, loss = 0.000481993
I0403 03:33:21.557160 32196 solver.cpp:244]     Train net output #0: loss = 0.000482023 (* 1 = 0.000482023 loss)
I0403 03:33:21.678871 32196 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 03:33:33.246390 32196 solver.cpp:228] Iteration 4192, loss = 0.000321793
I0403 03:33:33.256873 32196 solver.cpp:244]     Train net output #0: loss = 0.000321823 (* 1 = 0.000321823 loss)
I0403 03:33:33.458492 32196 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 03:33:45.055552 32196 solver.cpp:228] Iteration 4208, loss = 0.000365003
I0403 03:33:45.060681 32196 solver.cpp:244]     Train net output #0: loss = 0.000365032 (* 1 = 0.000365032 loss)
I0403 03:33:45.222782 32196 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 03:33:56.851127 32196 solver.cpp:228] Iteration 4224, loss = 0.000579575
I0403 03:33:56.858728 32196 solver.cpp:244]     Train net output #0: loss = 0.000579605 (* 1 = 0.000579605 loss)
I0403 03:33:57.063596 32196 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 03:33:57.063828 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4225.caffemodel
I0403 03:33:59.826503 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4225.solverstate
I0403 03:34:01.701964 32196 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 03:34:50.672291 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990415
I0403 03:34:50.672588 32196 solver.cpp:404]     Test net output #1: loss = 0.0350532 (* 1 = 0.0350532 loss)
I0403 03:35:02.165838 32196 solver.cpp:228] Iteration 4240, loss = 0.000195144
I0403 03:35:02.165938 32196 solver.cpp:244]     Train net output #0: loss = 0.000195175 (* 1 = 0.000195175 loss)
I0403 03:35:02.316493 32196 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:35:13.839896 32196 solver.cpp:228] Iteration 4256, loss = 0.000429969
I0403 03:35:13.840013 32196 solver.cpp:244]     Train net output #0: loss = 0.00043 (* 1 = 0.00043 loss)
I0403 03:35:14.117108 32196 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 03:35:25.523547 32196 solver.cpp:228] Iteration 4272, loss = 0.00107748
I0403 03:35:25.523912 32196 solver.cpp:244]     Train net output #0: loss = 0.00107751 (* 1 = 0.00107751 loss)
I0403 03:35:25.728963 32196 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 03:35:37.222589 32196 solver.cpp:228] Iteration 4288, loss = 0.000772218
I0403 03:35:37.223574 32196 solver.cpp:244]     Train net output #0: loss = 0.000772249 (* 1 = 0.000772249 loss)
I0403 03:35:37.431838 32196 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 03:35:48.996935 32196 solver.cpp:228] Iteration 4304, loss = 5.67213e-05
I0403 03:35:48.997045 32196 solver.cpp:244]     Train net output #0: loss = 5.67515e-05 (* 1 = 5.67515e-05 loss)
I0403 03:35:49.192898 32196 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 03:36:00.959566 32196 solver.cpp:228] Iteration 4320, loss = 0.000478817
I0403 03:36:00.959905 32196 solver.cpp:244]     Train net output #0: loss = 0.000478847 (* 1 = 0.000478847 loss)
I0403 03:36:01.167181 32196 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:36:12.774977 32196 solver.cpp:228] Iteration 4336, loss = 0.00677129
I0403 03:36:12.775068 32196 solver.cpp:244]     Train net output #0: loss = 0.00677132 (* 1 = 0.00677132 loss)
I0403 03:36:13.047245 32196 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 03:36:24.554002 32196 solver.cpp:228] Iteration 4352, loss = 0.000396423
I0403 03:36:24.554113 32196 solver.cpp:244]     Train net output #0: loss = 0.000396453 (* 1 = 0.000396453 loss)
I0403 03:36:24.737030 32196 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 03:36:36.170830 32196 solver.cpp:228] Iteration 4368, loss = 0.00909011
I0403 03:36:36.171147 32196 solver.cpp:244]     Train net output #0: loss = 0.00909014 (* 1 = 0.00909014 loss)
I0403 03:36:36.350664 32196 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:36:47.844074 32196 solver.cpp:228] Iteration 4384, loss = 0.000323169
I0403 03:36:47.844192 32196 solver.cpp:244]     Train net output #0: loss = 0.000323198 (* 1 = 0.000323198 loss)
I0403 03:36:48.073833 32196 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 03:36:59.687877 32196 solver.cpp:228] Iteration 4400, loss = 0.01027
I0403 03:36:59.687979 32196 solver.cpp:244]     Train net output #0: loss = 0.0102701 (* 1 = 0.0102701 loss)
I0403 03:36:59.806315 32196 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 03:37:11.304991 32196 solver.cpp:228] Iteration 4416, loss = 0.00721626
I0403 03:37:11.305318 32196 solver.cpp:244]     Train net output #0: loss = 0.00721629 (* 1 = 0.00721629 loss)
I0403 03:37:11.523351 32196 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 03:37:22.939059 32196 solver.cpp:228] Iteration 4432, loss = 0.000102084
I0403 03:37:22.939175 32196 solver.cpp:244]     Train net output #0: loss = 0.000102114 (* 1 = 0.000102114 loss)
I0403 03:37:23.126957 32196 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 03:37:34.902819 32196 solver.cpp:228] Iteration 4448, loss = 0.00112578
I0403 03:37:34.902928 32196 solver.cpp:244]     Train net output #0: loss = 0.00112581 (* 1 = 0.00112581 loss)
I0403 03:37:35.090700 32196 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 03:37:46.724964 32196 solver.cpp:228] Iteration 4464, loss = 0.00123698
I0403 03:37:46.725261 32196 solver.cpp:244]     Train net output #0: loss = 0.00123701 (* 1 = 0.00123701 loss)
I0403 03:37:46.894171 32196 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 03:37:58.432972 32196 solver.cpp:228] Iteration 4480, loss = 0.000428105
I0403 03:37:58.433084 32196 solver.cpp:244]     Train net output #0: loss = 0.000428137 (* 1 = 0.000428137 loss)
I0403 03:37:58.656605 32196 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 03:38:10.139807 32196 solver.cpp:228] Iteration 4496, loss = 0.000324191
I0403 03:38:10.139920 32196 solver.cpp:244]     Train net output #0: loss = 0.000324223 (* 1 = 0.000324223 loss)
I0403 03:38:10.339148 32196 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 03:38:21.802026 32196 solver.cpp:228] Iteration 4512, loss = 2.25861e-05
I0403 03:38:21.802296 32196 solver.cpp:244]     Train net output #0: loss = 2.2619e-05 (* 1 = 2.2619e-05 loss)
I0403 03:38:22.010829 32196 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 03:38:33.781829 32196 solver.cpp:228] Iteration 4528, loss = 0.013551
I0403 03:38:33.781925 32196 solver.cpp:244]     Train net output #0: loss = 0.013551 (* 1 = 0.013551 loss)
I0403 03:38:33.961307 32196 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 03:38:45.514979 32196 solver.cpp:228] Iteration 4544, loss = 0.0024008
I0403 03:38:45.525662 32196 solver.cpp:244]     Train net output #0: loss = 0.00240083 (* 1 = 0.00240083 loss)
I0403 03:38:45.711639 32196 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 03:38:49.412924 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4550.caffemodel
I0403 03:38:52.157980 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4550.solverstate
I0403 03:38:54.052098 32196 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 03:39:42.985908 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990415
I0403 03:39:42.986204 32196 solver.cpp:404]     Test net output #1: loss = 0.0357355 (* 1 = 0.0357355 loss)
I0403 03:39:51.006466 32196 solver.cpp:228] Iteration 4560, loss = 0.0017348
I0403 03:39:51.006579 32196 solver.cpp:244]     Train net output #0: loss = 0.00173483 (* 1 = 0.00173483 loss)
I0403 03:39:51.228257 32196 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 03:40:02.779508 32196 solver.cpp:228] Iteration 4576, loss = 0.000382279
I0403 03:40:02.779608 32196 solver.cpp:244]     Train net output #0: loss = 0.000382314 (* 1 = 0.000382314 loss)
I0403 03:40:02.941144 32196 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:40:14.497645 32196 solver.cpp:228] Iteration 4592, loss = 0.00566816
I0403 03:40:14.497958 32196 solver.cpp:244]     Train net output #0: loss = 0.0056682 (* 1 = 0.0056682 loss)
I0403 03:40:14.680367 32196 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 03:40:26.287031 32196 solver.cpp:228] Iteration 4608, loss = 0.000103069
I0403 03:40:26.287140 32196 solver.cpp:244]     Train net output #0: loss = 0.000103103 (* 1 = 0.000103103 loss)
I0403 03:40:26.462841 32196 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 03:40:38.151880 32196 solver.cpp:228] Iteration 4624, loss = 0.000750779
I0403 03:40:38.151989 32196 solver.cpp:244]     Train net output #0: loss = 0.000750813 (* 1 = 0.000750813 loss)
I0403 03:40:38.357702 32196 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 03:40:49.867914 32196 solver.cpp:228] Iteration 4640, loss = 0.0304888
I0403 03:40:49.868202 32196 solver.cpp:244]     Train net output #0: loss = 0.0304888 (* 1 = 0.0304888 loss)
I0403 03:40:50.057243 32196 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 03:41:01.636920 32196 solver.cpp:228] Iteration 4656, loss = 0.00125506
I0403 03:41:01.637032 32196 solver.cpp:244]     Train net output #0: loss = 0.0012551 (* 1 = 0.0012551 loss)
I0403 03:41:01.867732 32196 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 03:41:13.367514 32196 solver.cpp:228] Iteration 4672, loss = 0.000280253
I0403 03:41:13.367626 32196 solver.cpp:244]     Train net output #0: loss = 0.000280287 (* 1 = 0.000280287 loss)
I0403 03:41:13.551339 32196 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 03:41:25.159555 32196 solver.cpp:228] Iteration 4688, loss = 0.00318519
I0403 03:41:25.159883 32196 solver.cpp:244]     Train net output #0: loss = 0.00318523 (* 1 = 0.00318523 loss)
I0403 03:41:25.350846 32196 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 03:41:36.838984 32196 solver.cpp:228] Iteration 4704, loss = 0.000129307
I0403 03:41:36.839102 32196 solver.cpp:244]     Train net output #0: loss = 0.000129342 (* 1 = 0.000129342 loss)
I0403 03:41:37.056985 32196 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:41:48.520040 32196 solver.cpp:228] Iteration 4720, loss = 0.000257467
I0403 03:41:48.520138 32196 solver.cpp:244]     Train net output #0: loss = 0.000257503 (* 1 = 0.000257503 loss)
I0403 03:41:48.717998 32196 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 03:42:00.200515 32196 solver.cpp:228] Iteration 4736, loss = 0.000440894
I0403 03:42:00.200867 32196 solver.cpp:244]     Train net output #0: loss = 0.000440929 (* 1 = 0.000440929 loss)
I0403 03:42:00.383821 32196 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 03:42:12.039333 32196 solver.cpp:228] Iteration 4752, loss = 0.00187718
I0403 03:42:12.039443 32196 solver.cpp:244]     Train net output #0: loss = 0.00187722 (* 1 = 0.00187722 loss)
I0403 03:42:12.223762 32196 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 03:42:23.660904 32196 solver.cpp:228] Iteration 4768, loss = 0.000691146
I0403 03:42:23.661005 32196 solver.cpp:244]     Train net output #0: loss = 0.00069118 (* 1 = 0.00069118 loss)
I0403 03:42:23.817544 32196 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 03:42:35.722719 32196 solver.cpp:228] Iteration 4784, loss = 0.0191795
I0403 03:42:35.723002 32196 solver.cpp:244]     Train net output #0: loss = 0.0191795 (* 1 = 0.0191795 loss)
I0403 03:42:35.881294 32196 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:42:47.553289 32196 solver.cpp:228] Iteration 4800, loss = 7.22576e-05
I0403 03:42:47.553402 32196 solver.cpp:244]     Train net output #0: loss = 7.22919e-05 (* 1 = 7.22919e-05 loss)
I0403 03:42:47.736023 32196 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 03:42:59.141141 32196 solver.cpp:228] Iteration 4816, loss = 0.000167069
I0403 03:42:59.141253 32196 solver.cpp:244]     Train net output #0: loss = 0.000167103 (* 1 = 0.000167103 loss)
I0403 03:42:59.323783 32196 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 03:43:10.978386 32196 solver.cpp:228] Iteration 4832, loss = 0.00132076
I0403 03:43:10.978648 32196 solver.cpp:244]     Train net output #0: loss = 0.00132079 (* 1 = 0.00132079 loss)
I0403 03:43:11.151921 32196 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 03:43:22.722679 32196 solver.cpp:228] Iteration 4848, loss = 0.000438243
I0403 03:43:22.722779 32196 solver.cpp:244]     Train net output #0: loss = 0.000438277 (* 1 = 0.000438277 loss)
I0403 03:43:22.872004 32196 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 03:43:34.462061 32196 solver.cpp:228] Iteration 4864, loss = 0.000962574
I0403 03:43:34.462173 32196 solver.cpp:244]     Train net output #0: loss = 0.000962608 (* 1 = 0.000962608 loss)
I0403 03:43:34.624755 32196 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 03:43:42.014480 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4875.caffemodel
I0403 03:43:44.767120 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_4875.solverstate
I0403 03:43:46.624830 32196 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 03:44:35.547622 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990323
I0403 03:44:35.547982 32196 solver.cpp:404]     Test net output #1: loss = 0.0360106 (* 1 = 0.0360106 loss)
I0403 03:44:39.829269 32196 solver.cpp:228] Iteration 4880, loss = 0.000215907
I0403 03:44:39.829368 32196 solver.cpp:244]     Train net output #0: loss = 0.000215941 (* 1 = 0.000215941 loss)
I0403 03:44:40.017225 32196 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 03:44:51.417667 32196 solver.cpp:228] Iteration 4896, loss = 0.000332552
I0403 03:44:51.417783 32196 solver.cpp:244]     Train net output #0: loss = 0.000332585 (* 1 = 0.000332585 loss)
I0403 03:44:51.621762 32196 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 03:45:03.190217 32196 solver.cpp:228] Iteration 4912, loss = 0.00157005
I0403 03:45:03.190325 32196 solver.cpp:244]     Train net output #0: loss = 0.00157008 (* 1 = 0.00157008 loss)
I0403 03:45:03.376229 32196 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 03:45:14.759277 32196 solver.cpp:228] Iteration 4928, loss = 0.000471477
I0403 03:45:14.759584 32196 solver.cpp:244]     Train net output #0: loss = 0.000471508 (* 1 = 0.000471508 loss)
I0403 03:45:14.949259 32196 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 03:45:26.547009 32196 solver.cpp:228] Iteration 4944, loss = 0.000716913
I0403 03:45:26.548019 32196 solver.cpp:244]     Train net output #0: loss = 0.000716944 (* 1 = 0.000716944 loss)
I0403 03:45:26.733153 32196 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 03:45:38.513403 32196 solver.cpp:228] Iteration 4960, loss = 0.00210313
I0403 03:45:38.513515 32196 solver.cpp:244]     Train net output #0: loss = 0.00210316 (* 1 = 0.00210316 loss)
I0403 03:45:38.697659 32196 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 03:45:50.133774 32196 solver.cpp:228] Iteration 4976, loss = 0.00118272
I0403 03:45:50.134130 32196 solver.cpp:244]     Train net output #0: loss = 0.00118275 (* 1 = 0.00118275 loss)
I0403 03:45:50.329674 32196 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 03:46:01.801336 32196 solver.cpp:228] Iteration 4992, loss = 0.00019782
I0403 03:46:01.801434 32196 solver.cpp:244]     Train net output #0: loss = 0.00019785 (* 1 = 0.00019785 loss)
I0403 03:46:01.983089 32196 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:46:13.424572 32196 solver.cpp:228] Iteration 5008, loss = 0.000763038
I0403 03:46:13.424690 32196 solver.cpp:244]     Train net output #0: loss = 0.000763066 (* 1 = 0.000763066 loss)
I0403 03:46:13.640106 32196 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 03:46:25.243175 32196 solver.cpp:228] Iteration 5024, loss = 0.000299168
I0403 03:46:25.243495 32196 solver.cpp:244]     Train net output #0: loss = 0.000299197 (* 1 = 0.000299197 loss)
I0403 03:46:25.437706 32196 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 03:46:37.051524 32196 solver.cpp:228] Iteration 5040, loss = 0.000176265
I0403 03:46:37.051625 32196 solver.cpp:244]     Train net output #0: loss = 0.000176294 (* 1 = 0.000176294 loss)
I0403 03:46:37.227354 32196 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:46:48.808564 32196 solver.cpp:228] Iteration 5056, loss = 0.00902418
I0403 03:46:48.808672 32196 solver.cpp:244]     Train net output #0: loss = 0.00902421 (* 1 = 0.00902421 loss)
I0403 03:46:49.009258 32196 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 03:47:00.426924 32196 solver.cpp:228] Iteration 5072, loss = 9.32674e-05
I0403 03:47:00.427237 32196 solver.cpp:244]     Train net output #0: loss = 9.32972e-05 (* 1 = 9.32972e-05 loss)
I0403 03:47:00.620446 32196 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 03:47:12.175745 32196 solver.cpp:228] Iteration 5088, loss = 0.00139678
I0403 03:47:12.175858 32196 solver.cpp:244]     Train net output #0: loss = 0.00139681 (* 1 = 0.00139681 loss)
I0403 03:47:12.358817 32196 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 03:47:24.003384 32196 solver.cpp:228] Iteration 5104, loss = 0.00111899
I0403 03:47:24.003509 32196 solver.cpp:244]     Train net output #0: loss = 0.00111902 (* 1 = 0.00111902 loss)
I0403 03:47:24.214262 32196 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 03:47:35.721719 32196 solver.cpp:228] Iteration 5120, loss = 0.0131886
I0403 03:47:35.722029 32196 solver.cpp:244]     Train net output #0: loss = 0.0131887 (* 1 = 0.0131887 loss)
I0403 03:47:35.922077 32196 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 03:47:47.458524 32196 solver.cpp:228] Iteration 5136, loss = 0.000313861
I0403 03:47:47.458636 32196 solver.cpp:244]     Train net output #0: loss = 0.00031389 (* 1 = 0.00031389 loss)
I0403 03:47:47.672579 32196 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 03:47:59.150773 32196 solver.cpp:228] Iteration 5152, loss = 3.27732e-05
I0403 03:47:59.150892 32196 solver.cpp:244]     Train net output #0: loss = 3.2802e-05 (* 1 = 3.2802e-05 loss)
I0403 03:47:59.332846 32196 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 03:48:10.901836 32196 solver.cpp:228] Iteration 5168, loss = 0.000277982
I0403 03:48:10.902160 32196 solver.cpp:244]     Train net output #0: loss = 0.000278011 (* 1 = 0.000278011 loss)
I0403 03:48:11.113881 32196 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 03:48:22.803809 32196 solver.cpp:228] Iteration 5184, loss = 0.000539521
I0403 03:48:22.803920 32196 solver.cpp:244]     Train net output #0: loss = 0.00053955 (* 1 = 0.00053955 loss)
I0403 03:48:23.027389 32196 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 03:48:34.025774 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5200.caffemodel
I0403 03:48:36.739153 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5200.solverstate
I0403 03:48:38.537714 32196 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 03:49:27.475266 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990416
I0403 03:49:27.475608 32196 solver.cpp:404]     Test net output #1: loss = 0.0358214 (* 1 = 0.0358214 loss)
I0403 03:49:27.983146 32196 solver.cpp:228] Iteration 5200, loss = 0.00379436
I0403 03:49:27.983223 32196 solver.cpp:244]     Train net output #0: loss = 0.00379438 (* 1 = 0.00379438 loss)
I0403 03:49:28.155953 32196 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:49:39.693362 32196 solver.cpp:228] Iteration 5216, loss = 0.0020805
I0403 03:49:39.693475 32196 solver.cpp:244]     Train net output #0: loss = 0.00208053 (* 1 = 0.00208053 loss)
I0403 03:49:39.872691 32196 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 03:49:51.512778 32196 solver.cpp:228] Iteration 5232, loss = 0.000122843
I0403 03:49:51.512892 32196 solver.cpp:244]     Train net output #0: loss = 0.000122871 (* 1 = 0.000122871 loss)
I0403 03:49:51.722110 32196 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 03:50:03.141120 32196 solver.cpp:228] Iteration 5248, loss = 0.000401008
I0403 03:50:03.141450 32196 solver.cpp:244]     Train net output #0: loss = 0.000401036 (* 1 = 0.000401036 loss)
I0403 03:50:03.343314 32196 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 03:50:14.798877 32196 solver.cpp:228] Iteration 5264, loss = 0.00375287
I0403 03:50:14.798987 32196 solver.cpp:244]     Train net output #0: loss = 0.0037529 (* 1 = 0.0037529 loss)
I0403 03:50:14.985458 32196 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 03:50:26.462824 32196 solver.cpp:228] Iteration 5280, loss = 0.000110385
I0403 03:50:26.462927 32196 solver.cpp:244]     Train net output #0: loss = 0.000110413 (* 1 = 0.000110413 loss)
I0403 03:50:26.613750 32196 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 03:50:38.234495 32196 solver.cpp:228] Iteration 5296, loss = 0.000182499
I0403 03:50:38.234799 32196 solver.cpp:244]     Train net output #0: loss = 0.000182527 (* 1 = 0.000182527 loss)
I0403 03:50:38.401471 32196 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 03:50:49.930016 32196 solver.cpp:228] Iteration 5312, loss = 0.00329713
I0403 03:50:49.930137 32196 solver.cpp:244]     Train net output #0: loss = 0.00329716 (* 1 = 0.00329716 loss)
I0403 03:50:50.122341 32196 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 03:51:01.521132 32196 solver.cpp:228] Iteration 5328, loss = 0.000154454
I0403 03:51:01.521241 32196 solver.cpp:244]     Train net output #0: loss = 0.000154482 (* 1 = 0.000154482 loss)
I0403 03:51:01.737895 32196 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 03:51:13.389878 32196 solver.cpp:228] Iteration 5344, loss = 0.000751851
I0403 03:51:13.390192 32196 solver.cpp:244]     Train net output #0: loss = 0.000751879 (* 1 = 0.000751879 loss)
I0403 03:51:13.588168 32196 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 03:51:25.190304 32196 solver.cpp:228] Iteration 5360, loss = 0.000169659
I0403 03:51:25.190415 32196 solver.cpp:244]     Train net output #0: loss = 0.000169687 (* 1 = 0.000169687 loss)
I0403 03:51:25.386373 32196 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 03:51:36.835667 32196 solver.cpp:228] Iteration 5376, loss = 0.00129386
I0403 03:51:36.835773 32196 solver.cpp:244]     Train net output #0: loss = 0.00129389 (* 1 = 0.00129389 loss)
I0403 03:51:37.020853 32196 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:51:48.702072 32196 solver.cpp:228] Iteration 5392, loss = 0.000290724
I0403 03:51:48.702353 32196 solver.cpp:244]     Train net output #0: loss = 0.000290752 (* 1 = 0.000290752 loss)
I0403 03:51:48.889564 32196 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 03:52:00.366374 32196 solver.cpp:228] Iteration 5408, loss = 0.00691438
I0403 03:52:00.366490 32196 solver.cpp:244]     Train net output #0: loss = 0.00691441 (* 1 = 0.00691441 loss)
I0403 03:52:00.596917 32196 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 03:52:12.035295 32196 solver.cpp:228] Iteration 5424, loss = 7.83313e-05
I0403 03:52:12.035411 32196 solver.cpp:244]     Train net output #0: loss = 7.83579e-05 (* 1 = 7.83579e-05 loss)
I0403 03:52:12.239344 32196 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 03:52:23.843612 32196 solver.cpp:228] Iteration 5440, loss = 0.00696627
I0403 03:52:23.843931 32196 solver.cpp:244]     Train net output #0: loss = 0.0069663 (* 1 = 0.0069663 loss)
I0403 03:52:24.031195 32196 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 03:52:35.400516 32196 solver.cpp:228] Iteration 5456, loss = 0.000460424
I0403 03:52:35.400625 32196 solver.cpp:244]     Train net output #0: loss = 0.00046045 (* 1 = 0.00046045 loss)
I0403 03:52:35.611419 32196 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 03:52:47.092638 32196 solver.cpp:228] Iteration 5472, loss = 0.000106336
I0403 03:52:47.092738 32196 solver.cpp:244]     Train net output #0: loss = 0.000106364 (* 1 = 0.000106364 loss)
I0403 03:52:47.267630 32196 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 03:52:58.855319 32196 solver.cpp:228] Iteration 5488, loss = 0.00289294
I0403 03:52:58.855603 32196 solver.cpp:244]     Train net output #0: loss = 0.00289297 (* 1 = 0.00289297 loss)
I0403 03:52:58.956843 32196 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 03:53:10.589100 32196 solver.cpp:228] Iteration 5504, loss = 0.00135986
I0403 03:53:10.589221 32196 solver.cpp:244]     Train net output #0: loss = 0.00135989 (* 1 = 0.00135989 loss)
I0403 03:53:10.844660 32196 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 03:53:22.599647 32196 solver.cpp:228] Iteration 5520, loss = 0.000797873
I0403 03:53:22.599756 32196 solver.cpp:244]     Train net output #0: loss = 0.000797901 (* 1 = 0.000797901 loss)
I0403 03:53:22.782169 32196 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 03:53:25.677952 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5525.caffemodel
I0403 03:53:28.399834 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5525.solverstate
I0403 03:53:30.238862 32196 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 03:54:19.167335 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990646
I0403 03:54:19.167682 32196 solver.cpp:404]     Test net output #1: loss = 0.0354831 (* 1 = 0.0354831 loss)
I0403 03:54:27.769098 32196 solver.cpp:228] Iteration 5536, loss = 8.03263e-05
I0403 03:54:27.769183 32196 solver.cpp:244]     Train net output #0: loss = 8.03542e-05 (* 1 = 8.03542e-05 loss)
I0403 03:54:27.946969 32196 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 03:54:39.557544 32196 solver.cpp:228] Iteration 5552, loss = 0.000896535
I0403 03:54:39.557654 32196 solver.cpp:244]     Train net output #0: loss = 0.000896563 (* 1 = 0.000896563 loss)
I0403 03:54:39.740125 32196 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 03:54:51.081821 32196 solver.cpp:228] Iteration 5568, loss = 0.000730233
I0403 03:54:51.082142 32196 solver.cpp:244]     Train net output #0: loss = 0.00073026 (* 1 = 0.00073026 loss)
I0403 03:54:51.281203 32196 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 03:55:02.902503 32196 solver.cpp:228] Iteration 5584, loss = 0.000460107
I0403 03:55:02.902611 32196 solver.cpp:244]     Train net output #0: loss = 0.000460135 (* 1 = 0.000460135 loss)
I0403 03:55:03.088865 32196 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 03:55:14.700599 32196 solver.cpp:228] Iteration 5600, loss = 0.000255032
I0403 03:55:14.706804 32196 solver.cpp:244]     Train net output #0: loss = 0.000255059 (* 1 = 0.000255059 loss)
I0403 03:55:14.876899 32196 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 03:55:26.582914 32196 solver.cpp:228] Iteration 5616, loss = 0.000511205
I0403 03:55:26.589944 32196 solver.cpp:244]     Train net output #0: loss = 0.000511233 (* 1 = 0.000511233 loss)
I0403 03:55:26.743602 32196 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 03:55:38.285326 32196 solver.cpp:228] Iteration 5632, loss = 0.00433169
I0403 03:55:38.291256 32196 solver.cpp:244]     Train net output #0: loss = 0.00433172 (* 1 = 0.00433172 loss)
I0403 03:55:38.487071 32196 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 03:55:50.151417 32196 solver.cpp:228] Iteration 5648, loss = 9.2735e-05
I0403 03:55:50.151520 32196 solver.cpp:244]     Train net output #0: loss = 9.27628e-05 (* 1 = 9.27628e-05 loss)
I0403 03:55:50.329880 32196 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 03:56:01.809073 32196 solver.cpp:228] Iteration 5664, loss = 0.000218628
I0403 03:56:01.809422 32196 solver.cpp:244]     Train net output #0: loss = 0.000218656 (* 1 = 0.000218656 loss)
I0403 03:56:02.005297 32196 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 03:56:13.444567 32196 solver.cpp:228] Iteration 5680, loss = 0.000407056
I0403 03:56:13.444679 32196 solver.cpp:244]     Train net output #0: loss = 0.000407084 (* 1 = 0.000407084 loss)
I0403 03:56:13.635685 32196 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 03:56:25.039079 32196 solver.cpp:228] Iteration 5696, loss = 0.0028333
I0403 03:56:25.039197 32196 solver.cpp:244]     Train net output #0: loss = 0.00283333 (* 1 = 0.00283333 loss)
I0403 03:56:25.229406 32196 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 03:56:36.758638 32196 solver.cpp:228] Iteration 5712, loss = 0.000157877
I0403 03:56:36.758920 32196 solver.cpp:244]     Train net output #0: loss = 0.000157905 (* 1 = 0.000157905 loss)
I0403 03:56:36.939934 32196 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:56:48.491147 32196 solver.cpp:228] Iteration 5728, loss = 0.00402488
I0403 03:56:48.491260 32196 solver.cpp:244]     Train net output #0: loss = 0.00402491 (* 1 = 0.00402491 loss)
I0403 03:56:48.681277 32196 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 03:57:00.245017 32196 solver.cpp:228] Iteration 5744, loss = 0.000167304
I0403 03:57:00.245141 32196 solver.cpp:244]     Train net output #0: loss = 0.000167332 (* 1 = 0.000167332 loss)
I0403 03:57:00.437682 32196 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 03:57:12.074431 32196 solver.cpp:228] Iteration 5760, loss = 0.000388319
I0403 03:57:12.074723 32196 solver.cpp:244]     Train net output #0: loss = 0.000388346 (* 1 = 0.000388346 loss)
I0403 03:57:12.261615 32196 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 03:57:23.749845 32196 solver.cpp:228] Iteration 5776, loss = 8.39077e-05
I0403 03:57:23.749954 32196 solver.cpp:244]     Train net output #0: loss = 8.39342e-05 (* 1 = 8.39342e-05 loss)
I0403 03:57:23.933073 32196 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 03:57:35.307126 32196 solver.cpp:228] Iteration 5792, loss = 0.000126776
I0403 03:57:35.307241 32196 solver.cpp:244]     Train net output #0: loss = 0.000126802 (* 1 = 0.000126802 loss)
I0403 03:57:35.539546 32196 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 03:57:47.206966 32196 solver.cpp:228] Iteration 5808, loss = 0.000509412
I0403 03:57:47.207286 32196 solver.cpp:244]     Train net output #0: loss = 0.000509439 (* 1 = 0.000509439 loss)
I0403 03:57:47.407032 32196 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 03:57:58.833135 32196 solver.cpp:228] Iteration 5824, loss = 0.00024369
I0403 03:57:58.833245 32196 solver.cpp:244]     Train net output #0: loss = 0.000243717 (* 1 = 0.000243717 loss)
I0403 03:57:59.047598 32196 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 03:58:10.444878 32196 solver.cpp:228] Iteration 5840, loss = 0.000119569
I0403 03:58:10.444993 32196 solver.cpp:244]     Train net output #0: loss = 0.000119594 (* 1 = 0.000119594 loss)
I0403 03:58:10.657022 32196 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 03:58:17.281955 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5850.caffemodel
I0403 03:58:19.955909 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_5850.solverstate
I0403 03:58:21.809869 32196 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 03:59:10.781395 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990554
I0403 03:59:10.781718 32196 solver.cpp:404]     Test net output #1: loss = 0.0354701 (* 1 = 0.0354701 loss)
I0403 03:59:15.769026 32196 solver.cpp:228] Iteration 5856, loss = 0.000885704
I0403 03:59:15.769129 32196 solver.cpp:244]     Train net output #0: loss = 0.000885728 (* 1 = 0.000885728 loss)
I0403 03:59:15.987169 32196 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 03:59:27.607048 32196 solver.cpp:228] Iteration 5872, loss = 8.11e-05
I0403 03:59:27.607167 32196 solver.cpp:244]     Train net output #0: loss = 8.1124e-05 (* 1 = 8.1124e-05 loss)
I0403 03:59:27.793094 32196 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 03:59:39.217248 32196 solver.cpp:228] Iteration 5888, loss = 0.00147061
I0403 03:59:39.217414 32196 solver.cpp:244]     Train net output #0: loss = 0.00147063 (* 1 = 0.00147063 loss)
I0403 03:59:39.411559 32196 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 03:59:50.871529 32196 solver.cpp:228] Iteration 5904, loss = 0.00113918
I0403 03:59:50.871845 32196 solver.cpp:244]     Train net output #0: loss = 0.0011392 (* 1 = 0.0011392 loss)
I0403 03:59:51.075837 32196 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 04:00:02.525120 32196 solver.cpp:228] Iteration 5920, loss = 0.000374728
I0403 04:00:02.525220 32196 solver.cpp:244]     Train net output #0: loss = 0.000374752 (* 1 = 0.000374752 loss)
I0403 04:00:02.684303 32196 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 04:00:14.149082 32196 solver.cpp:228] Iteration 5936, loss = 0.00120091
I0403 04:00:14.149199 32196 solver.cpp:244]     Train net output #0: loss = 0.00120093 (* 1 = 0.00120093 loss)
I0403 04:00:14.358238 32196 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 04:00:25.796305 32196 solver.cpp:228] Iteration 5952, loss = 0.00326833
I0403 04:00:25.796615 32196 solver.cpp:244]     Train net output #0: loss = 0.00326835 (* 1 = 0.00326835 loss)
I0403 04:00:26.012908 32196 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 04:00:37.594064 32196 solver.cpp:228] Iteration 5968, loss = 0.000185557
I0403 04:00:37.594171 32196 solver.cpp:244]     Train net output #0: loss = 0.000185581 (* 1 = 0.000185581 loss)
I0403 04:00:37.773970 32196 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 04:00:49.252876 32196 solver.cpp:228] Iteration 5984, loss = 0.00048227
I0403 04:00:49.252985 32196 solver.cpp:244]     Train net output #0: loss = 0.000482293 (* 1 = 0.000482293 loss)
I0403 04:00:49.465111 32196 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 04:01:00.944332 32196 solver.cpp:228] Iteration 6000, loss = 0.000238369
I0403 04:01:00.944638 32196 solver.cpp:244]     Train net output #0: loss = 0.000238392 (* 1 = 0.000238392 loss)
I0403 04:01:01.096460 32196 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 04:01:12.627323 32196 solver.cpp:228] Iteration 6016, loss = 0.000168456
I0403 04:01:12.627429 32196 solver.cpp:244]     Train net output #0: loss = 0.00016848 (* 1 = 0.00016848 loss)
I0403 04:01:12.804020 32196 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 04:01:24.316980 32196 solver.cpp:228] Iteration 6032, loss = 0.00136396
I0403 04:01:24.317083 32196 solver.cpp:244]     Train net output #0: loss = 0.00136398 (* 1 = 0.00136398 loss)
I0403 04:01:24.497648 32196 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 04:01:36.017555 32196 solver.cpp:228] Iteration 6048, loss = 0.000644744
I0403 04:01:36.017839 32196 solver.cpp:244]     Train net output #0: loss = 0.000644767 (* 1 = 0.000644767 loss)
I0403 04:01:36.214391 32196 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 04:01:47.622082 32196 solver.cpp:228] Iteration 6064, loss = 9.33199e-05
I0403 04:01:47.622212 32196 solver.cpp:244]     Train net output #0: loss = 9.33429e-05 (* 1 = 9.33429e-05 loss)
I0403 04:01:47.808076 32196 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 04:01:59.183159 32196 solver.cpp:228] Iteration 6080, loss = 0.000155806
I0403 04:01:59.183260 32196 solver.cpp:244]     Train net output #0: loss = 0.000155828 (* 1 = 0.000155828 loss)
I0403 04:01:59.358610 32196 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 04:02:10.843463 32196 solver.cpp:228] Iteration 6096, loss = 0.000186413
I0403 04:02:10.843781 32196 solver.cpp:244]     Train net output #0: loss = 0.000186435 (* 1 = 0.000186435 loss)
I0403 04:02:11.048912 32196 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 04:02:22.775251 32196 solver.cpp:228] Iteration 6112, loss = 0.000169516
I0403 04:02:22.775353 32196 solver.cpp:244]     Train net output #0: loss = 0.000169537 (* 1 = 0.000169537 loss)
I0403 04:02:22.895721 32196 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 04:02:34.576232 32196 solver.cpp:228] Iteration 6128, loss = 0.000455513
I0403 04:02:34.576335 32196 solver.cpp:244]     Train net output #0: loss = 0.000455535 (* 1 = 0.000455535 loss)
I0403 04:02:34.725033 32196 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 04:02:46.370386 32196 solver.cpp:228] Iteration 6144, loss = 0.00186902
I0403 04:02:46.370651 32196 solver.cpp:244]     Train net output #0: loss = 0.00186904 (* 1 = 0.00186904 loss)
I0403 04:02:46.523592 32196 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 04:02:58.119273 32196 solver.cpp:228] Iteration 6160, loss = 0.0117877
I0403 04:02:58.119385 32196 solver.cpp:244]     Train net output #0: loss = 0.0117878 (* 1 = 0.0117878 loss)
I0403 04:02:58.377475 32196 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 04:03:08.532721 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6175.caffemodel
I0403 04:03:11.274771 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6175.solverstate
I0403 04:03:13.159266 32196 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 04:04:02.085955 32196 solver.cpp:404]     Test net output #0: accuracy = 0.991061
I0403 04:04:02.086208 32196 solver.cpp:404]     Test net output #1: loss = 0.0336164 (* 1 = 0.0336164 loss)
I0403 04:04:03.434998 32196 solver.cpp:228] Iteration 6176, loss = 0.00106924
I0403 04:04:03.435099 32196 solver.cpp:244]     Train net output #0: loss = 0.00106927 (* 1 = 0.00106927 loss)
I0403 04:04:03.538029 32196 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 04:04:15.082305 32196 solver.cpp:228] Iteration 6192, loss = 0.000601484
I0403 04:04:15.082418 32196 solver.cpp:244]     Train net output #0: loss = 0.000601509 (* 1 = 0.000601509 loss)
I0403 04:04:15.284538 32196 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 04:04:26.797205 32196 solver.cpp:228] Iteration 6208, loss = 0.000909675
I0403 04:04:26.797318 32196 solver.cpp:244]     Train net output #0: loss = 0.0009097 (* 1 = 0.0009097 loss)
I0403 04:04:26.991312 32196 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 04:04:38.412358 32196 solver.cpp:228] Iteration 6224, loss = 0.00078108
I0403 04:04:38.412662 32196 solver.cpp:244]     Train net output #0: loss = 0.000781104 (* 1 = 0.000781104 loss)
I0403 04:04:38.563474 32196 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 04:04:50.188699 32196 solver.cpp:228] Iteration 6240, loss = 0.0187944
I0403 04:04:50.188810 32196 solver.cpp:244]     Train net output #0: loss = 0.0187944 (* 1 = 0.0187944 loss)
I0403 04:04:50.385741 32196 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 04:05:01.866837 32196 solver.cpp:228] Iteration 6256, loss = 0.000235338
I0403 04:05:01.866947 32196 solver.cpp:244]     Train net output #0: loss = 0.000235363 (* 1 = 0.000235363 loss)
I0403 04:05:02.092584 32196 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 04:05:13.642804 32196 solver.cpp:228] Iteration 6272, loss = 0.00275761
I0403 04:05:13.647053 32196 solver.cpp:244]     Train net output #0: loss = 0.00275763 (* 1 = 0.00275763 loss)
I0403 04:05:13.850167 32196 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 04:05:25.763882 32196 solver.cpp:228] Iteration 6288, loss = 0.000176515
I0403 04:05:25.763991 32196 solver.cpp:244]     Train net output #0: loss = 0.00017654 (* 1 = 0.00017654 loss)
I0403 04:05:25.961926 32196 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 04:05:37.735586 32196 solver.cpp:228] Iteration 6304, loss = 0.00111443
I0403 04:05:37.735689 32196 solver.cpp:244]     Train net output #0: loss = 0.00111446 (* 1 = 0.00111446 loss)
I0403 04:05:37.920502 32196 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 04:05:49.636800 32196 solver.cpp:228] Iteration 6320, loss = 0.00226764
I0403 04:05:49.637111 32196 solver.cpp:244]     Train net output #0: loss = 0.00226766 (* 1 = 0.00226766 loss)
I0403 04:05:49.825350 32196 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 04:06:01.289132 32196 solver.cpp:228] Iteration 6336, loss = 0.000261584
I0403 04:06:01.289247 32196 solver.cpp:244]     Train net output #0: loss = 0.000261608 (* 1 = 0.000261608 loss)
I0403 04:06:01.528012 32196 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 04:06:12.952152 32196 solver.cpp:228] Iteration 6352, loss = 0.00332146
I0403 04:06:12.952265 32196 solver.cpp:244]     Train net output #0: loss = 0.00332148 (* 1 = 0.00332148 loss)
I0403 04:06:13.143620 32196 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 04:06:24.710135 32196 solver.cpp:228] Iteration 6368, loss = 0.000688907
I0403 04:06:24.710445 32196 solver.cpp:244]     Train net output #0: loss = 0.000688932 (* 1 = 0.000688932 loss)
I0403 04:06:24.901813 32196 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 04:06:36.475505 32196 solver.cpp:228] Iteration 6384, loss = 0.000196725
I0403 04:06:36.475620 32196 solver.cpp:244]     Train net output #0: loss = 0.00019675 (* 1 = 0.00019675 loss)
I0403 04:06:36.698149 32196 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 04:06:48.109526 32196 solver.cpp:228] Iteration 6400, loss = 6.76836e-05
I0403 04:06:48.109640 32196 solver.cpp:244]     Train net output #0: loss = 6.77089e-05 (* 1 = 6.77089e-05 loss)
I0403 04:06:48.367980 32196 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 04:06:59.912840 32196 solver.cpp:228] Iteration 6416, loss = 0.000538319
I0403 04:06:59.913127 32196 solver.cpp:244]     Train net output #0: loss = 0.000538346 (* 1 = 0.000538346 loss)
I0403 04:07:00.103325 32196 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 04:07:11.577364 32196 solver.cpp:228] Iteration 6432, loss = 0.0002321
I0403 04:07:11.577478 32196 solver.cpp:244]     Train net output #0: loss = 0.000232127 (* 1 = 0.000232127 loss)
I0403 04:07:11.782774 32196 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 04:07:23.282681 32196 solver.cpp:228] Iteration 6448, loss = 0.000297896
I0403 04:07:23.282781 32196 solver.cpp:244]     Train net output #0: loss = 0.000297923 (* 1 = 0.000297923 loss)
I0403 04:07:23.462369 32196 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 04:07:35.088683 32196 solver.cpp:228] Iteration 6464, loss = 0.000152685
I0403 04:07:35.088995 32196 solver.cpp:244]     Train net output #0: loss = 0.000152711 (* 1 = 0.000152711 loss)
I0403 04:07:35.333569 32196 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 04:07:46.727483 32196 solver.cpp:228] Iteration 6480, loss = 0.000443899
I0403 04:07:46.727617 32196 solver.cpp:244]     Train net output #0: loss = 0.000443924 (* 1 = 0.000443924 loss)
I0403 04:07:47.006443 32196 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 04:07:58.407157 32196 solver.cpp:228] Iteration 6496, loss = 0.0019511
I0403 04:07:58.407263 32196 solver.cpp:244]     Train net output #0: loss = 0.00195112 (* 1 = 0.00195112 loss)
I0403 04:07:58.560231 32196 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 04:08:00.838214 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6500.caffemodel
I0403 04:08:03.586649 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6500.solverstate
I0403 04:08:05.449229 32196 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 04:08:54.370007 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990554
I0403 04:08:54.370359 32196 solver.cpp:404]     Test net output #1: loss = 0.034784 (* 1 = 0.034784 loss)
I0403 04:09:03.730983 32196 solver.cpp:228] Iteration 6512, loss = 7.48841e-05
I0403 04:09:03.731076 32196 solver.cpp:244]     Train net output #0: loss = 7.49095e-05 (* 1 = 7.49095e-05 loss)
I0403 04:09:03.912781 32196 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 04:09:15.511919 32196 solver.cpp:228] Iteration 6528, loss = 0.000468768
I0403 04:09:15.512027 32196 solver.cpp:244]     Train net output #0: loss = 0.000468793 (* 1 = 0.000468793 loss)
I0403 04:09:15.699337 32196 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 04:09:27.272481 32196 solver.cpp:228] Iteration 6544, loss = 0.00997222
I0403 04:09:27.272779 32196 solver.cpp:244]     Train net output #0: loss = 0.00997225 (* 1 = 0.00997225 loss)
I0403 04:09:27.464471 32196 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 04:09:38.793202 32196 solver.cpp:228] Iteration 6560, loss = 0.00152489
I0403 04:09:38.793315 32196 solver.cpp:244]     Train net output #0: loss = 0.00152492 (* 1 = 0.00152492 loss)
I0403 04:09:38.983538 32196 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 04:09:50.418375 32196 solver.cpp:228] Iteration 6576, loss = 0.000476554
I0403 04:09:50.418490 32196 solver.cpp:244]     Train net output #0: loss = 0.00047658 (* 1 = 0.00047658 loss)
I0403 04:09:50.707489 32196 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 04:10:02.243631 32196 solver.cpp:228] Iteration 6592, loss = 0.00015615
I0403 04:10:02.243957 32196 solver.cpp:244]     Train net output #0: loss = 0.000156175 (* 1 = 0.000156175 loss)
I0403 04:10:02.433039 32196 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 04:10:13.928894 32196 solver.cpp:228] Iteration 6608, loss = 0.000172692
I0403 04:10:13.928995 32196 solver.cpp:244]     Train net output #0: loss = 0.000172718 (* 1 = 0.000172718 loss)
I0403 04:10:14.111009 32196 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 04:10:25.642720 32196 solver.cpp:228] Iteration 6624, loss = 0.000717326
I0403 04:10:25.642824 32196 solver.cpp:244]     Train net output #0: loss = 0.000717353 (* 1 = 0.000717353 loss)
I0403 04:10:25.816587 32196 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 04:10:37.557955 32196 solver.cpp:228] Iteration 6640, loss = 0.00145391
I0403 04:10:37.561825 32196 solver.cpp:244]     Train net output #0: loss = 0.00145394 (* 1 = 0.00145394 loss)
I0403 04:10:37.707085 32196 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 04:10:49.271280 32196 solver.cpp:228] Iteration 6656, loss = 0.00434519
I0403 04:10:49.271401 32196 solver.cpp:244]     Train net output #0: loss = 0.00434521 (* 1 = 0.00434521 loss)
I0403 04:10:49.457265 32196 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:11:01.283838 32196 solver.cpp:228] Iteration 6672, loss = 0.00087917
I0403 04:11:01.283951 32196 solver.cpp:244]     Train net output #0: loss = 0.000879196 (* 1 = 0.000879196 loss)
I0403 04:11:01.471060 32196 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 04:11:13.060398 32196 solver.cpp:228] Iteration 6688, loss = 0.0021838
I0403 04:11:13.060714 32196 solver.cpp:244]     Train net output #0: loss = 0.00218382 (* 1 = 0.00218382 loss)
I0403 04:11:13.242471 32196 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 04:11:24.765300 32196 solver.cpp:228] Iteration 6704, loss = 0.00185281
I0403 04:11:24.765401 32196 solver.cpp:244]     Train net output #0: loss = 0.00185283 (* 1 = 0.00185283 loss)
I0403 04:11:24.928884 32196 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 04:11:36.548058 32196 solver.cpp:228] Iteration 6720, loss = 0.00020446
I0403 04:11:36.548168 32196 solver.cpp:244]     Train net output #0: loss = 0.000204487 (* 1 = 0.000204487 loss)
I0403 04:11:36.724822 32196 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 04:11:48.227772 32196 solver.cpp:228] Iteration 6736, loss = 0.00107329
I0403 04:11:48.228116 32196 solver.cpp:244]     Train net output #0: loss = 0.00107331 (* 1 = 0.00107331 loss)
I0403 04:11:48.363910 32196 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 04:11:59.880002 32196 solver.cpp:228] Iteration 6752, loss = 0.000274934
I0403 04:11:59.880115 32196 solver.cpp:244]     Train net output #0: loss = 0.00027496 (* 1 = 0.00027496 loss)
I0403 04:12:00.092056 32196 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 04:12:11.625028 32196 solver.cpp:228] Iteration 6768, loss = 0.000873799
I0403 04:12:11.625138 32196 solver.cpp:244]     Train net output #0: loss = 0.000873826 (* 1 = 0.000873826 loss)
I0403 04:12:11.777547 32196 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 04:12:23.373251 32196 solver.cpp:228] Iteration 6784, loss = 0.000158682
I0403 04:12:23.373553 32196 solver.cpp:244]     Train net output #0: loss = 0.000158709 (* 1 = 0.000158709 loss)
I0403 04:12:23.570787 32196 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 04:12:35.249104 32196 solver.cpp:228] Iteration 6800, loss = 0.000272405
I0403 04:12:35.249217 32196 solver.cpp:244]     Train net output #0: loss = 0.000272432 (* 1 = 0.000272432 loss)
I0403 04:12:35.453625 32196 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 04:12:46.900225 32196 solver.cpp:228] Iteration 6816, loss = 0.000260035
I0403 04:12:46.900355 32196 solver.cpp:244]     Train net output #0: loss = 0.000260061 (* 1 = 0.000260061 loss)
I0403 04:12:47.120175 32196 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 04:12:53.054347 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6825.caffemodel
I0403 04:12:55.817570 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_6825.solverstate
I0403 04:12:57.698891 32196 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 04:13:46.629647 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990646
I0403 04:13:46.630002 32196 solver.cpp:404]     Test net output #1: loss = 0.0348647 (* 1 = 0.0348647 loss)
I0403 04:13:52.303302 32196 solver.cpp:228] Iteration 6832, loss = 0.000137103
I0403 04:13:52.303411 32196 solver.cpp:244]     Train net output #0: loss = 0.00013713 (* 1 = 0.00013713 loss)
I0403 04:13:52.492653 32196 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 04:14:04.021697 32196 solver.cpp:228] Iteration 6848, loss = 0.00127259
I0403 04:14:04.021806 32196 solver.cpp:244]     Train net output #0: loss = 0.00127262 (* 1 = 0.00127262 loss)
I0403 04:14:04.216161 32196 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 04:14:15.769079 32196 solver.cpp:228] Iteration 6864, loss = 0.00224233
I0403 04:14:15.769191 32196 solver.cpp:244]     Train net output #0: loss = 0.00224236 (* 1 = 0.00224236 loss)
I0403 04:14:15.972472 32196 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:14:27.346498 32196 solver.cpp:228] Iteration 6880, loss = 0.000822551
I0403 04:14:27.346758 32196 solver.cpp:244]     Train net output #0: loss = 0.000822577 (* 1 = 0.000822577 loss)
I0403 04:14:27.550971 32196 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 04:14:39.192589 32196 solver.cpp:228] Iteration 6896, loss = 0.000371583
I0403 04:14:39.192693 32196 solver.cpp:244]     Train net output #0: loss = 0.000371608 (* 1 = 0.000371608 loss)
I0403 04:14:39.381369 32196 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 04:14:50.803197 32196 solver.cpp:228] Iteration 6912, loss = 0.000185259
I0403 04:14:50.803298 32196 solver.cpp:244]     Train net output #0: loss = 0.000185284 (* 1 = 0.000185284 loss)
I0403 04:14:50.984138 32196 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 04:15:02.568594 32196 solver.cpp:228] Iteration 6928, loss = 0.000968706
I0403 04:15:02.568959 32196 solver.cpp:244]     Train net output #0: loss = 0.000968731 (* 1 = 0.000968731 loss)
I0403 04:15:02.762408 32196 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 04:15:14.213153 32196 solver.cpp:228] Iteration 6944, loss = 0.000869862
I0403 04:15:14.213264 32196 solver.cpp:244]     Train net output #0: loss = 0.000869887 (* 1 = 0.000869887 loss)
I0403 04:15:14.416537 32196 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 04:15:25.847430 32196 solver.cpp:228] Iteration 6960, loss = 0.000304881
I0403 04:15:25.847532 32196 solver.cpp:244]     Train net output #0: loss = 0.000304905 (* 1 = 0.000304905 loss)
I0403 04:15:25.997376 32196 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 04:15:37.562942 32196 solver.cpp:228] Iteration 6976, loss = 0.000101109
I0403 04:15:37.563262 32196 solver.cpp:244]     Train net output #0: loss = 0.000101134 (* 1 = 0.000101134 loss)
I0403 04:15:37.758883 32196 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 04:15:49.301946 32196 solver.cpp:228] Iteration 6992, loss = 0.000924423
I0403 04:15:49.302045 32196 solver.cpp:244]     Train net output #0: loss = 0.000924449 (* 1 = 0.000924449 loss)
I0403 04:15:49.484012 32196 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 04:16:00.865559 32196 solver.cpp:228] Iteration 7008, loss = 0.00456395
I0403 04:16:00.865666 32196 solver.cpp:244]     Train net output #0: loss = 0.00456398 (* 1 = 0.00456398 loss)
I0403 04:16:01.051213 32196 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 04:16:12.548511 32196 solver.cpp:228] Iteration 7024, loss = 0.00480555
I0403 04:16:12.548836 32196 solver.cpp:244]     Train net output #0: loss = 0.00480558 (* 1 = 0.00480558 loss)
I0403 04:16:12.771348 32196 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 04:16:24.393892 32196 solver.cpp:228] Iteration 7040, loss = 0.00189311
I0403 04:16:24.394001 32196 solver.cpp:244]     Train net output #0: loss = 0.00189314 (* 1 = 0.00189314 loss)
I0403 04:16:24.578084 32196 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 04:16:36.028965 32196 solver.cpp:228] Iteration 7056, loss = 0.000256714
I0403 04:16:36.029074 32196 solver.cpp:244]     Train net output #0: loss = 0.000256742 (* 1 = 0.000256742 loss)
I0403 04:16:36.224123 32196 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 04:16:47.811200 32196 solver.cpp:228] Iteration 7072, loss = 0.00043456
I0403 04:16:47.811496 32196 solver.cpp:244]     Train net output #0: loss = 0.000434588 (* 1 = 0.000434588 loss)
I0403 04:16:48.030956 32196 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:16:59.868607 32196 solver.cpp:228] Iteration 7088, loss = 0.000888885
I0403 04:16:59.868719 32196 solver.cpp:244]     Train net output #0: loss = 0.000888913 (* 1 = 0.000888913 loss)
I0403 04:17:00.059707 32196 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 04:17:11.542436 32196 solver.cpp:228] Iteration 7104, loss = 0.000502296
I0403 04:17:11.542554 32196 solver.cpp:244]     Train net output #0: loss = 0.000502323 (* 1 = 0.000502323 loss)
I0403 04:17:11.745987 32196 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 04:17:23.089298 32196 solver.cpp:228] Iteration 7120, loss = 0.00013003
I0403 04:17:23.089637 32196 solver.cpp:244]     Train net output #0: loss = 0.000130058 (* 1 = 0.000130058 loss)
I0403 04:17:23.264811 32196 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 04:17:34.889883 32196 solver.cpp:228] Iteration 7136, loss = 0.00733133
I0403 04:17:34.889984 32196 solver.cpp:244]     Train net output #0: loss = 0.00733135 (* 1 = 0.00733135 loss)
I0403 04:17:35.055181 32196 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 04:17:44.802155 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7150.caffemodel
I0403 04:17:47.574663 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7150.solverstate
I0403 04:17:49.472234 32196 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 04:18:38.399276 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990507
I0403 04:18:38.403643 32196 solver.cpp:404]     Test net output #1: loss = 0.0348081 (* 1 = 0.0348081 loss)
I0403 04:18:40.384258 32196 solver.cpp:228] Iteration 7152, loss = 0.000304728
I0403 04:18:40.384349 32196 solver.cpp:244]     Train net output #0: loss = 0.000304756 (* 1 = 0.000304756 loss)
I0403 04:18:40.570070 32196 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 04:18:52.193723 32196 solver.cpp:228] Iteration 7168, loss = 0.00101862
I0403 04:18:52.193836 32196 solver.cpp:244]     Train net output #0: loss = 0.00101865 (* 1 = 0.00101865 loss)
I0403 04:18:52.376505 32196 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 04:19:03.883617 32196 solver.cpp:228] Iteration 7184, loss = 0.000144523
I0403 04:19:03.883728 32196 solver.cpp:244]     Train net output #0: loss = 0.00014455 (* 1 = 0.00014455 loss)
I0403 04:19:04.077158 32196 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 04:19:15.599858 32196 solver.cpp:228] Iteration 7200, loss = 8.72232e-05
I0403 04:19:15.600191 32196 solver.cpp:244]     Train net output #0: loss = 8.72503e-05 (* 1 = 8.72503e-05 loss)
I0403 04:19:15.782088 32196 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 04:19:27.332067 32196 solver.cpp:228] Iteration 7216, loss = 0.0001607
I0403 04:19:27.332186 32196 solver.cpp:244]     Train net output #0: loss = 0.000160727 (* 1 = 0.000160727 loss)
I0403 04:19:27.516898 32196 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 04:19:38.981591 32196 solver.cpp:228] Iteration 7232, loss = 0.00065597
I0403 04:19:38.981701 32196 solver.cpp:244]     Train net output #0: loss = 0.000655997 (* 1 = 0.000655997 loss)
I0403 04:19:39.169731 32196 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 04:19:50.836733 32196 solver.cpp:228] Iteration 7248, loss = 0.000408176
I0403 04:19:50.837031 32196 solver.cpp:244]     Train net output #0: loss = 0.000408203 (* 1 = 0.000408203 loss)
I0403 04:19:51.021554 32196 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 04:20:02.607736 32196 solver.cpp:228] Iteration 7264, loss = 0.000321228
I0403 04:20:02.607851 32196 solver.cpp:244]     Train net output #0: loss = 0.000321255 (* 1 = 0.000321255 loss)
I0403 04:20:02.790355 32196 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 04:20:14.389080 32196 solver.cpp:228] Iteration 7280, loss = 0.000424145
I0403 04:20:14.389185 32196 solver.cpp:244]     Train net output #0: loss = 0.000424171 (* 1 = 0.000424171 loss)
I0403 04:20:14.565155 32196 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:20:26.169100 32196 solver.cpp:228] Iteration 7296, loss = 0.00113553
I0403 04:20:26.169412 32196 solver.cpp:244]     Train net output #0: loss = 0.00113556 (* 1 = 0.00113556 loss)
I0403 04:20:26.333516 32196 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 04:20:37.923351 32196 solver.cpp:228] Iteration 7312, loss = 0.000205708
I0403 04:20:37.923472 32196 solver.cpp:244]     Train net output #0: loss = 0.000205734 (* 1 = 0.000205734 loss)
I0403 04:20:38.107502 32196 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 04:20:49.585374 32196 solver.cpp:228] Iteration 7328, loss = 0.00089965
I0403 04:20:49.585487 32196 solver.cpp:244]     Train net output #0: loss = 0.000899675 (* 1 = 0.000899675 loss)
I0403 04:20:49.836030 32196 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 04:21:01.215735 32196 solver.cpp:228] Iteration 7344, loss = 0.000225096
I0403 04:21:01.216070 32196 solver.cpp:244]     Train net output #0: loss = 0.000225121 (* 1 = 0.000225121 loss)
I0403 04:21:01.410329 32196 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 04:21:12.943311 32196 solver.cpp:228] Iteration 7360, loss = 0.00450323
I0403 04:21:12.943418 32196 solver.cpp:244]     Train net output #0: loss = 0.00450326 (* 1 = 0.00450326 loss)
I0403 04:21:13.128566 32196 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 04:21:24.720163 32196 solver.cpp:228] Iteration 7376, loss = 0.00010402
I0403 04:21:24.721185 32196 solver.cpp:244]     Train net output #0: loss = 0.000104046 (* 1 = 0.000104046 loss)
I0403 04:21:24.906859 32196 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 04:21:36.432168 32196 solver.cpp:228] Iteration 7392, loss = 0.000213294
I0403 04:21:36.432518 32196 solver.cpp:244]     Train net output #0: loss = 0.000213318 (* 1 = 0.000213318 loss)
I0403 04:21:36.616322 32196 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 04:21:48.067533 32196 solver.cpp:228] Iteration 7408, loss = 0.0012964
I0403 04:21:48.067644 32196 solver.cpp:244]     Train net output #0: loss = 0.00129643 (* 1 = 0.00129643 loss)
I0403 04:21:48.260468 32196 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 04:21:59.755919 32196 solver.cpp:228] Iteration 7424, loss = 0.000112953
I0403 04:21:59.756028 32196 solver.cpp:244]     Train net output #0: loss = 0.000112978 (* 1 = 0.000112978 loss)
I0403 04:21:59.935302 32196 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 04:22:11.295372 32196 solver.cpp:228] Iteration 7440, loss = 5.18485e-05
I0403 04:22:11.295687 32196 solver.cpp:244]     Train net output #0: loss = 5.18732e-05 (* 1 = 5.18732e-05 loss)
I0403 04:22:11.485564 32196 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 04:22:23.044256 32196 solver.cpp:228] Iteration 7456, loss = 0.000136748
I0403 04:22:23.044359 32196 solver.cpp:244]     Train net output #0: loss = 0.000136773 (* 1 = 0.000136773 loss)
I0403 04:22:23.226234 32196 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 04:22:34.713879 32196 solver.cpp:228] Iteration 7472, loss = 5.24545e-05
I0403 04:22:34.713991 32196 solver.cpp:244]     Train net output #0: loss = 5.24785e-05 (* 1 = 5.24785e-05 loss)
I0403 04:22:34.896020 32196 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 04:22:36.322242 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7475.caffemodel
I0403 04:22:39.007124 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7475.solverstate
I0403 04:22:41.316673 32196 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 04:23:30.318771 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990508
I0403 04:23:30.319118 32196 solver.cpp:404]     Test net output #1: loss = 0.0350345 (* 1 = 0.0350345 loss)
I0403 04:23:40.247289 32196 solver.cpp:228] Iteration 7488, loss = 0.000125364
I0403 04:23:40.247414 32196 solver.cpp:244]     Train net output #0: loss = 0.000125388 (* 1 = 0.000125388 loss)
I0403 04:23:40.438536 32196 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:23:52.242851 32196 solver.cpp:228] Iteration 7504, loss = 0.0145704
I0403 04:23:52.242967 32196 solver.cpp:244]     Train net output #0: loss = 0.0145704 (* 1 = 0.0145704 loss)
I0403 04:23:52.431098 32196 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 04:24:03.818486 32196 solver.cpp:228] Iteration 7520, loss = 0.000343836
I0403 04:24:03.818783 32196 solver.cpp:244]     Train net output #0: loss = 0.00034386 (* 1 = 0.00034386 loss)
I0403 04:24:04.032894 32196 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 04:24:15.519711 32196 solver.cpp:228] Iteration 7536, loss = 0.000254661
I0403 04:24:15.519810 32196 solver.cpp:244]     Train net output #0: loss = 0.000254685 (* 1 = 0.000254685 loss)
I0403 04:24:15.700919 32196 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 04:24:27.266950 32196 solver.cpp:228] Iteration 7552, loss = 4.81384e-05
I0403 04:24:27.267060 32196 solver.cpp:244]     Train net output #0: loss = 4.81622e-05 (* 1 = 4.81622e-05 loss)
I0403 04:24:27.451921 32196 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 04:24:38.968045 32196 solver.cpp:228] Iteration 7568, loss = 0.000234977
I0403 04:24:38.968358 32196 solver.cpp:244]     Train net output #0: loss = 0.000235 (* 1 = 0.000235 loss)
I0403 04:24:39.175616 32196 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 04:24:50.640874 32196 solver.cpp:228] Iteration 7584, loss = 0.000165241
I0403 04:24:50.640990 32196 solver.cpp:244]     Train net output #0: loss = 0.000165265 (* 1 = 0.000165265 loss)
I0403 04:24:50.822525 32196 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 04:25:02.397924 32196 solver.cpp:228] Iteration 7600, loss = 9.74405e-05
I0403 04:25:02.398037 32196 solver.cpp:244]     Train net output #0: loss = 9.74629e-05 (* 1 = 9.74629e-05 loss)
I0403 04:25:02.583397 32196 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 04:25:14.051285 32196 solver.cpp:228] Iteration 7616, loss = 0.000228935
I0403 04:25:14.051632 32196 solver.cpp:244]     Train net output #0: loss = 0.000228958 (* 1 = 0.000228958 loss)
I0403 04:25:14.239946 32196 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 04:25:25.754256 32196 solver.cpp:228] Iteration 7632, loss = 0.000455507
I0403 04:25:25.754356 32196 solver.cpp:244]     Train net output #0: loss = 0.000455529 (* 1 = 0.000455529 loss)
I0403 04:25:25.932674 32196 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 04:25:37.372769 32196 solver.cpp:228] Iteration 7648, loss = 0.000296462
I0403 04:25:37.372880 32196 solver.cpp:244]     Train net output #0: loss = 0.000296485 (* 1 = 0.000296485 loss)
I0403 04:25:37.562460 32196 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 04:25:49.183291 32196 solver.cpp:228] Iteration 7664, loss = 0.000235713
I0403 04:25:49.183604 32196 solver.cpp:244]     Train net output #0: loss = 0.000235737 (* 1 = 0.000235737 loss)
I0403 04:25:49.346089 32196 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 04:26:01.057046 32196 solver.cpp:228] Iteration 7680, loss = 0.000585154
I0403 04:26:01.057153 32196 solver.cpp:244]     Train net output #0: loss = 0.000585177 (* 1 = 0.000585177 loss)
I0403 04:26:01.218502 32196 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 04:26:12.763380 32196 solver.cpp:228] Iteration 7696, loss = 0.00325477
I0403 04:26:12.763504 32196 solver.cpp:244]     Train net output #0: loss = 0.00325479 (* 1 = 0.00325479 loss)
I0403 04:26:12.966878 32196 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:26:24.615667 32196 solver.cpp:228] Iteration 7712, loss = 0.00213004
I0403 04:26:24.615983 32196 solver.cpp:244]     Train net output #0: loss = 0.00213007 (* 1 = 0.00213007 loss)
I0403 04:26:24.806207 32196 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 04:26:36.478498 32196 solver.cpp:228] Iteration 7728, loss = 0.000434302
I0403 04:26:36.478600 32196 solver.cpp:244]     Train net output #0: loss = 0.000434326 (* 1 = 0.000434326 loss)
I0403 04:26:36.639343 32196 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 04:26:48.161293 32196 solver.cpp:228] Iteration 7744, loss = 0.000101317
I0403 04:26:48.161417 32196 solver.cpp:244]     Train net output #0: loss = 0.000101342 (* 1 = 0.000101342 loss)
I0403 04:26:48.350932 32196 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 04:26:59.754207 32196 solver.cpp:228] Iteration 7760, loss = 0.000702666
I0403 04:26:59.754516 32196 solver.cpp:244]     Train net output #0: loss = 0.000702691 (* 1 = 0.000702691 loss)
I0403 04:26:59.942720 32196 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 04:27:11.366379 32196 solver.cpp:228] Iteration 7776, loss = 0.00437522
I0403 04:27:11.366490 32196 solver.cpp:244]     Train net output #0: loss = 0.00437525 (* 1 = 0.00437525 loss)
I0403 04:27:11.548820 32196 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 04:27:23.008239 32196 solver.cpp:228] Iteration 7792, loss = 0.00031277
I0403 04:27:23.013968 32196 solver.cpp:244]     Train net output #0: loss = 0.000312795 (* 1 = 0.000312795 loss)
I0403 04:27:23.207895 32196 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 04:27:28.336658 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7800.caffemodel
I0403 04:27:31.106813 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_7800.solverstate
I0403 04:27:32.983017 32196 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 04:28:21.912137 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990646
I0403 04:28:21.912467 32196 solver.cpp:404]     Test net output #1: loss = 0.0347349 (* 1 = 0.0347349 loss)
I0403 04:28:28.324224 32196 solver.cpp:228] Iteration 7808, loss = 0.00592365
I0403 04:28:28.324329 32196 solver.cpp:244]     Train net output #0: loss = 0.00592367 (* 1 = 0.00592367 loss)
I0403 04:28:28.471673 32196 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 04:28:40.230950 32196 solver.cpp:228] Iteration 7824, loss = 0.0103874
I0403 04:28:40.231055 32196 solver.cpp:244]     Train net output #0: loss = 0.0103874 (* 1 = 0.0103874 loss)
I0403 04:28:40.341081 32196 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 04:28:51.935997 32196 solver.cpp:228] Iteration 7840, loss = 0.000745897
I0403 04:28:51.936312 32196 solver.cpp:244]     Train net output #0: loss = 0.000745922 (* 1 = 0.000745922 loss)
I0403 04:28:52.156921 32196 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 04:29:03.812629 32196 solver.cpp:228] Iteration 7856, loss = 0.000224677
I0403 04:29:03.812731 32196 solver.cpp:244]     Train net output #0: loss = 0.000224704 (* 1 = 0.000224704 loss)
I0403 04:29:04.004258 32196 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 04:29:15.578583 32196 solver.cpp:228] Iteration 7872, loss = 0.00462566
I0403 04:29:15.578692 32196 solver.cpp:244]     Train net output #0: loss = 0.00462569 (* 1 = 0.00462569 loss)
I0403 04:29:15.762141 32196 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 04:29:27.098085 32196 solver.cpp:228] Iteration 7888, loss = 0.000326916
I0403 04:29:27.098383 32196 solver.cpp:244]     Train net output #0: loss = 0.000326943 (* 1 = 0.000326943 loss)
I0403 04:29:27.282558 32196 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 04:29:39.042510 32196 solver.cpp:228] Iteration 7904, loss = 0.000941056
I0403 04:29:39.042624 32196 solver.cpp:244]     Train net output #0: loss = 0.000941083 (* 1 = 0.000941083 loss)
I0403 04:29:39.228864 32196 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:29:50.832201 32196 solver.cpp:228] Iteration 7920, loss = 0.00219578
I0403 04:29:50.832310 32196 solver.cpp:244]     Train net output #0: loss = 0.00219581 (* 1 = 0.00219581 loss)
I0403 04:29:51.015372 32196 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 04:30:02.567405 32196 solver.cpp:228] Iteration 7936, loss = 0.000153615
I0403 04:30:02.571470 32196 solver.cpp:244]     Train net output #0: loss = 0.000153642 (* 1 = 0.000153642 loss)
I0403 04:30:02.731484 32196 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 04:30:14.325206 32196 solver.cpp:228] Iteration 7952, loss = 0.000246872
I0403 04:30:14.325317 32196 solver.cpp:244]     Train net output #0: loss = 0.0002469 (* 1 = 0.0002469 loss)
I0403 04:30:14.507426 32196 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 04:30:26.045172 32196 solver.cpp:228] Iteration 7968, loss = 0.000202567
I0403 04:30:26.045282 32196 solver.cpp:244]     Train net output #0: loss = 0.000202595 (* 1 = 0.000202595 loss)
I0403 04:30:26.231034 32196 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 04:30:37.938251 32196 solver.cpp:228] Iteration 7984, loss = 0.000935245
I0403 04:30:37.938565 32196 solver.cpp:244]     Train net output #0: loss = 0.000935273 (* 1 = 0.000935273 loss)
I0403 04:30:38.124341 32196 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 04:30:49.623353 32196 solver.cpp:228] Iteration 8000, loss = 0.000697788
I0403 04:30:49.623451 32196 solver.cpp:244]     Train net output #0: loss = 0.000697817 (* 1 = 0.000697817 loss)
I0403 04:30:49.805289 32196 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 04:31:01.219192 32196 solver.cpp:228] Iteration 8016, loss = 0.000282871
I0403 04:31:01.219293 32196 solver.cpp:244]     Train net output #0: loss = 0.0002829 (* 1 = 0.0002829 loss)
I0403 04:31:01.392407 32196 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 04:31:13.051323 32196 solver.cpp:228] Iteration 8032, loss = 0.00010184
I0403 04:31:13.052554 32196 solver.cpp:244]     Train net output #0: loss = 0.00010187 (* 1 = 0.00010187 loss)
I0403 04:31:13.243423 32196 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 04:31:24.730574 32196 solver.cpp:228] Iteration 8048, loss = 0.000784248
I0403 04:31:24.730685 32196 solver.cpp:244]     Train net output #0: loss = 0.000784278 (* 1 = 0.000784278 loss)
I0403 04:31:24.930727 32196 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 04:31:36.351016 32196 solver.cpp:228] Iteration 8064, loss = 0.000246756
I0403 04:31:36.351130 32196 solver.cpp:244]     Train net output #0: loss = 0.000246786 (* 1 = 0.000246786 loss)
I0403 04:31:36.544620 32196 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 04:31:47.891391 32196 solver.cpp:228] Iteration 8080, loss = 7.34302e-05
I0403 04:31:47.891696 32196 solver.cpp:244]     Train net output #0: loss = 7.34605e-05 (* 1 = 7.34605e-05 loss)
I0403 04:31:48.066025 32196 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 04:31:59.508994 32196 solver.cpp:228] Iteration 8096, loss = 0.000183622
I0403 04:31:59.509088 32196 solver.cpp:244]     Train net output #0: loss = 0.000183653 (* 1 = 0.000183653 loss)
I0403 04:31:59.711205 32196 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 04:32:11.251618 32196 solver.cpp:228] Iteration 8112, loss = 6.78023e-05
I0403 04:32:11.251725 32196 solver.cpp:244]     Train net output #0: loss = 6.78326e-05 (* 1 = 6.78326e-05 loss)
I0403 04:32:11.374682 32196 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 04:32:20.235738 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8125.caffemodel
I0403 04:32:23.609948 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8125.solverstate
I0403 04:32:25.532946 32196 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 04:33:14.484163 32196 solver.cpp:404]     Test net output #0: accuracy = 0.9906
I0403 04:33:14.484467 32196 solver.cpp:404]     Test net output #1: loss = 0.0348831 (* 1 = 0.0348831 loss)
I0403 04:33:17.193678 32196 solver.cpp:228] Iteration 8128, loss = 0.000300274
I0403 04:33:17.193788 32196 solver.cpp:244]     Train net output #0: loss = 0.000300304 (* 1 = 0.000300304 loss)
I0403 04:33:17.390686 32196 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 04:33:29.151567 32196 solver.cpp:228] Iteration 8144, loss = 5.30509e-05
I0403 04:33:29.151674 32196 solver.cpp:244]     Train net output #0: loss = 5.30814e-05 (* 1 = 5.30814e-05 loss)
I0403 04:33:29.352216 32196 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 04:33:40.935052 32196 solver.cpp:228] Iteration 8160, loss = 9.27849e-05
I0403 04:33:40.935168 32196 solver.cpp:244]     Train net output #0: loss = 9.28143e-05 (* 1 = 9.28143e-05 loss)
I0403 04:33:41.118263 32196 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 04:33:52.499011 32196 solver.cpp:228] Iteration 8176, loss = 0.000333497
I0403 04:33:52.499318 32196 solver.cpp:244]     Train net output #0: loss = 0.000333527 (* 1 = 0.000333527 loss)
I0403 04:33:52.727888 32196 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 04:34:04.150353 32196 solver.cpp:228] Iteration 8192, loss = 0.000164143
I0403 04:34:04.150473 32196 solver.cpp:244]     Train net output #0: loss = 0.000164173 (* 1 = 0.000164173 loss)
I0403 04:34:04.342651 32196 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 04:34:15.749956 32196 solver.cpp:228] Iteration 8208, loss = 0.000825931
I0403 04:34:15.750063 32196 solver.cpp:244]     Train net output #0: loss = 0.000825961 (* 1 = 0.000825961 loss)
I0403 04:34:15.933635 32196 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 04:34:27.445904 32196 solver.cpp:228] Iteration 8224, loss = 0.000103605
I0403 04:34:27.446205 32196 solver.cpp:244]     Train net output #0: loss = 0.000103634 (* 1 = 0.000103634 loss)
I0403 04:34:27.605352 32196 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 04:34:39.348143 32196 solver.cpp:228] Iteration 8240, loss = 0.00514859
I0403 04:34:39.349203 32196 solver.cpp:244]     Train net output #0: loss = 0.00514862 (* 1 = 0.00514862 loss)
I0403 04:34:39.514422 32196 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 04:34:51.132910 32196 solver.cpp:228] Iteration 8256, loss = 0.0014779
I0403 04:34:51.133015 32196 solver.cpp:244]     Train net output #0: loss = 0.00147793 (* 1 = 0.00147793 loss)
I0403 04:34:51.321807 32196 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 04:35:02.788458 32196 solver.cpp:228] Iteration 8272, loss = 9.364e-05
I0403 04:35:02.788764 32196 solver.cpp:244]     Train net output #0: loss = 9.36699e-05 (* 1 = 9.36699e-05 loss)
I0403 04:35:02.967059 32196 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 04:35:14.529960 32196 solver.cpp:228] Iteration 8288, loss = 6.70665e-05
I0403 04:35:14.530068 32196 solver.cpp:244]     Train net output #0: loss = 6.70964e-05 (* 1 = 6.70964e-05 loss)
I0403 04:35:14.717134 32196 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 04:35:26.287278 32196 solver.cpp:228] Iteration 8304, loss = 0.000328253
I0403 04:35:26.287376 32196 solver.cpp:244]     Train net output #0: loss = 0.000328283 (* 1 = 0.000328283 loss)
I0403 04:35:26.458989 32196 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 04:35:38.441750 32196 solver.cpp:228] Iteration 8320, loss = 6.30433e-05
I0403 04:35:38.442039 32196 solver.cpp:244]     Train net output #0: loss = 6.30732e-05 (* 1 = 6.30732e-05 loss)
I0403 04:35:38.614416 32196 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 04:35:50.229625 32196 solver.cpp:228] Iteration 8336, loss = 0.00141683
I0403 04:35:50.229737 32196 solver.cpp:244]     Train net output #0: loss = 0.00141686 (* 1 = 0.00141686 loss)
I0403 04:35:50.423290 32196 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 04:36:01.910730 32196 solver.cpp:228] Iteration 8352, loss = 0.0143939
I0403 04:36:01.910840 32196 solver.cpp:244]     Train net output #0: loss = 0.0143939 (* 1 = 0.0143939 loss)
I0403 04:36:02.102560 32196 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 04:36:13.687645 32196 solver.cpp:228] Iteration 8368, loss = 0.000138517
I0403 04:36:13.687932 32196 solver.cpp:244]     Train net output #0: loss = 0.000138548 (* 1 = 0.000138548 loss)
I0403 04:36:13.863322 32196 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 04:36:25.474184 32196 solver.cpp:228] Iteration 8384, loss = 0.000368444
I0403 04:36:25.474292 32196 solver.cpp:244]     Train net output #0: loss = 0.000368475 (* 1 = 0.000368475 loss)
I0403 04:36:25.695165 32196 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 04:36:37.257694 32196 solver.cpp:228] Iteration 8400, loss = 3.32414e-05
I0403 04:36:37.257807 32196 solver.cpp:244]     Train net output #0: loss = 3.32724e-05 (* 1 = 3.32724e-05 loss)
I0403 04:36:37.443231 32196 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 04:36:49.040907 32196 solver.cpp:228] Iteration 8416, loss = 0.0112683
I0403 04:36:49.041220 32196 solver.cpp:244]     Train net output #0: loss = 0.0112684 (* 1 = 0.0112684 loss)
I0403 04:36:49.225865 32196 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 04:37:00.658037 32196 solver.cpp:228] Iteration 8432, loss = 0.00176351
I0403 04:37:00.658149 32196 solver.cpp:244]     Train net output #0: loss = 0.00176354 (* 1 = 0.00176354 loss)
I0403 04:37:00.867876 32196 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 04:37:12.376734 32196 solver.cpp:228] Iteration 8448, loss = 8.03741e-05
I0403 04:37:12.376848 32196 solver.cpp:244]     Train net output #0: loss = 8.04082e-05 (* 1 = 8.04082e-05 loss)
I0403 04:37:12.590611 32196 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 04:37:13.329694 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8450.caffemodel
I0403 04:37:16.006875 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8450.solverstate
I0403 04:37:17.874394 32196 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 04:38:06.796430 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990508
I0403 04:38:06.796756 32196 solver.cpp:404]     Test net output #1: loss = 0.0349052 (* 1 = 0.0349052 loss)
I0403 04:38:17.503628 32196 solver.cpp:228] Iteration 8464, loss = 0.000953612
I0403 04:38:17.503739 32196 solver.cpp:244]     Train net output #0: loss = 0.000953646 (* 1 = 0.000953646 loss)
I0403 04:38:17.724443 32196 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 04:38:29.167927 32196 solver.cpp:228] Iteration 8480, loss = 0.000729222
I0403 04:38:29.168025 32196 solver.cpp:244]     Train net output #0: loss = 0.000729256 (* 1 = 0.000729256 loss)
I0403 04:38:29.342942 32196 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 04:38:40.950177 32196 solver.cpp:228] Iteration 8496, loss = 0.00210602
I0403 04:38:40.950498 32196 solver.cpp:244]     Train net output #0: loss = 0.00210606 (* 1 = 0.00210606 loss)
I0403 04:38:41.152256 32196 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 04:38:52.612098 32196 solver.cpp:228] Iteration 8512, loss = 0.000151544
I0403 04:38:52.612203 32196 solver.cpp:244]     Train net output #0: loss = 0.000151579 (* 1 = 0.000151579 loss)
I0403 04:38:52.787343 32196 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 04:39:04.269824 32196 solver.cpp:228] Iteration 8528, loss = 0.000846081
I0403 04:39:04.269932 32196 solver.cpp:244]     Train net output #0: loss = 0.000846115 (* 1 = 0.000846115 loss)
I0403 04:39:04.453820 32196 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 04:39:16.297333 32196 solver.cpp:228] Iteration 8544, loss = 0.000144479
I0403 04:39:16.297652 32196 solver.cpp:244]     Train net output #0: loss = 0.000144513 (* 1 = 0.000144513 loss)
I0403 04:39:16.489790 32196 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 04:39:28.033937 32196 solver.cpp:228] Iteration 8560, loss = 3.44087e-05
I0403 04:39:28.034046 32196 solver.cpp:244]     Train net output #0: loss = 3.44423e-05 (* 1 = 3.44423e-05 loss)
I0403 04:39:28.257663 32196 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 04:39:39.846119 32196 solver.cpp:228] Iteration 8576, loss = 0.00063624
I0403 04:39:39.846251 32196 solver.cpp:244]     Train net output #0: loss = 0.000636274 (* 1 = 0.000636274 loss)
I0403 04:39:40.071022 32196 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 04:39:51.518059 32196 solver.cpp:228] Iteration 8592, loss = 0.0130174
I0403 04:39:51.518391 32196 solver.cpp:244]     Train net output #0: loss = 0.0130175 (* 1 = 0.0130175 loss)
I0403 04:39:51.711285 32196 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 04:40:03.319938 32196 solver.cpp:228] Iteration 8608, loss = 0.000438554
I0403 04:40:03.320049 32196 solver.cpp:244]     Train net output #0: loss = 0.000438587 (* 1 = 0.000438587 loss)
I0403 04:40:03.502476 32196 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 04:40:14.991216 32196 solver.cpp:228] Iteration 8624, loss = 3.39409e-05
I0403 04:40:14.991317 32196 solver.cpp:244]     Train net output #0: loss = 3.39738e-05 (* 1 = 3.39738e-05 loss)
I0403 04:40:15.173076 32196 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 04:40:26.681869 32196 solver.cpp:228] Iteration 8640, loss = 7.01763e-05
I0403 04:40:26.682159 32196 solver.cpp:244]     Train net output #0: loss = 7.02088e-05 (* 1 = 7.02088e-05 loss)
I0403 04:40:26.870553 32196 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 04:40:38.313446 32196 solver.cpp:228] Iteration 8656, loss = 0.000110283
I0403 04:40:38.313556 32196 solver.cpp:244]     Train net output #0: loss = 0.000110316 (* 1 = 0.000110316 loss)
I0403 04:40:38.500358 32196 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 04:40:49.920835 32196 solver.cpp:228] Iteration 8672, loss = 0.000351474
I0403 04:40:49.920943 32196 solver.cpp:244]     Train net output #0: loss = 0.000351506 (* 1 = 0.000351506 loss)
I0403 04:40:50.104197 32196 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 04:41:01.595187 32196 solver.cpp:228] Iteration 8688, loss = 0.000227352
I0403 04:41:01.595546 32196 solver.cpp:244]     Train net output #0: loss = 0.000227384 (* 1 = 0.000227384 loss)
I0403 04:41:01.777434 32196 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 04:41:13.388996 32196 solver.cpp:228] Iteration 8704, loss = 0.000899996
I0403 04:41:13.389111 32196 solver.cpp:244]     Train net output #0: loss = 0.000900028 (* 1 = 0.000900028 loss)
I0403 04:41:13.573992 32196 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 04:41:25.495858 32196 solver.cpp:228] Iteration 8720, loss = 0.000227376
I0403 04:41:25.495959 32196 solver.cpp:244]     Train net output #0: loss = 0.000227407 (* 1 = 0.000227407 loss)
I0403 04:41:25.662171 32196 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 04:41:37.194942 32196 solver.cpp:228] Iteration 8736, loss = 0.0666844
I0403 04:41:37.195256 32196 solver.cpp:244]     Train net output #0: loss = 0.0666844 (* 1 = 0.0666844 loss)
I0403 04:41:37.389098 32196 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 04:41:48.925254 32196 solver.cpp:228] Iteration 8752, loss = 8.4315e-05
I0403 04:41:48.925369 32196 solver.cpp:244]     Train net output #0: loss = 8.43427e-05 (* 1 = 8.43427e-05 loss)
I0403 04:41:49.137362 32196 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 04:42:00.808368 32196 solver.cpp:228] Iteration 8768, loss = 0.000434533
I0403 04:42:00.808470 32196 solver.cpp:244]     Train net output #0: loss = 0.000434562 (* 1 = 0.000434562 loss)
I0403 04:42:00.987275 32196 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 04:42:05.476064 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8775.caffemodel
I0403 04:42:08.191534 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_8775.solverstate
I0403 04:42:10.080770 32196 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 04:42:59.022423 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990508
I0403 04:42:59.022737 32196 solver.cpp:404]     Test net output #1: loss = 0.0347734 (* 1 = 0.0347734 loss)
I0403 04:43:06.081096 32196 solver.cpp:228] Iteration 8784, loss = 0.00459568
I0403 04:43:06.081207 32196 solver.cpp:244]     Train net output #0: loss = 0.00459571 (* 1 = 0.00459571 loss)
I0403 04:43:06.263594 32196 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 04:43:17.821957 32196 solver.cpp:228] Iteration 8800, loss = 0.000263063
I0403 04:43:17.822069 32196 solver.cpp:244]     Train net output #0: loss = 0.000263091 (* 1 = 0.000263091 loss)
I0403 04:43:18.014199 32196 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 04:43:29.484719 32196 solver.cpp:228] Iteration 8816, loss = 0.00856777
I0403 04:43:29.485932 32196 solver.cpp:244]     Train net output #0: loss = 0.0085678 (* 1 = 0.0085678 loss)
I0403 04:43:29.661089 32196 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 04:43:41.191378 32196 solver.cpp:228] Iteration 8832, loss = 1.62281e-05
I0403 04:43:41.191485 32196 solver.cpp:244]     Train net output #0: loss = 1.62572e-05 (* 1 = 1.62572e-05 loss)
I0403 04:43:41.382936 32196 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 04:43:52.772964 32196 solver.cpp:228] Iteration 8848, loss = 0.000891183
I0403 04:43:52.773062 32196 solver.cpp:244]     Train net output #0: loss = 0.000891213 (* 1 = 0.000891213 loss)
I0403 04:43:52.949873 32196 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 04:44:04.376667 32196 solver.cpp:228] Iteration 8864, loss = 6.58577e-05
I0403 04:44:04.376981 32196 solver.cpp:244]     Train net output #0: loss = 6.58871e-05 (* 1 = 6.58871e-05 loss)
I0403 04:44:04.587494 32196 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 04:44:16.088099 32196 solver.cpp:228] Iteration 8880, loss = 0.000787448
I0403 04:44:16.088209 32196 solver.cpp:244]     Train net output #0: loss = 0.000787477 (* 1 = 0.000787477 loss)
I0403 04:44:16.269258 32196 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 04:44:27.966770 32196 solver.cpp:228] Iteration 8896, loss = 0.000674957
I0403 04:44:27.966879 32196 solver.cpp:244]     Train net output #0: loss = 0.000674986 (* 1 = 0.000674986 loss)
I0403 04:44:28.155344 32196 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 04:44:39.613548 32196 solver.cpp:228] Iteration 8912, loss = 0.000635115
I0403 04:44:39.613893 32196 solver.cpp:244]     Train net output #0: loss = 0.000635144 (* 1 = 0.000635144 loss)
I0403 04:44:39.814832 32196 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 04:44:51.458633 32196 solver.cpp:228] Iteration 8928, loss = 0.0127549
I0403 04:44:51.458744 32196 solver.cpp:244]     Train net output #0: loss = 0.012755 (* 1 = 0.012755 loss)
I0403 04:44:51.641548 32196 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 04:45:03.209893 32196 solver.cpp:228] Iteration 8944, loss = 0.000237006
I0403 04:45:03.210000 32196 solver.cpp:244]     Train net output #0: loss = 0.000237035 (* 1 = 0.000237035 loss)
I0403 04:45:03.414392 32196 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 04:45:14.937485 32196 solver.cpp:228] Iteration 8960, loss = 0.000312108
I0403 04:45:14.937804 32196 solver.cpp:244]     Train net output #0: loss = 0.000312136 (* 1 = 0.000312136 loss)
I0403 04:45:15.125017 32196 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 04:45:26.728829 32196 solver.cpp:228] Iteration 8976, loss = 3.85527e-05
I0403 04:45:26.728934 32196 solver.cpp:244]     Train net output #0: loss = 3.85814e-05 (* 1 = 3.85814e-05 loss)
I0403 04:45:26.894351 32196 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 04:45:38.764358 32196 solver.cpp:228] Iteration 8992, loss = 0.00120797
I0403 04:45:38.764461 32196 solver.cpp:244]     Train net output #0: loss = 0.00120799 (* 1 = 0.00120799 loss)
I0403 04:45:38.875527 32196 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 04:45:50.468525 32196 solver.cpp:228] Iteration 9008, loss = 0.000606208
I0403 04:45:50.468809 32196 solver.cpp:244]     Train net output #0: loss = 0.000606237 (* 1 = 0.000606237 loss)
I0403 04:45:50.641304 32196 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 04:46:02.220791 32196 solver.cpp:228] Iteration 9024, loss = 0.00162856
I0403 04:46:02.227251 32196 solver.cpp:244]     Train net output #0: loss = 0.00162859 (* 1 = 0.00162859 loss)
I0403 04:46:02.429910 32196 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 04:46:13.928599 32196 solver.cpp:228] Iteration 9040, loss = 7.44127e-06
I0403 04:46:13.928701 32196 solver.cpp:244]     Train net output #0: loss = 7.47118e-06 (* 1 = 7.47118e-06 loss)
I0403 04:46:14.102205 32196 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 04:46:25.566401 32196 solver.cpp:228] Iteration 9056, loss = 5.63985e-05
I0403 04:46:25.566737 32196 solver.cpp:244]     Train net output #0: loss = 5.64284e-05 (* 1 = 5.64284e-05 loss)
I0403 04:46:25.751757 32196 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 04:46:37.150404 32196 solver.cpp:228] Iteration 9072, loss = 0.00584623
I0403 04:46:37.150504 32196 solver.cpp:244]     Train net output #0: loss = 0.00584626 (* 1 = 0.00584626 loss)
I0403 04:46:37.332419 32196 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:46:48.876376 32196 solver.cpp:228] Iteration 9088, loss = 0.0028664
I0403 04:46:48.876502 32196 solver.cpp:244]     Train net output #0: loss = 0.00286643 (* 1 = 0.00286643 loss)
I0403 04:46:49.064885 32196 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 04:46:57.168172 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9100.caffemodel
I0403 04:46:59.932282 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9100.solverstate
I0403 04:47:01.740847 32196 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 04:47:50.694890 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990369
I0403 04:47:50.695178 32196 solver.cpp:404]     Test net output #1: loss = 0.034776 (* 1 = 0.034776 loss)
I0403 04:47:54.217990 32196 solver.cpp:228] Iteration 9104, loss = 0.000107594
I0403 04:47:54.218099 32196 solver.cpp:244]     Train net output #0: loss = 0.000107622 (* 1 = 0.000107622 loss)
I0403 04:47:54.423655 32196 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 04:48:06.057282 32196 solver.cpp:228] Iteration 9120, loss = 0.000241482
I0403 04:48:06.057394 32196 solver.cpp:244]     Train net output #0: loss = 0.000241509 (* 1 = 0.000241509 loss)
I0403 04:48:06.245620 32196 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 04:48:17.900439 32196 solver.cpp:228] Iteration 9136, loss = 0.000144861
I0403 04:48:17.900539 32196 solver.cpp:244]     Train net output #0: loss = 0.000144889 (* 1 = 0.000144889 loss)
I0403 04:48:18.066320 32196 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 04:48:29.573293 32196 solver.cpp:228] Iteration 9152, loss = 0.000216135
I0403 04:48:29.573612 32196 solver.cpp:244]     Train net output #0: loss = 0.000216163 (* 1 = 0.000216163 loss)
I0403 04:48:29.765617 32196 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 04:48:41.306639 32196 solver.cpp:228] Iteration 9168, loss = 8.98743e-05
I0403 04:48:41.306751 32196 solver.cpp:244]     Train net output #0: loss = 8.99017e-05 (* 1 = 8.99017e-05 loss)
I0403 04:48:41.534898 32196 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 04:48:53.393739 32196 solver.cpp:228] Iteration 9184, loss = 0.0064655
I0403 04:48:53.393851 32196 solver.cpp:244]     Train net output #0: loss = 0.00646552 (* 1 = 0.00646552 loss)
I0403 04:48:53.613399 32196 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 04:49:05.084530 32196 solver.cpp:228] Iteration 9200, loss = 0.000162479
I0403 04:49:05.084843 32196 solver.cpp:244]     Train net output #0: loss = 0.000162506 (* 1 = 0.000162506 loss)
I0403 04:49:05.263588 32196 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 04:49:16.827339 32196 solver.cpp:228] Iteration 9216, loss = 0.000472504
I0403 04:49:16.827447 32196 solver.cpp:244]     Train net output #0: loss = 0.000472531 (* 1 = 0.000472531 loss)
I0403 04:49:17.010061 32196 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 04:49:28.479110 32196 solver.cpp:228] Iteration 9232, loss = 6.68546e-05
I0403 04:49:28.479224 32196 solver.cpp:244]     Train net output #0: loss = 6.68818e-05 (* 1 = 6.68818e-05 loss)
I0403 04:49:28.671502 32196 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 04:49:40.099656 32196 solver.cpp:228] Iteration 9248, loss = 0.000352693
I0403 04:49:40.099969 32196 solver.cpp:244]     Train net output #0: loss = 0.000352721 (* 1 = 0.000352721 loss)
I0403 04:49:40.307909 32196 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 04:49:51.964010 32196 solver.cpp:228] Iteration 9264, loss = 0.000148469
I0403 04:49:51.964139 32196 solver.cpp:244]     Train net output #0: loss = 0.000148496 (* 1 = 0.000148496 loss)
I0403 04:49:52.153522 32196 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 04:50:03.509342 32196 solver.cpp:228] Iteration 9280, loss = 0.000315087
I0403 04:50:03.509450 32196 solver.cpp:244]     Train net output #0: loss = 0.000315114 (* 1 = 0.000315114 loss)
I0403 04:50:03.712643 32196 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 04:50:15.390108 32196 solver.cpp:228] Iteration 9296, loss = 0.000998307
I0403 04:50:15.390400 32196 solver.cpp:244]     Train net output #0: loss = 0.000998334 (* 1 = 0.000998334 loss)
I0403 04:50:15.587159 32196 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 04:50:27.316578 32196 solver.cpp:228] Iteration 9312, loss = 7.11009e-05
I0403 04:50:27.316687 32196 solver.cpp:244]     Train net output #0: loss = 7.11276e-05 (* 1 = 7.11276e-05 loss)
I0403 04:50:27.507731 32196 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 04:50:39.053149 32196 solver.cpp:228] Iteration 9328, loss = 0.00253295
I0403 04:50:39.053267 32196 solver.cpp:244]     Train net output #0: loss = 0.00253298 (* 1 = 0.00253298 loss)
I0403 04:50:39.318387 32196 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 04:50:50.677503 32196 solver.cpp:228] Iteration 9344, loss = 0.000162578
I0403 04:50:50.677841 32196 solver.cpp:244]     Train net output #0: loss = 0.000162605 (* 1 = 0.000162605 loss)
I0403 04:50:50.863960 32196 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 04:51:02.377183 32196 solver.cpp:228] Iteration 9360, loss = 0.000179527
I0403 04:51:02.377297 32196 solver.cpp:244]     Train net output #0: loss = 0.000179553 (* 1 = 0.000179553 loss)
I0403 04:51:02.559696 32196 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 04:51:14.204670 32196 solver.cpp:228] Iteration 9376, loss = 2.09735e-05
I0403 04:51:14.204777 32196 solver.cpp:244]     Train net output #0: loss = 2.09994e-05 (* 1 = 2.09994e-05 loss)
I0403 04:51:14.389627 32196 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 04:51:25.904997 32196 solver.cpp:228] Iteration 9392, loss = 0.00033667
I0403 04:51:25.905316 32196 solver.cpp:244]     Train net output #0: loss = 0.000336695 (* 1 = 0.000336695 loss)
I0403 04:51:26.094882 32196 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 04:51:37.658403 32196 solver.cpp:228] Iteration 9408, loss = 0.000144295
I0403 04:51:37.658514 32196 solver.cpp:244]     Train net output #0: loss = 0.00014432 (* 1 = 0.00014432 loss)
I0403 04:51:37.887137 32196 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:51:49.462146 32196 solver.cpp:228] Iteration 9424, loss = 5.94916e-05
I0403 04:51:49.462249 32196 solver.cpp:244]     Train net output #0: loss = 5.95168e-05 (* 1 = 5.95168e-05 loss)
I0403 04:51:49.607571 32196 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 04:51:49.607817 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9425.caffemodel
I0403 04:51:52.437464 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9425.solverstate
I0403 04:51:54.303866 32196 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 04:52:43.227627 32196 solver.cpp:404]     Test net output #0: accuracy = 0.9906
I0403 04:52:43.228011 32196 solver.cpp:404]     Test net output #1: loss = 0.0345861 (* 1 = 0.0345861 loss)
I0403 04:52:54.631595 32196 solver.cpp:228] Iteration 9440, loss = 0.000415197
I0403 04:52:54.631700 32196 solver.cpp:244]     Train net output #0: loss = 0.000415221 (* 1 = 0.000415221 loss)
I0403 04:52:54.785910 32196 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 04:53:06.318228 32196 solver.cpp:228] Iteration 9456, loss = 0.00248644
I0403 04:53:06.318341 32196 solver.cpp:244]     Train net output #0: loss = 0.00248647 (* 1 = 0.00248647 loss)
I0403 04:53:06.510267 32196 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 04:53:17.892155 32196 solver.cpp:228] Iteration 9472, loss = 0.000400957
I0403 04:53:17.892470 32196 solver.cpp:244]     Train net output #0: loss = 0.00040098 (* 1 = 0.00040098 loss)
I0403 04:53:18.091434 32196 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 04:53:29.773371 32196 solver.cpp:228] Iteration 9488, loss = 0.00251521
I0403 04:53:29.773493 32196 solver.cpp:244]     Train net output #0: loss = 0.00251524 (* 1 = 0.00251524 loss)
I0403 04:53:29.975952 32196 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 04:53:41.601372 32196 solver.cpp:228] Iteration 9504, loss = 0.000521534
I0403 04:53:41.601485 32196 solver.cpp:244]     Train net output #0: loss = 0.000521557 (* 1 = 0.000521557 loss)
I0403 04:53:41.799268 32196 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 04:53:53.217730 32196 solver.cpp:228] Iteration 9520, loss = 3.82841e-05
I0403 04:53:53.218035 32196 solver.cpp:244]     Train net output #0: loss = 3.83073e-05 (* 1 = 3.83073e-05 loss)
I0403 04:53:53.399495 32196 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 04:54:04.941254 32196 solver.cpp:228] Iteration 9536, loss = 0.00269207
I0403 04:54:04.941367 32196 solver.cpp:244]     Train net output #0: loss = 0.00269209 (* 1 = 0.00269209 loss)
I0403 04:54:05.133602 32196 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 04:54:16.621649 32196 solver.cpp:228] Iteration 9552, loss = 0.000489224
I0403 04:54:16.621747 32196 solver.cpp:244]     Train net output #0: loss = 0.000489246 (* 1 = 0.000489246 loss)
I0403 04:54:16.791071 32196 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 04:54:28.193053 32196 solver.cpp:228] Iteration 9568, loss = 4.60368e-05
I0403 04:54:28.193377 32196 solver.cpp:244]     Train net output #0: loss = 4.60591e-05 (* 1 = 4.60591e-05 loss)
I0403 04:54:28.383074 32196 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 04:54:39.994710 32196 solver.cpp:228] Iteration 9584, loss = 0.000591902
I0403 04:54:39.994820 32196 solver.cpp:244]     Train net output #0: loss = 0.000591925 (* 1 = 0.000591925 loss)
I0403 04:54:40.166532 32196 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 04:54:51.877616 32196 solver.cpp:228] Iteration 9600, loss = 7.01687e-05
I0403 04:54:51.877719 32196 solver.cpp:244]     Train net output #0: loss = 7.01913e-05 (* 1 = 7.01913e-05 loss)
I0403 04:54:52.047060 32196 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 04:55:03.512066 32196 solver.cpp:228] Iteration 9616, loss = 0.000720775
I0403 04:55:03.512375 32196 solver.cpp:244]     Train net output #0: loss = 0.000720797 (* 1 = 0.000720797 loss)
I0403 04:55:03.702882 32196 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 04:55:15.362988 32196 solver.cpp:228] Iteration 9632, loss = 0.000210178
I0403 04:55:15.363103 32196 solver.cpp:244]     Train net output #0: loss = 0.0002102 (* 1 = 0.0002102 loss)
I0403 04:55:15.556644 32196 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 04:55:26.982568 32196 solver.cpp:228] Iteration 9648, loss = 0.00010634
I0403 04:55:26.982676 32196 solver.cpp:244]     Train net output #0: loss = 0.000106362 (* 1 = 0.000106362 loss)
I0403 04:55:27.167140 32196 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 04:55:38.859369 32196 solver.cpp:228] Iteration 9664, loss = 0.000408276
I0403 04:55:38.859676 32196 solver.cpp:244]     Train net output #0: loss = 0.000408298 (* 1 = 0.000408298 loss)
I0403 04:55:39.054905 32196 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 04:55:50.588137 32196 solver.cpp:228] Iteration 9680, loss = 0.000347778
I0403 04:55:50.588248 32196 solver.cpp:244]     Train net output #0: loss = 0.000347801 (* 1 = 0.000347801 loss)
I0403 04:55:50.777370 32196 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 04:56:02.276986 32196 solver.cpp:228] Iteration 9696, loss = 0.0118845
I0403 04:56:02.277091 32196 solver.cpp:244]     Train net output #0: loss = 0.0118845 (* 1 = 0.0118845 loss)
I0403 04:56:02.453174 32196 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 04:56:14.027433 32196 solver.cpp:228] Iteration 9712, loss = 0.00673461
I0403 04:56:14.027696 32196 solver.cpp:244]     Train net output #0: loss = 0.00673463 (* 1 = 0.00673463 loss)
I0403 04:56:14.210330 32196 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 04:56:25.755511 32196 solver.cpp:228] Iteration 9728, loss = 0.000197679
I0403 04:56:25.755612 32196 solver.cpp:244]     Train net output #0: loss = 0.000197701 (* 1 = 0.000197701 loss)
I0403 04:56:25.886203 32196 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 04:56:37.528239 32196 solver.cpp:228] Iteration 9744, loss = 0.00221925
I0403 04:56:37.528340 32196 solver.cpp:244]     Train net output #0: loss = 0.00221927 (* 1 = 0.00221927 loss)
I0403 04:56:37.700726 32196 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:56:41.310220 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9750.caffemodel
I0403 04:56:44.100929 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9750.solverstate
I0403 04:56:45.992386 32196 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 04:57:34.912786 32196 solver.cpp:404]     Test net output #0: accuracy = 0.990738
I0403 04:57:34.913095 32196 solver.cpp:404]     Test net output #1: loss = 0.0348361 (* 1 = 0.0348361 loss)
I0403 04:57:39.275923 32196 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9756.caffemodel
I0403 04:57:42.025694 32196 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_finetune/snapshots__iter_9756.solverstate
I0403 04:57:43.895117 32196 solver.cpp:322] Optimization Done.
I0403 04:57:43.977478 32196 caffe.cpp:222] Optimization Done.
