I0403 07:30:58.927672 29785 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 07:30:58.928081 29785 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 07:30:58.928112 29785 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 07:31:02.933826 29785 caffe.cpp:185] Using GPUs 0, 1
I0403 07:31:02.934275 29785 caffe.cpp:190] GPU 0: Tesla K40m
I0403 07:31:02.934651 29785 caffe.cpp:190] GPU 1: Tesla K40m
I0403 07:31:03.144215 29785 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9756
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3252
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 07:31:03.170840 29785 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 07:31:03.185729 29785 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 07:31:03.185860 29785 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 07:31:03.187335 29785 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 07:31:03.187808 29785 layer_factory.hpp:77] Creating layer data
I0403 07:31:03.188503 29785 net.cpp:91] Creating Layer data
I0403 07:31:03.188539 29785 net.cpp:399] data -> data
I0403 07:31:03.188594 29785 net.cpp:399] data -> label
I0403 07:31:03.188632 29785 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto
I0403 07:31:03.282030 29788 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-60-40/train_db
I0403 07:31:03.348959 29785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:31:03.466367 29785 net.cpp:141] Setting up data
I0403 07:31:03.466455 29785 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 07:31:03.466476 29785 net.cpp:148] Top shape: 100 (100)
I0403 07:31:03.466495 29785 net.cpp:156] Memory required for data: 61835200
I0403 07:31:03.466526 29785 layer_factory.hpp:77] Creating layer conv1
I0403 07:31:03.466570 29785 net.cpp:91] Creating Layer conv1
I0403 07:31:03.466594 29785 net.cpp:425] conv1 <- data
I0403 07:31:03.466627 29785 net.cpp:399] conv1 -> conv1
I0403 07:31:03.469344 29785 net.cpp:141] Setting up conv1
I0403 07:31:03.469377 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:03.469395 29785 net.cpp:156] Memory required for data: 177995200
I0403 07:31:03.469432 29785 layer_factory.hpp:77] Creating layer relu1
I0403 07:31:03.469461 29785 net.cpp:91] Creating Layer relu1
I0403 07:31:03.469480 29785 net.cpp:425] relu1 <- conv1
I0403 07:31:03.469499 29785 net.cpp:386] relu1 -> conv1 (in-place)
I0403 07:31:03.469526 29785 net.cpp:141] Setting up relu1
I0403 07:31:03.469547 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:03.469563 29785 net.cpp:156] Memory required for data: 294155200
I0403 07:31:03.469578 29785 layer_factory.hpp:77] Creating layer norm1
I0403 07:31:03.469597 29785 net.cpp:91] Creating Layer norm1
I0403 07:31:03.469648 29785 net.cpp:425] norm1 <- conv1
I0403 07:31:03.469668 29785 net.cpp:399] norm1 -> norm1
I0403 07:31:03.475389 29785 net.cpp:141] Setting up norm1
I0403 07:31:03.475426 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:03.475443 29785 net.cpp:156] Memory required for data: 410315200
I0403 07:31:03.475460 29785 layer_factory.hpp:77] Creating layer pool1
I0403 07:31:03.475481 29785 net.cpp:91] Creating Layer pool1
I0403 07:31:03.475500 29785 net.cpp:425] pool1 <- norm1
I0403 07:31:03.475520 29785 net.cpp:399] pool1 -> pool1
I0403 07:31:03.475584 29785 net.cpp:141] Setting up pool1
I0403 07:31:03.475610 29785 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 07:31:03.475627 29785 net.cpp:156] Memory required for data: 438308800
I0403 07:31:03.475643 29785 layer_factory.hpp:77] Creating layer conv2
I0403 07:31:03.475667 29785 net.cpp:91] Creating Layer conv2
I0403 07:31:03.475685 29785 net.cpp:425] conv2 <- pool1
I0403 07:31:03.475705 29785 net.cpp:399] conv2 -> conv2
I0403 07:31:03.477262 29790 blocking_queue.cpp:50] Waiting for data
I0403 07:31:03.492971 29785 net.cpp:141] Setting up conv2
I0403 07:31:03.493003 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:03.493021 29785 net.cpp:156] Memory required for data: 512958400
I0403 07:31:03.493043 29785 layer_factory.hpp:77] Creating layer relu2
I0403 07:31:03.493064 29785 net.cpp:91] Creating Layer relu2
I0403 07:31:03.493088 29785 net.cpp:425] relu2 <- conv2
I0403 07:31:03.493106 29785 net.cpp:386] relu2 -> conv2 (in-place)
I0403 07:31:03.493127 29785 net.cpp:141] Setting up relu2
I0403 07:31:03.493145 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:03.493160 29785 net.cpp:156] Memory required for data: 587608000
I0403 07:31:03.493175 29785 layer_factory.hpp:77] Creating layer norm2
I0403 07:31:03.493194 29785 net.cpp:91] Creating Layer norm2
I0403 07:31:03.493211 29785 net.cpp:425] norm2 <- conv2
I0403 07:31:03.493229 29785 net.cpp:399] norm2 -> norm2
I0403 07:31:03.493275 29785 net.cpp:141] Setting up norm2
I0403 07:31:03.493299 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:03.493312 29785 net.cpp:156] Memory required for data: 662257600
I0403 07:31:03.493329 29785 layer_factory.hpp:77] Creating layer pool2
I0403 07:31:03.493348 29785 net.cpp:91] Creating Layer pool2
I0403 07:31:03.493365 29785 net.cpp:425] pool2 <- norm2
I0403 07:31:03.493383 29785 net.cpp:399] pool2 -> pool2
I0403 07:31:03.493428 29785 net.cpp:141] Setting up pool2
I0403 07:31:03.493450 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:03.493466 29785 net.cpp:156] Memory required for data: 679563200
I0403 07:31:03.493481 29785 layer_factory.hpp:77] Creating layer conv3
I0403 07:31:03.493505 29785 net.cpp:91] Creating Layer conv3
I0403 07:31:03.493522 29785 net.cpp:425] conv3 <- pool2
I0403 07:31:03.493542 29785 net.cpp:399] conv3 -> conv3
I0403 07:31:03.527570 29785 net.cpp:141] Setting up conv3
I0403 07:31:03.527603 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:03.527621 29785 net.cpp:156] Memory required for data: 705521600
I0403 07:31:03.527643 29785 layer_factory.hpp:77] Creating layer relu3
I0403 07:31:03.527664 29785 net.cpp:91] Creating Layer relu3
I0403 07:31:03.527683 29785 net.cpp:425] relu3 <- conv3
I0403 07:31:03.527700 29785 net.cpp:386] relu3 -> conv3 (in-place)
I0403 07:31:03.527720 29785 net.cpp:141] Setting up relu3
I0403 07:31:03.527739 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:03.527755 29785 net.cpp:156] Memory required for data: 731480000
I0403 07:31:03.527770 29785 layer_factory.hpp:77] Creating layer conv4
I0403 07:31:03.527791 29785 net.cpp:91] Creating Layer conv4
I0403 07:31:03.527809 29785 net.cpp:425] conv4 <- conv3
I0403 07:31:03.527828 29785 net.cpp:399] conv4 -> conv4
I0403 07:31:03.554026 29785 net.cpp:141] Setting up conv4
I0403 07:31:03.554060 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:03.554081 29785 net.cpp:156] Memory required for data: 757438400
I0403 07:31:03.554128 29785 layer_factory.hpp:77] Creating layer relu4
I0403 07:31:03.554150 29785 net.cpp:91] Creating Layer relu4
I0403 07:31:03.554167 29785 net.cpp:425] relu4 <- conv4
I0403 07:31:03.554186 29785 net.cpp:386] relu4 -> conv4 (in-place)
I0403 07:31:03.554206 29785 net.cpp:141] Setting up relu4
I0403 07:31:03.554225 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:03.554240 29785 net.cpp:156] Memory required for data: 783396800
I0403 07:31:03.554255 29785 layer_factory.hpp:77] Creating layer conv5
I0403 07:31:03.554277 29785 net.cpp:91] Creating Layer conv5
I0403 07:31:03.554296 29785 net.cpp:425] conv5 <- conv4
I0403 07:31:03.554316 29785 net.cpp:399] conv5 -> conv5
I0403 07:31:03.571478 29785 net.cpp:141] Setting up conv5
I0403 07:31:03.571509 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:03.571527 29785 net.cpp:156] Memory required for data: 800702400
I0403 07:31:03.571548 29785 layer_factory.hpp:77] Creating layer relu5
I0403 07:31:03.571568 29785 net.cpp:91] Creating Layer relu5
I0403 07:31:03.571585 29785 net.cpp:425] relu5 <- conv5
I0403 07:31:03.571615 29785 net.cpp:386] relu5 -> conv5 (in-place)
I0403 07:31:03.571633 29785 net.cpp:141] Setting up relu5
I0403 07:31:03.571650 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:03.571665 29785 net.cpp:156] Memory required for data: 818008000
I0403 07:31:03.571691 29785 layer_factory.hpp:77] Creating layer pool5
I0403 07:31:03.571712 29785 net.cpp:91] Creating Layer pool5
I0403 07:31:03.571732 29785 net.cpp:425] pool5 <- conv5
I0403 07:31:03.571749 29785 net.cpp:399] pool5 -> pool5
I0403 07:31:03.571799 29785 net.cpp:141] Setting up pool5
I0403 07:31:03.571820 29785 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 07:31:03.571835 29785 net.cpp:156] Memory required for data: 821694400
I0403 07:31:03.571851 29785 layer_factory.hpp:77] Creating layer fc6
I0403 07:31:03.571878 29785 net.cpp:91] Creating Layer fc6
I0403 07:31:03.571897 29785 net.cpp:425] fc6 <- pool5
I0403 07:31:03.571915 29785 net.cpp:399] fc6 -> fc6
I0403 07:31:04.965812 29785 net.cpp:141] Setting up fc6
I0403 07:31:04.965894 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:04.965910 29785 net.cpp:156] Memory required for data: 823332800
I0403 07:31:04.965934 29785 layer_factory.hpp:77] Creating layer relu6
I0403 07:31:04.965960 29785 net.cpp:91] Creating Layer relu6
I0403 07:31:04.965976 29785 net.cpp:425] relu6 <- fc6
I0403 07:31:04.966001 29785 net.cpp:386] relu6 -> fc6 (in-place)
I0403 07:31:04.966023 29785 net.cpp:141] Setting up relu6
I0403 07:31:04.966042 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:04.966055 29785 net.cpp:156] Memory required for data: 824971200
I0403 07:31:04.966070 29785 layer_factory.hpp:77] Creating layer drop6
I0403 07:31:04.966109 29785 net.cpp:91] Creating Layer drop6
I0403 07:31:04.966127 29785 net.cpp:425] drop6 <- fc6
I0403 07:31:04.966145 29785 net.cpp:386] drop6 -> fc6 (in-place)
I0403 07:31:04.966190 29785 net.cpp:141] Setting up drop6
I0403 07:31:04.966213 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:04.966228 29785 net.cpp:156] Memory required for data: 826609600
I0403 07:31:04.966243 29785 layer_factory.hpp:77] Creating layer fc7
I0403 07:31:04.966262 29785 net.cpp:91] Creating Layer fc7
I0403 07:31:04.966279 29785 net.cpp:425] fc7 <- fc6
I0403 07:31:04.966296 29785 net.cpp:399] fc7 -> fc7
I0403 07:31:05.571027 29785 net.cpp:141] Setting up fc7
I0403 07:31:05.571115 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:05.571132 29785 net.cpp:156] Memory required for data: 828248000
I0403 07:31:05.571154 29785 layer_factory.hpp:77] Creating layer relu7
I0403 07:31:05.571178 29785 net.cpp:91] Creating Layer relu7
I0403 07:31:05.571195 29785 net.cpp:425] relu7 <- fc7
I0403 07:31:05.571216 29785 net.cpp:386] relu7 -> fc7 (in-place)
I0403 07:31:05.571240 29785 net.cpp:141] Setting up relu7
I0403 07:31:05.571257 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:05.571271 29785 net.cpp:156] Memory required for data: 829886400
I0403 07:31:05.571285 29785 layer_factory.hpp:77] Creating layer drop7
I0403 07:31:05.571354 29785 net.cpp:91] Creating Layer drop7
I0403 07:31:05.571372 29785 net.cpp:425] drop7 <- fc7
I0403 07:31:05.571391 29785 net.cpp:386] drop7 -> fc7 (in-place)
I0403 07:31:05.571430 29785 net.cpp:141] Setting up drop7
I0403 07:31:05.571452 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:05.571468 29785 net.cpp:156] Memory required for data: 831524800
I0403 07:31:05.571482 29785 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 07:31:05.571506 29785 net.cpp:91] Creating Layer fc8_plantvillage
I0403 07:31:05.571521 29785 net.cpp:425] fc8_plantvillage <- fc7
I0403 07:31:05.571540 29785 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 07:31:05.577740 29785 net.cpp:141] Setting up fc8_plantvillage
I0403 07:31:05.577769 29785 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:31:05.577785 29785 net.cpp:156] Memory required for data: 831540000
I0403 07:31:05.577802 29785 layer_factory.hpp:77] Creating layer loss
I0403 07:31:05.577826 29785 net.cpp:91] Creating Layer loss
I0403 07:31:05.577843 29785 net.cpp:425] loss <- fc8_plantvillage
I0403 07:31:05.577859 29785 net.cpp:425] loss <- label
I0403 07:31:05.577879 29785 net.cpp:399] loss -> loss
I0403 07:31:05.577908 29785 layer_factory.hpp:77] Creating layer loss
I0403 07:31:05.578007 29785 net.cpp:141] Setting up loss
I0403 07:31:05.578032 29785 net.cpp:148] Top shape: (1)
I0403 07:31:05.578047 29785 net.cpp:151]     with loss weight 1
I0403 07:31:05.578105 29785 net.cpp:156] Memory required for data: 831540004
I0403 07:31:05.578121 29785 net.cpp:217] loss needs backward computation.
I0403 07:31:05.578137 29785 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 07:31:05.578152 29785 net.cpp:217] drop7 needs backward computation.
I0403 07:31:05.578166 29785 net.cpp:217] relu7 needs backward computation.
I0403 07:31:05.578179 29785 net.cpp:217] fc7 needs backward computation.
I0403 07:31:05.578193 29785 net.cpp:217] drop6 needs backward computation.
I0403 07:31:05.578207 29785 net.cpp:217] relu6 needs backward computation.
I0403 07:31:05.578220 29785 net.cpp:217] fc6 needs backward computation.
I0403 07:31:05.578235 29785 net.cpp:217] pool5 needs backward computation.
I0403 07:31:05.578249 29785 net.cpp:217] relu5 needs backward computation.
I0403 07:31:05.578263 29785 net.cpp:217] conv5 needs backward computation.
I0403 07:31:05.578277 29785 net.cpp:217] relu4 needs backward computation.
I0403 07:31:05.578290 29785 net.cpp:217] conv4 needs backward computation.
I0403 07:31:05.578305 29785 net.cpp:217] relu3 needs backward computation.
I0403 07:31:05.578320 29785 net.cpp:217] conv3 needs backward computation.
I0403 07:31:05.578335 29785 net.cpp:217] pool2 needs backward computation.
I0403 07:31:05.578347 29785 net.cpp:217] norm2 needs backward computation.
I0403 07:31:05.578362 29785 net.cpp:217] relu2 needs backward computation.
I0403 07:31:05.578375 29785 net.cpp:217] conv2 needs backward computation.
I0403 07:31:05.578390 29785 net.cpp:217] pool1 needs backward computation.
I0403 07:31:05.578405 29785 net.cpp:217] norm1 needs backward computation.
I0403 07:31:05.578419 29785 net.cpp:217] relu1 needs backward computation.
I0403 07:31:05.578433 29785 net.cpp:217] conv1 needs backward computation.
I0403 07:31:05.578447 29785 net.cpp:219] data does not need backward computation.
I0403 07:31:05.578461 29785 net.cpp:261] This network produces output loss
I0403 07:31:05.578487 29785 net.cpp:274] Network initialization done.
I0403 07:31:05.579527 29785 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 07:31:05.579586 29785 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 07:31:05.580217 29785 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 07:31:05.580374 29785 layer_factory.hpp:77] Creating layer data
I0403 07:31:05.580538 29785 net.cpp:91] Creating Layer data
I0403 07:31:05.580565 29785 net.cpp:399] data -> data
I0403 07:31:05.580590 29785 net.cpp:399] data -> label
I0403 07:31:05.580616 29785 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-60-40/mean.binaryproto
I0403 07:31:05.656731 29791 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-60-40/test_db
I0403 07:31:05.698138 29785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:31:05.843577 29785 net.cpp:141] Setting up data
I0403 07:31:05.843652 29785 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 07:31:05.843679 29785 net.cpp:148] Top shape: 100 (100)
I0403 07:31:05.843708 29785 net.cpp:156] Memory required for data: 61835200
I0403 07:31:05.843731 29785 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 07:31:05.843765 29785 net.cpp:91] Creating Layer label_data_1_split
I0403 07:31:05.843788 29785 net.cpp:425] label_data_1_split <- label
I0403 07:31:05.843818 29785 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 07:31:05.843850 29785 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 07:31:05.843914 29785 net.cpp:141] Setting up label_data_1_split
I0403 07:31:05.843941 29785 net.cpp:148] Top shape: 100 (100)
I0403 07:31:05.843966 29785 net.cpp:148] Top shape: 100 (100)
I0403 07:31:05.843997 29785 net.cpp:156] Memory required for data: 61836000
I0403 07:31:05.844018 29785 layer_factory.hpp:77] Creating layer conv1
I0403 07:31:05.844055 29785 net.cpp:91] Creating Layer conv1
I0403 07:31:05.844074 29785 net.cpp:425] conv1 <- data
I0403 07:31:05.844099 29785 net.cpp:399] conv1 -> conv1
I0403 07:31:05.845742 29785 net.cpp:141] Setting up conv1
I0403 07:31:05.845774 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:05.845796 29785 net.cpp:156] Memory required for data: 177996000
I0403 07:31:05.845825 29785 layer_factory.hpp:77] Creating layer relu1
I0403 07:31:05.845850 29785 net.cpp:91] Creating Layer relu1
I0403 07:31:05.845873 29785 net.cpp:425] relu1 <- conv1
I0403 07:31:05.845893 29785 net.cpp:386] relu1 -> conv1 (in-place)
I0403 07:31:05.845917 29785 net.cpp:141] Setting up relu1
I0403 07:31:05.845940 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:05.845962 29785 net.cpp:156] Memory required for data: 294156000
I0403 07:31:05.845979 29785 layer_factory.hpp:77] Creating layer norm1
I0403 07:31:05.846001 29785 net.cpp:91] Creating Layer norm1
I0403 07:31:05.846024 29785 net.cpp:425] norm1 <- conv1
I0403 07:31:05.846047 29785 net.cpp:399] norm1 -> norm1
I0403 07:31:05.846107 29785 net.cpp:141] Setting up norm1
I0403 07:31:05.846139 29785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:31:05.846159 29785 net.cpp:156] Memory required for data: 410316000
I0403 07:31:05.846179 29785 layer_factory.hpp:77] Creating layer pool1
I0403 07:31:05.846209 29785 net.cpp:91] Creating Layer pool1
I0403 07:31:05.846226 29785 net.cpp:425] pool1 <- norm1
I0403 07:31:05.846249 29785 net.cpp:399] pool1 -> pool1
I0403 07:31:05.846304 29785 net.cpp:141] Setting up pool1
I0403 07:31:05.846330 29785 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 07:31:05.846351 29785 net.cpp:156] Memory required for data: 438309600
I0403 07:31:05.846406 29785 layer_factory.hpp:77] Creating layer conv2
I0403 07:31:05.846433 29785 net.cpp:91] Creating Layer conv2
I0403 07:31:05.846457 29785 net.cpp:425] conv2 <- pool1
I0403 07:31:05.846485 29785 net.cpp:399] conv2 -> conv2
I0403 07:31:05.859127 29785 net.cpp:141] Setting up conv2
I0403 07:31:05.859161 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:05.859177 29785 net.cpp:156] Memory required for data: 512959200
I0403 07:31:05.859201 29785 layer_factory.hpp:77] Creating layer relu2
I0403 07:31:05.859221 29785 net.cpp:91] Creating Layer relu2
I0403 07:31:05.859238 29785 net.cpp:425] relu2 <- conv2
I0403 07:31:05.859257 29785 net.cpp:386] relu2 -> conv2 (in-place)
I0403 07:31:05.859278 29785 net.cpp:141] Setting up relu2
I0403 07:31:05.859297 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:05.859311 29785 net.cpp:156] Memory required for data: 587608800
I0403 07:31:05.859326 29785 layer_factory.hpp:77] Creating layer norm2
I0403 07:31:05.859346 29785 net.cpp:91] Creating Layer norm2
I0403 07:31:05.859364 29785 net.cpp:425] norm2 <- conv2
I0403 07:31:05.859382 29785 net.cpp:399] norm2 -> norm2
I0403 07:31:05.859433 29785 net.cpp:141] Setting up norm2
I0403 07:31:05.859457 29785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:31:05.859472 29785 net.cpp:156] Memory required for data: 662258400
I0403 07:31:05.859488 29785 layer_factory.hpp:77] Creating layer pool2
I0403 07:31:05.859506 29785 net.cpp:91] Creating Layer pool2
I0403 07:31:05.859524 29785 net.cpp:425] pool2 <- norm2
I0403 07:31:05.859541 29785 net.cpp:399] pool2 -> pool2
I0403 07:31:05.859589 29785 net.cpp:141] Setting up pool2
I0403 07:31:05.859612 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:05.859627 29785 net.cpp:156] Memory required for data: 679564000
I0403 07:31:05.859645 29785 layer_factory.hpp:77] Creating layer conv3
I0403 07:31:05.859671 29785 net.cpp:91] Creating Layer conv3
I0403 07:31:05.859695 29785 net.cpp:425] conv3 <- pool2
I0403 07:31:05.859715 29785 net.cpp:399] conv3 -> conv3
I0403 07:31:05.895934 29785 net.cpp:141] Setting up conv3
I0403 07:31:05.895987 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:05.896005 29785 net.cpp:156] Memory required for data: 705522400
I0403 07:31:05.896033 29785 layer_factory.hpp:77] Creating layer relu3
I0403 07:31:05.896059 29785 net.cpp:91] Creating Layer relu3
I0403 07:31:05.896078 29785 net.cpp:425] relu3 <- conv3
I0403 07:31:05.896098 29785 net.cpp:386] relu3 -> conv3 (in-place)
I0403 07:31:05.896133 29785 net.cpp:141] Setting up relu3
I0403 07:31:05.896155 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:05.896172 29785 net.cpp:156] Memory required for data: 731480800
I0403 07:31:05.896188 29785 layer_factory.hpp:77] Creating layer conv4
I0403 07:31:05.896214 29785 net.cpp:91] Creating Layer conv4
I0403 07:31:05.896230 29785 net.cpp:425] conv4 <- conv3
I0403 07:31:05.896252 29785 net.cpp:399] conv4 -> conv4
I0403 07:31:05.923517 29785 net.cpp:141] Setting up conv4
I0403 07:31:05.923554 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:05.923571 29785 net.cpp:156] Memory required for data: 757439200
I0403 07:31:05.923591 29785 layer_factory.hpp:77] Creating layer relu4
I0403 07:31:05.923614 29785 net.cpp:91] Creating Layer relu4
I0403 07:31:05.923631 29785 net.cpp:425] relu4 <- conv4
I0403 07:31:05.923651 29785 net.cpp:386] relu4 -> conv4 (in-place)
I0403 07:31:05.923672 29785 net.cpp:141] Setting up relu4
I0403 07:31:05.923691 29785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:31:05.923708 29785 net.cpp:156] Memory required for data: 783397600
I0403 07:31:05.923724 29785 layer_factory.hpp:77] Creating layer conv5
I0403 07:31:05.923748 29785 net.cpp:91] Creating Layer conv5
I0403 07:31:05.923765 29785 net.cpp:425] conv5 <- conv4
I0403 07:31:05.923785 29785 net.cpp:399] conv5 -> conv5
I0403 07:31:05.942044 29785 net.cpp:141] Setting up conv5
I0403 07:31:05.942076 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:05.942095 29785 net.cpp:156] Memory required for data: 800703200
I0403 07:31:05.942159 29785 layer_factory.hpp:77] Creating layer relu5
I0403 07:31:05.942185 29785 net.cpp:91] Creating Layer relu5
I0403 07:31:05.942205 29785 net.cpp:425] relu5 <- conv5
I0403 07:31:05.942226 29785 net.cpp:386] relu5 -> conv5 (in-place)
I0403 07:31:05.942252 29785 net.cpp:141] Setting up relu5
I0403 07:31:05.942277 29785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:31:05.942299 29785 net.cpp:156] Memory required for data: 818008800
I0403 07:31:05.942322 29785 layer_factory.hpp:77] Creating layer pool5
I0403 07:31:05.942349 29785 net.cpp:91] Creating Layer pool5
I0403 07:31:05.942378 29785 net.cpp:425] pool5 <- conv5
I0403 07:31:05.942400 29785 net.cpp:399] pool5 -> pool5
I0403 07:31:05.942461 29785 net.cpp:141] Setting up pool5
I0403 07:31:05.942487 29785 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 07:31:05.942503 29785 net.cpp:156] Memory required for data: 821695200
I0403 07:31:05.942520 29785 layer_factory.hpp:77] Creating layer fc6
I0403 07:31:05.942543 29785 net.cpp:91] Creating Layer fc6
I0403 07:31:05.942560 29785 net.cpp:425] fc6 <- pool5
I0403 07:31:05.942584 29785 net.cpp:399] fc6 -> fc6
I0403 07:31:07.393555 29785 net.cpp:141] Setting up fc6
I0403 07:31:07.393635 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:07.393651 29785 net.cpp:156] Memory required for data: 823333600
I0403 07:31:07.393674 29785 layer_factory.hpp:77] Creating layer relu6
I0403 07:31:07.393700 29785 net.cpp:91] Creating Layer relu6
I0403 07:31:07.393718 29785 net.cpp:425] relu6 <- fc6
I0403 07:31:07.393740 29785 net.cpp:386] relu6 -> fc6 (in-place)
I0403 07:31:07.393764 29785 net.cpp:141] Setting up relu6
I0403 07:31:07.393781 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:07.393795 29785 net.cpp:156] Memory required for data: 824972000
I0403 07:31:07.393810 29785 layer_factory.hpp:77] Creating layer drop6
I0403 07:31:07.393831 29785 net.cpp:91] Creating Layer drop6
I0403 07:31:07.393846 29785 net.cpp:425] drop6 <- fc6
I0403 07:31:07.393863 29785 net.cpp:386] drop6 -> fc6 (in-place)
I0403 07:31:07.393906 29785 net.cpp:141] Setting up drop6
I0403 07:31:07.393928 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:07.393942 29785 net.cpp:156] Memory required for data: 826610400
I0403 07:31:07.393957 29785 layer_factory.hpp:77] Creating layer fc7
I0403 07:31:07.393977 29785 net.cpp:91] Creating Layer fc7
I0403 07:31:07.393992 29785 net.cpp:425] fc7 <- fc6
I0403 07:31:07.394011 29785 net.cpp:399] fc7 -> fc7
I0403 07:31:08.002835 29785 net.cpp:141] Setting up fc7
I0403 07:31:08.002917 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:08.002933 29785 net.cpp:156] Memory required for data: 828248800
I0403 07:31:08.002956 29785 layer_factory.hpp:77] Creating layer relu7
I0403 07:31:08.002981 29785 net.cpp:91] Creating Layer relu7
I0403 07:31:08.003000 29785 net.cpp:425] relu7 <- fc7
I0403 07:31:08.003023 29785 net.cpp:386] relu7 -> fc7 (in-place)
I0403 07:31:08.003046 29785 net.cpp:141] Setting up relu7
I0403 07:31:08.003065 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:08.003079 29785 net.cpp:156] Memory required for data: 829887200
I0403 07:31:08.003093 29785 layer_factory.hpp:77] Creating layer drop7
I0403 07:31:08.003114 29785 net.cpp:91] Creating Layer drop7
I0403 07:31:08.003132 29785 net.cpp:425] drop7 <- fc7
I0403 07:31:08.003152 29785 net.cpp:386] drop7 -> fc7 (in-place)
I0403 07:31:08.003193 29785 net.cpp:141] Setting up drop7
I0403 07:31:08.003216 29785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:31:08.003229 29785 net.cpp:156] Memory required for data: 831525600
I0403 07:31:08.003243 29785 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 07:31:08.003265 29785 net.cpp:91] Creating Layer fc8_plantvillage
I0403 07:31:08.003283 29785 net.cpp:425] fc8_plantvillage <- fc7
I0403 07:31:08.003301 29785 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 07:31:08.009294 29785 net.cpp:141] Setting up fc8_plantvillage
I0403 07:31:08.009323 29785 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:31:08.009383 29785 net.cpp:156] Memory required for data: 831540800
I0403 07:31:08.009403 29785 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:31:08.009423 29785 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:31:08.009440 29785 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 07:31:08.009461 29785 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 07:31:08.009484 29785 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 07:31:08.009532 29785 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:31:08.009557 29785 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:31:08.009574 29785 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:31:08.009589 29785 net.cpp:156] Memory required for data: 831571200
I0403 07:31:08.009604 29785 layer_factory.hpp:77] Creating layer loss
I0403 07:31:08.009635 29785 net.cpp:91] Creating Layer loss
I0403 07:31:08.009650 29785 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 07:31:08.009666 29785 net.cpp:425] loss <- label_data_1_split_0
I0403 07:31:08.009683 29785 net.cpp:399] loss -> loss
I0403 07:31:08.009706 29785 layer_factory.hpp:77] Creating layer loss
I0403 07:31:08.009798 29785 net.cpp:141] Setting up loss
I0403 07:31:08.009819 29785 net.cpp:148] Top shape: (1)
I0403 07:31:08.009834 29785 net.cpp:151]     with loss weight 1
I0403 07:31:08.009856 29785 net.cpp:156] Memory required for data: 831571204
I0403 07:31:08.009871 29785 layer_factory.hpp:77] Creating layer accuracy
I0403 07:31:08.009891 29785 net.cpp:91] Creating Layer accuracy
I0403 07:31:08.009907 29785 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 07:31:08.009922 29785 net.cpp:425] accuracy <- label_data_1_split_1
I0403 07:31:08.009941 29785 net.cpp:399] accuracy -> accuracy
I0403 07:31:08.009969 29785 net.cpp:141] Setting up accuracy
I0403 07:31:08.009989 29785 net.cpp:148] Top shape: (1)
I0403 07:31:08.010004 29785 net.cpp:156] Memory required for data: 831571208
I0403 07:31:08.010018 29785 net.cpp:219] accuracy does not need backward computation.
I0403 07:31:08.010033 29785 net.cpp:217] loss needs backward computation.
I0403 07:31:08.010048 29785 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 07:31:08.010063 29785 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 07:31:08.010077 29785 net.cpp:217] drop7 needs backward computation.
I0403 07:31:08.010092 29785 net.cpp:217] relu7 needs backward computation.
I0403 07:31:08.010104 29785 net.cpp:217] fc7 needs backward computation.
I0403 07:31:08.010124 29785 net.cpp:217] drop6 needs backward computation.
I0403 07:31:08.010139 29785 net.cpp:217] relu6 needs backward computation.
I0403 07:31:08.010152 29785 net.cpp:217] fc6 needs backward computation.
I0403 07:31:08.010166 29785 net.cpp:217] pool5 needs backward computation.
I0403 07:31:08.010180 29785 net.cpp:217] relu5 needs backward computation.
I0403 07:31:08.010195 29785 net.cpp:217] conv5 needs backward computation.
I0403 07:31:08.010210 29785 net.cpp:217] relu4 needs backward computation.
I0403 07:31:08.010223 29785 net.cpp:217] conv4 needs backward computation.
I0403 07:31:08.010238 29785 net.cpp:217] relu3 needs backward computation.
I0403 07:31:08.010252 29785 net.cpp:217] conv3 needs backward computation.
I0403 07:31:08.010265 29785 net.cpp:217] pool2 needs backward computation.
I0403 07:31:08.010280 29785 net.cpp:217] norm2 needs backward computation.
I0403 07:31:08.010294 29785 net.cpp:217] relu2 needs backward computation.
I0403 07:31:08.010309 29785 net.cpp:217] conv2 needs backward computation.
I0403 07:31:08.010324 29785 net.cpp:217] pool1 needs backward computation.
I0403 07:31:08.010339 29785 net.cpp:217] norm1 needs backward computation.
I0403 07:31:08.010352 29785 net.cpp:217] relu1 needs backward computation.
I0403 07:31:08.010365 29785 net.cpp:217] conv1 needs backward computation.
I0403 07:31:08.010393 29785 net.cpp:219] label_data_1_split does not need backward computation.
I0403 07:31:08.010409 29785 net.cpp:219] data does not need backward computation.
I0403 07:31:08.010423 29785 net.cpp:261] This network produces output accuracy
I0403 07:31:08.010437 29785 net.cpp:261] This network produces output loss
I0403 07:31:08.010467 29785 net.cpp:274] Network initialization done.
I0403 07:31:08.010570 29785 solver.cpp:60] Solver scaffolding done.
I0403 07:31:08.034277 29785 parallel.cpp:392] GPUs pairs 0:1
I0403 07:31:08.289760 29785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:31:10.675026 29785 parallel.cpp:425] Starting Optimization
I0403 07:31:10.675190 29785 solver.cpp:279] Solving 
I0403 07:31:10.675215 29785 solver.cpp:280] Learning Rate Policy: step
I0403 07:31:10.675390 29785 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 07:32:00.249194 29785 solver.cpp:404]     Test net output #0: accuracy = 0.031659
I0403 07:32:00.249383 29785 solver.cpp:404]     Test net output #1: loss = 3.65433 (* 1 = 3.65433 loss)
I0403 07:32:00.824787 29785 solver.cpp:228] Iteration 0, loss = 3.65556
I0403 07:32:00.824867 29785 solver.cpp:244]     Train net output #0: loss = 3.65556 (* 1 = 3.65556 loss)
I0403 07:32:01.013589 29785 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 07:32:12.521407 29785 solver.cpp:228] Iteration 16, loss = 3.31594
I0403 07:32:12.521488 29785 solver.cpp:244]     Train net output #0: loss = 3.31594 (* 1 = 3.31594 loss)
I0403 07:32:12.723248 29785 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 07:32:24.102154 29785 solver.cpp:228] Iteration 32, loss = 2.98422
I0403 07:32:24.102224 29785 solver.cpp:244]     Train net output #0: loss = 2.98422 (* 1 = 2.98422 loss)
I0403 07:32:24.274987 29785 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 07:32:35.840422 29785 solver.cpp:228] Iteration 48, loss = 3.19967
I0403 07:32:35.840679 29785 solver.cpp:244]     Train net output #0: loss = 3.19967 (* 1 = 3.19967 loss)
I0403 07:32:36.014196 29785 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 07:32:47.364424 29785 solver.cpp:228] Iteration 64, loss = 2.6952
I0403 07:32:47.364506 29785 solver.cpp:244]     Train net output #0: loss = 2.6952 (* 1 = 2.6952 loss)
I0403 07:32:47.565704 29785 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 07:32:59.155797 29785 solver.cpp:228] Iteration 80, loss = 2.91485
I0403 07:32:59.155879 29785 solver.cpp:244]     Train net output #0: loss = 2.91485 (* 1 = 2.91485 loss)
I0403 07:32:59.338670 29785 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 07:33:10.726563 29785 solver.cpp:228] Iteration 96, loss = 2.6478
I0403 07:33:10.726816 29785 solver.cpp:244]     Train net output #0: loss = 2.6478 (* 1 = 2.6478 loss)
I0403 07:33:10.911557 29785 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 07:33:22.270994 29785 solver.cpp:228] Iteration 112, loss = 2.46625
I0403 07:33:22.271077 29785 solver.cpp:244]     Train net output #0: loss = 2.46625 (* 1 = 2.46625 loss)
I0403 07:33:22.459838 29785 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 07:33:33.967334 29785 solver.cpp:228] Iteration 128, loss = 2.2027
I0403 07:33:33.967403 29785 solver.cpp:244]     Train net output #0: loss = 2.2027 (* 1 = 2.2027 loss)
I0403 07:33:34.133164 29785 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 07:33:45.703866 29785 solver.cpp:228] Iteration 144, loss = 2.03488
I0403 07:33:45.704129 29785 solver.cpp:244]     Train net output #0: loss = 2.03488 (* 1 = 2.03488 loss)
I0403 07:33:45.892849 29785 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 07:33:57.264636 29785 solver.cpp:228] Iteration 160, loss = 2.17815
I0403 07:33:57.264747 29785 solver.cpp:244]     Train net output #0: loss = 2.17815 (* 1 = 2.17815 loss)
I0403 07:33:57.455266 29785 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 07:34:08.877502 29785 solver.cpp:228] Iteration 176, loss = 1.6568
I0403 07:34:08.877604 29785 solver.cpp:244]     Train net output #0: loss = 1.6568 (* 1 = 1.6568 loss)
I0403 07:34:09.108219 29785 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 07:34:20.586695 29785 solver.cpp:228] Iteration 192, loss = 1.56588
I0403 07:34:20.587029 29785 solver.cpp:244]     Train net output #0: loss = 1.56588 (* 1 = 1.56588 loss)
I0403 07:34:20.850322 29785 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 07:34:32.284315 29785 solver.cpp:228] Iteration 208, loss = 1.45022
I0403 07:34:32.284415 29785 solver.cpp:244]     Train net output #0: loss = 1.45022 (* 1 = 1.45022 loss)
I0403 07:34:32.474802 29785 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 07:34:43.844652 29785 solver.cpp:228] Iteration 224, loss = 1.36028
I0403 07:34:43.844750 29785 solver.cpp:244]     Train net output #0: loss = 1.36028 (* 1 = 1.36028 loss)
I0403 07:34:44.026674 29785 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 07:34:55.530367 29785 solver.cpp:228] Iteration 240, loss = 1.16843
I0403 07:34:55.530664 29785 solver.cpp:244]     Train net output #0: loss = 1.16843 (* 1 = 1.16843 loss)
I0403 07:34:55.703052 29785 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 07:35:07.086524 29785 solver.cpp:228] Iteration 256, loss = 1.40866
I0403 07:35:07.086609 29785 solver.cpp:244]     Train net output #0: loss = 1.40866 (* 1 = 1.40866 loss)
I0403 07:35:07.267609 29785 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 07:35:18.977831 29785 solver.cpp:228] Iteration 272, loss = 1.07827
I0403 07:35:18.977921 29785 solver.cpp:244]     Train net output #0: loss = 1.07827 (* 1 = 1.07827 loss)
I0403 07:35:19.132135 29785 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 07:35:30.692147 29785 solver.cpp:228] Iteration 288, loss = 1.24077
I0403 07:35:30.692426 29785 solver.cpp:244]     Train net output #0: loss = 1.24077 (* 1 = 1.24077 loss)
I0403 07:35:30.886721 29785 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 07:35:42.379179 29785 solver.cpp:228] Iteration 304, loss = 1.13954
I0403 07:35:42.379274 29785 solver.cpp:244]     Train net output #0: loss = 1.13954 (* 1 = 1.13954 loss)
I0403 07:35:42.592417 29785 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 07:35:54.032606 29785 solver.cpp:228] Iteration 320, loss = 0.70646
I0403 07:35:54.032706 29785 solver.cpp:244]     Train net output #0: loss = 0.70646 (* 1 = 0.70646 loss)
I0403 07:35:54.250017 29785 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 07:35:57.156203 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_325.caffemodel
I0403 07:36:00.049376 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_325.solverstate
I0403 07:36:01.988064 29785 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 07:36:50.686945 29785 solver.cpp:404]     Test net output #0: accuracy = 0.760277
I0403 07:36:50.687238 29785 solver.cpp:404]     Test net output #1: loss = 0.770438 (* 1 = 0.770438 loss)
I0403 07:36:59.263314 29785 solver.cpp:228] Iteration 336, loss = 0.970571
I0403 07:36:59.263408 29785 solver.cpp:244]     Train net output #0: loss = 0.970571 (* 1 = 0.970571 loss)
I0403 07:36:59.456691 29785 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 07:37:10.884472 29785 solver.cpp:228] Iteration 352, loss = 0.942762
I0403 07:37:10.884570 29785 solver.cpp:244]     Train net output #0: loss = 0.942762 (* 1 = 0.942762 loss)
I0403 07:37:11.083194 29785 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 07:37:22.522169 29785 solver.cpp:228] Iteration 368, loss = 0.83543
I0403 07:37:22.522472 29785 solver.cpp:244]     Train net output #0: loss = 0.83543 (* 1 = 0.83543 loss)
I0403 07:37:22.718952 29785 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 07:37:34.199265 29785 solver.cpp:228] Iteration 384, loss = 0.905817
I0403 07:37:34.199359 29785 solver.cpp:244]     Train net output #0: loss = 0.905817 (* 1 = 0.905817 loss)
I0403 07:37:34.389551 29785 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 07:37:45.743378 29785 solver.cpp:228] Iteration 400, loss = 0.757195
I0403 07:37:45.743474 29785 solver.cpp:244]     Train net output #0: loss = 0.757195 (* 1 = 0.757195 loss)
I0403 07:37:45.969612 29785 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 07:37:57.418237 29785 solver.cpp:228] Iteration 416, loss = 0.703285
I0403 07:37:57.418552 29785 solver.cpp:244]     Train net output #0: loss = 0.703285 (* 1 = 0.703285 loss)
I0403 07:37:57.588338 29785 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 07:38:09.125874 29785 solver.cpp:228] Iteration 432, loss = 0.572107
I0403 07:38:09.125965 29785 solver.cpp:244]     Train net output #0: loss = 0.572107 (* 1 = 0.572107 loss)
I0403 07:38:09.354252 29785 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 07:38:20.798319 29785 solver.cpp:228] Iteration 448, loss = 0.713946
I0403 07:38:20.798414 29785 solver.cpp:244]     Train net output #0: loss = 0.713946 (* 1 = 0.713946 loss)
I0403 07:38:20.987272 29785 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 07:38:32.475477 29785 solver.cpp:228] Iteration 464, loss = 0.540011
I0403 07:38:32.475785 29785 solver.cpp:244]     Train net output #0: loss = 0.540011 (* 1 = 0.540011 loss)
I0403 07:38:32.643764 29785 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 07:38:44.008971 29785 solver.cpp:228] Iteration 480, loss = 0.624069
I0403 07:38:44.009065 29785 solver.cpp:244]     Train net output #0: loss = 0.624069 (* 1 = 0.624069 loss)
I0403 07:38:44.199311 29785 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 07:38:55.597904 29785 solver.cpp:228] Iteration 496, loss = 0.72709
I0403 07:38:55.598002 29785 solver.cpp:244]     Train net output #0: loss = 0.72709 (* 1 = 0.72709 loss)
I0403 07:38:55.797370 29785 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 07:39:07.350653 29785 solver.cpp:228] Iteration 512, loss = 0.548867
I0403 07:39:07.350944 29785 solver.cpp:244]     Train net output #0: loss = 0.548867 (* 1 = 0.548867 loss)
I0403 07:39:07.527062 29785 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 07:39:18.875169 29785 solver.cpp:228] Iteration 528, loss = 0.40495
I0403 07:39:18.875267 29785 solver.cpp:244]     Train net output #0: loss = 0.40495 (* 1 = 0.40495 loss)
I0403 07:39:19.073846 29785 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 07:39:30.541496 29785 solver.cpp:228] Iteration 544, loss = 0.731548
I0403 07:39:30.541579 29785 solver.cpp:244]     Train net output #0: loss = 0.731548 (* 1 = 0.731548 loss)
I0403 07:39:30.651718 29785 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 07:39:42.303302 29785 solver.cpp:228] Iteration 560, loss = 0.607434
I0403 07:39:42.303606 29785 solver.cpp:244]     Train net output #0: loss = 0.607434 (* 1 = 0.607434 loss)
I0403 07:39:42.498857 29785 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 07:39:53.808910 29785 solver.cpp:228] Iteration 576, loss = 0.592592
I0403 07:39:53.809005 29785 solver.cpp:244]     Train net output #0: loss = 0.592592 (* 1 = 0.592592 loss)
I0403 07:39:54.004864 29785 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 07:40:05.457288 29785 solver.cpp:228] Iteration 592, loss = 0.424392
I0403 07:40:05.457381 29785 solver.cpp:244]     Train net output #0: loss = 0.424392 (* 1 = 0.424392 loss)
I0403 07:40:05.662209 29785 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 07:40:17.049002 29785 solver.cpp:228] Iteration 608, loss = 0.74545
I0403 07:40:17.049307 29785 solver.cpp:244]     Train net output #0: loss = 0.74545 (* 1 = 0.74545 loss)
I0403 07:40:17.233340 29785 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 07:40:28.551317 29785 solver.cpp:228] Iteration 624, loss = 0.444605
I0403 07:40:28.551409 29785 solver.cpp:244]     Train net output #0: loss = 0.444605 (* 1 = 0.444605 loss)
I0403 07:40:28.735625 29785 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 07:40:40.184556 29785 solver.cpp:228] Iteration 640, loss = 0.498944
I0403 07:40:40.184651 29785 solver.cpp:244]     Train net output #0: loss = 0.498944 (* 1 = 0.498944 loss)
I0403 07:40:40.374444 29785 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 07:40:46.994719 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_650.caffemodel
I0403 07:40:49.704628 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_650.solverstate
I0403 07:40:51.534322 29785 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 07:41:40.233973 29785 solver.cpp:404]     Test net output #0: accuracy = 0.860784
I0403 07:41:40.234274 29785 solver.cpp:404]     Test net output #1: loss = 0.437528 (* 1 = 0.437528 loss)
I0403 07:41:45.093675 29785 solver.cpp:228] Iteration 656, loss = 0.466656
I0403 07:41:45.093760 29785 solver.cpp:244]     Train net output #0: loss = 0.466656 (* 1 = 0.466656 loss)
I0403 07:41:45.262960 29785 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 07:41:56.668359 29785 solver.cpp:228] Iteration 672, loss = 0.497062
I0403 07:41:56.668488 29785 solver.cpp:244]     Train net output #0: loss = 0.497062 (* 1 = 0.497062 loss)
I0403 07:41:56.862808 29785 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 07:42:08.232875 29785 solver.cpp:228] Iteration 688, loss = 0.316211
I0403 07:42:08.232972 29785 solver.cpp:244]     Train net output #0: loss = 0.316211 (* 1 = 0.316211 loss)
I0403 07:42:08.416254 29785 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 07:42:19.981796 29785 solver.cpp:228] Iteration 704, loss = 0.484688
I0403 07:42:19.982090 29785 solver.cpp:244]     Train net output #0: loss = 0.484688 (* 1 = 0.484688 loss)
I0403 07:42:20.146842 29785 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 07:42:31.604794 29785 solver.cpp:228] Iteration 720, loss = 0.530639
I0403 07:42:31.604889 29785 solver.cpp:244]     Train net output #0: loss = 0.530639 (* 1 = 0.530639 loss)
I0403 07:42:31.823886 29785 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 07:42:43.217087 29785 solver.cpp:228] Iteration 736, loss = 0.407448
I0403 07:42:43.217181 29785 solver.cpp:244]     Train net output #0: loss = 0.407448 (* 1 = 0.407448 loss)
I0403 07:42:43.425643 29785 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 07:42:54.863489 29785 solver.cpp:228] Iteration 752, loss = 0.378303
I0403 07:42:54.863785 29785 solver.cpp:244]     Train net output #0: loss = 0.378303 (* 1 = 0.378303 loss)
I0403 07:42:55.057057 29785 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 07:43:06.565237 29785 solver.cpp:228] Iteration 768, loss = 0.316439
I0403 07:43:06.565325 29785 solver.cpp:244]     Train net output #0: loss = 0.316439 (* 1 = 0.316439 loss)
I0403 07:43:06.728672 29785 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 07:43:18.341326 29785 solver.cpp:228] Iteration 784, loss = 0.435473
I0403 07:43:18.341420 29785 solver.cpp:244]     Train net output #0: loss = 0.435473 (* 1 = 0.435473 loss)
I0403 07:43:18.523304 29785 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 07:43:29.975420 29785 solver.cpp:228] Iteration 800, loss = 0.328
I0403 07:43:29.975661 29785 solver.cpp:244]     Train net output #0: loss = 0.328 (* 1 = 0.328 loss)
I0403 07:43:30.161456 29785 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 07:43:41.629572 29785 solver.cpp:228] Iteration 816, loss = 0.432311
I0403 07:43:41.629664 29785 solver.cpp:244]     Train net output #0: loss = 0.432311 (* 1 = 0.432311 loss)
I0403 07:43:41.812966 29785 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 07:43:53.135586 29785 solver.cpp:228] Iteration 832, loss = 0.534293
I0403 07:43:53.135681 29785 solver.cpp:244]     Train net output #0: loss = 0.534294 (* 1 = 0.534294 loss)
I0403 07:43:53.340191 29785 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 07:44:04.920655 29785 solver.cpp:228] Iteration 848, loss = 0.324615
I0403 07:44:04.920955 29785 solver.cpp:244]     Train net output #0: loss = 0.324615 (* 1 = 0.324615 loss)
I0403 07:44:05.105120 29785 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 07:44:16.546483 29785 solver.cpp:228] Iteration 864, loss = 0.64026
I0403 07:44:16.546571 29785 solver.cpp:244]     Train net output #0: loss = 0.64026 (* 1 = 0.64026 loss)
I0403 07:44:16.724452 29785 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 07:44:28.150156 29785 solver.cpp:228] Iteration 880, loss = 0.264641
I0403 07:44:28.150249 29785 solver.cpp:244]     Train net output #0: loss = 0.264641 (* 1 = 0.264641 loss)
I0403 07:44:28.343350 29785 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 07:44:39.748474 29785 solver.cpp:228] Iteration 896, loss = 0.369549
I0403 07:44:39.748795 29785 solver.cpp:244]     Train net output #0: loss = 0.369549 (* 1 = 0.369549 loss)
I0403 07:44:39.952368 29785 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 07:44:51.356488 29785 solver.cpp:228] Iteration 912, loss = 0.30928
I0403 07:44:51.356585 29785 solver.cpp:244]     Train net output #0: loss = 0.30928 (* 1 = 0.30928 loss)
I0403 07:44:51.555675 29785 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 07:45:02.863759 29785 solver.cpp:228] Iteration 928, loss = 0.440218
I0403 07:45:02.863854 29785 solver.cpp:244]     Train net output #0: loss = 0.440218 (* 1 = 0.440218 loss)
I0403 07:45:03.047583 29785 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 07:45:14.522379 29785 solver.cpp:228] Iteration 944, loss = 0.353106
I0403 07:45:14.522683 29785 solver.cpp:244]     Train net output #0: loss = 0.353106 (* 1 = 0.353106 loss)
I0403 07:45:14.716336 29785 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 07:45:26.239332 29785 solver.cpp:228] Iteration 960, loss = 0.328753
I0403 07:45:26.239436 29785 solver.cpp:244]     Train net output #0: loss = 0.328753 (* 1 = 0.328753 loss)
I0403 07:45:26.422624 29785 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 07:45:36.403259 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_975.caffemodel
I0403 07:45:39.207590 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_975.solverstate
I0403 07:45:41.042829 29785 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 07:46:29.734987 29785 solver.cpp:404]     Test net output #0: accuracy = 0.908341
I0403 07:46:29.739437 29785 solver.cpp:404]     Test net output #1: loss = 0.284031 (* 1 = 0.284031 loss)
I0403 07:46:31.034914 29785 solver.cpp:228] Iteration 976, loss = 0.360196
I0403 07:46:31.035006 29785 solver.cpp:244]     Train net output #0: loss = 0.360196 (* 1 = 0.360196 loss)
I0403 07:46:31.222579 29785 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 07:46:42.857025 29785 solver.cpp:228] Iteration 992, loss = 0.339023
I0403 07:46:42.857125 29785 solver.cpp:244]     Train net output #0: loss = 0.339023 (* 1 = 0.339023 loss)
I0403 07:46:43.053831 29785 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 07:46:54.462651 29785 solver.cpp:228] Iteration 1008, loss = 0.183423
I0403 07:46:54.462750 29785 solver.cpp:244]     Train net output #0: loss = 0.183423 (* 1 = 0.183423 loss)
I0403 07:46:54.644834 29785 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 07:47:06.185773 29785 solver.cpp:228] Iteration 1024, loss = 0.428161
I0403 07:47:06.186060 29785 solver.cpp:244]     Train net output #0: loss = 0.428161 (* 1 = 0.428161 loss)
I0403 07:47:06.376895 29785 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 07:47:17.875113 29785 solver.cpp:228] Iteration 1040, loss = 0.39494
I0403 07:47:17.875198 29785 solver.cpp:244]     Train net output #0: loss = 0.39494 (* 1 = 0.39494 loss)
I0403 07:47:18.045572 29785 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 07:47:29.417146 29785 solver.cpp:228] Iteration 1056, loss = 0.451358
I0403 07:47:29.417240 29785 solver.cpp:244]     Train net output #0: loss = 0.451358 (* 1 = 0.451358 loss)
I0403 07:47:29.646023 29785 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 07:47:41.172674 29785 solver.cpp:228] Iteration 1072, loss = 0.346877
I0403 07:47:41.172994 29785 solver.cpp:244]     Train net output #0: loss = 0.346877 (* 1 = 0.346877 loss)
I0403 07:47:41.369967 29785 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 07:47:52.716984 29785 solver.cpp:228] Iteration 1088, loss = 0.253251
I0403 07:47:52.717082 29785 solver.cpp:244]     Train net output #0: loss = 0.253251 (* 1 = 0.253251 loss)
I0403 07:47:52.898638 29785 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 07:48:04.298008 29785 solver.cpp:228] Iteration 1104, loss = 0.321938
I0403 07:48:04.298105 29785 solver.cpp:244]     Train net output #0: loss = 0.321939 (* 1 = 0.321939 loss)
I0403 07:48:04.510715 29785 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 07:48:15.930006 29785 solver.cpp:228] Iteration 1120, loss = 0.27429
I0403 07:48:15.930423 29785 solver.cpp:244]     Train net output #0: loss = 0.27429 (* 1 = 0.27429 loss)
I0403 07:48:16.167120 29785 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 07:48:27.577077 29785 solver.cpp:228] Iteration 1136, loss = 0.306457
I0403 07:48:27.577175 29785 solver.cpp:244]     Train net output #0: loss = 0.306457 (* 1 = 0.306457 loss)
I0403 07:48:27.763576 29785 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 07:48:39.190788 29785 solver.cpp:228] Iteration 1152, loss = 0.287623
I0403 07:48:39.190883 29785 solver.cpp:244]     Train net output #0: loss = 0.287623 (* 1 = 0.287623 loss)
I0403 07:48:39.399519 29785 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 07:48:50.855643 29785 solver.cpp:228] Iteration 1168, loss = 0.153079
I0403 07:48:50.855911 29785 solver.cpp:244]     Train net output #0: loss = 0.153079 (* 1 = 0.153079 loss)
I0403 07:48:51.033087 29785 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 07:49:02.531159 29785 solver.cpp:228] Iteration 1184, loss = 0.262472
I0403 07:49:02.531251 29785 solver.cpp:244]     Train net output #0: loss = 0.262472 (* 1 = 0.262472 loss)
I0403 07:49:02.722692 29785 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 07:49:14.213791 29785 solver.cpp:228] Iteration 1200, loss = 0.264501
I0403 07:49:14.213888 29785 solver.cpp:244]     Train net output #0: loss = 0.264501 (* 1 = 0.264501 loss)
I0403 07:49:14.396581 29785 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 07:49:25.754842 29785 solver.cpp:228] Iteration 1216, loss = 0.220918
I0403 07:49:25.755144 29785 solver.cpp:244]     Train net output #0: loss = 0.220918 (* 1 = 0.220918 loss)
I0403 07:49:25.953651 29785 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 07:49:37.433625 29785 solver.cpp:228] Iteration 1232, loss = 0.206545
I0403 07:49:37.433722 29785 solver.cpp:244]     Train net output #0: loss = 0.206545 (* 1 = 0.206545 loss)
I0403 07:49:37.672917 29785 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 07:49:49.055008 29785 solver.cpp:228] Iteration 1248, loss = 0.162113
I0403 07:49:49.055109 29785 solver.cpp:244]     Train net output #0: loss = 0.162113 (* 1 = 0.162113 loss)
I0403 07:49:49.237977 29785 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 07:50:00.576145 29785 solver.cpp:228] Iteration 1264, loss = 0.343651
I0403 07:50:00.576413 29785 solver.cpp:244]     Train net output #0: loss = 0.343651 (* 1 = 0.343651 loss)
I0403 07:50:00.778018 29785 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 07:50:12.158550 29785 solver.cpp:228] Iteration 1280, loss = 0.140877
I0403 07:50:12.158638 29785 solver.cpp:244]     Train net output #0: loss = 0.140877 (* 1 = 0.140877 loss)
I0403 07:50:12.309506 29785 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 07:50:23.903725 29785 solver.cpp:228] Iteration 1296, loss = 0.282786
I0403 07:50:23.903823 29785 solver.cpp:244]     Train net output #0: loss = 0.282786 (* 1 = 0.282786 loss)
I0403 07:50:24.107581 29785 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 07:50:26.277905 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1300.caffemodel
I0403 07:50:29.085722 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1300.solverstate
I0403 07:50:30.942257 29785 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 07:51:19.638152 29785 solver.cpp:404]     Test net output #0: accuracy = 0.923687
I0403 07:51:19.638455 29785 solver.cpp:404]     Test net output #1: loss = 0.24352 (* 1 = 0.24352 loss)
I0403 07:51:29.025262 29785 solver.cpp:228] Iteration 1312, loss = 0.283902
I0403 07:51:29.025355 29785 solver.cpp:244]     Train net output #0: loss = 0.283902 (* 1 = 0.283902 loss)
I0403 07:51:29.219789 29785 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 07:51:40.739831 29785 solver.cpp:228] Iteration 1328, loss = 0.3289
I0403 07:51:40.739928 29785 solver.cpp:244]     Train net output #0: loss = 0.3289 (* 1 = 0.3289 loss)
I0403 07:51:40.914494 29785 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 07:51:52.327481 29785 solver.cpp:228] Iteration 1344, loss = 0.151704
I0403 07:51:52.327785 29785 solver.cpp:244]     Train net output #0: loss = 0.151704 (* 1 = 0.151704 loss)
I0403 07:51:52.561015 29785 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 07:52:04.046118 29785 solver.cpp:228] Iteration 1360, loss = 0.166832
I0403 07:52:04.046214 29785 solver.cpp:244]     Train net output #0: loss = 0.166832 (* 1 = 0.166832 loss)
I0403 07:52:04.235882 29785 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 07:52:15.691931 29785 solver.cpp:228] Iteration 1376, loss = 0.164724
I0403 07:52:15.692028 29785 solver.cpp:244]     Train net output #0: loss = 0.164724 (* 1 = 0.164724 loss)
I0403 07:52:15.886714 29785 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 07:52:27.337756 29785 solver.cpp:228] Iteration 1392, loss = 0.178994
I0403 07:52:27.338042 29785 solver.cpp:244]     Train net output #0: loss = 0.178994 (* 1 = 0.178994 loss)
I0403 07:52:27.536815 29785 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 07:52:39.005935 29785 solver.cpp:228] Iteration 1408, loss = 0.24912
I0403 07:52:39.006032 29785 solver.cpp:244]     Train net output #0: loss = 0.24912 (* 1 = 0.24912 loss)
I0403 07:52:39.207825 29785 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 07:52:50.834393 29785 solver.cpp:228] Iteration 1424, loss = 0.13882
I0403 07:52:50.834492 29785 solver.cpp:244]     Train net output #0: loss = 0.13882 (* 1 = 0.13882 loss)
I0403 07:52:51.045647 29785 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 07:53:02.553095 29785 solver.cpp:228] Iteration 1440, loss = 0.137872
I0403 07:53:02.553397 29785 solver.cpp:244]     Train net output #0: loss = 0.137872 (* 1 = 0.137872 loss)
I0403 07:53:02.742245 29785 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 07:53:14.143982 29785 solver.cpp:228] Iteration 1456, loss = 0.16759
I0403 07:53:14.144083 29785 solver.cpp:244]     Train net output #0: loss = 0.16759 (* 1 = 0.16759 loss)
I0403 07:53:14.338381 29785 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 07:53:25.838673 29785 solver.cpp:228] Iteration 1472, loss = 0.222797
I0403 07:53:25.838768 29785 solver.cpp:244]     Train net output #0: loss = 0.222797 (* 1 = 0.222797 loss)
I0403 07:53:26.029568 29785 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 07:53:37.549796 29785 solver.cpp:228] Iteration 1488, loss = 0.173054
I0403 07:53:37.549996 29785 solver.cpp:244]     Train net output #0: loss = 0.173054 (* 1 = 0.173054 loss)
I0403 07:53:37.732504 29785 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 07:53:49.096106 29785 solver.cpp:228] Iteration 1504, loss = 0.213712
I0403 07:53:49.096200 29785 solver.cpp:244]     Train net output #0: loss = 0.213712 (* 1 = 0.213712 loss)
I0403 07:53:49.289921 29785 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 07:54:00.652052 29785 solver.cpp:228] Iteration 1520, loss = 0.122544
I0403 07:54:00.652149 29785 solver.cpp:244]     Train net output #0: loss = 0.122544 (* 1 = 0.122544 loss)
I0403 07:54:00.859869 29785 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 07:54:12.250558 29785 solver.cpp:228] Iteration 1536, loss = 0.246096
I0403 07:54:12.250887 29785 solver.cpp:244]     Train net output #0: loss = 0.246096 (* 1 = 0.246096 loss)
I0403 07:54:12.433645 29785 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 07:54:23.827106 29785 solver.cpp:228] Iteration 1552, loss = 0.164569
I0403 07:54:23.827208 29785 solver.cpp:244]     Train net output #0: loss = 0.164569 (* 1 = 0.164569 loss)
I0403 07:54:24.060598 29785 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 07:54:35.510437 29785 solver.cpp:228] Iteration 1568, loss = 0.0653085
I0403 07:54:35.510524 29785 solver.cpp:244]     Train net output #0: loss = 0.0653086 (* 1 = 0.0653086 loss)
I0403 07:54:35.670280 29785 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 07:54:47.138411 29785 solver.cpp:228] Iteration 1584, loss = 0.187033
I0403 07:54:47.138702 29785 solver.cpp:244]     Train net output #0: loss = 0.187033 (* 1 = 0.187033 loss)
I0403 07:54:47.323489 29785 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 07:54:58.684273 29785 solver.cpp:228] Iteration 1600, loss = 0.164877
I0403 07:54:58.684358 29785 solver.cpp:244]     Train net output #0: loss = 0.164877 (* 1 = 0.164877 loss)
I0403 07:54:58.865963 29785 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 07:55:10.538236 29785 solver.cpp:228] Iteration 1616, loss = 0.113843
I0403 07:55:10.538331 29785 solver.cpp:244]     Train net output #0: loss = 0.113844 (* 1 = 0.113844 loss)
I0403 07:55:10.735263 29785 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 07:55:16.492897 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1625.caffemodel
I0403 07:55:19.300081 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1625.solverstate
I0403 07:55:21.200311 29785 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 07:56:09.867934 29785 solver.cpp:404]     Test net output #0: accuracy = 0.924884
I0403 07:56:09.869175 29785 solver.cpp:404]     Test net output #1: loss = 0.240116 (* 1 = 0.240116 loss)
I0403 07:56:15.419350 29785 solver.cpp:228] Iteration 1632, loss = 0.134143
I0403 07:56:15.419447 29785 solver.cpp:244]     Train net output #0: loss = 0.134143 (* 1 = 0.134143 loss)
I0403 07:56:15.627827 29785 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 07:56:27.105331 29785 solver.cpp:228] Iteration 1648, loss = 0.191457
I0403 07:56:27.105449 29785 solver.cpp:244]     Train net output #0: loss = 0.191457 (* 1 = 0.191457 loss)
I0403 07:56:27.304031 29785 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 07:56:38.668411 29785 solver.cpp:228] Iteration 1664, loss = 0.113524
I0403 07:56:38.668506 29785 solver.cpp:244]     Train net output #0: loss = 0.113524 (* 1 = 0.113524 loss)
I0403 07:56:38.869141 29785 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 07:56:50.235867 29785 solver.cpp:228] Iteration 1680, loss = 0.0599901
I0403 07:56:50.236181 29785 solver.cpp:244]     Train net output #0: loss = 0.0599903 (* 1 = 0.0599903 loss)
I0403 07:56:50.439784 29785 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 07:57:02.184917 29785 solver.cpp:228] Iteration 1696, loss = 0.0729688
I0403 07:57:02.185003 29785 solver.cpp:244]     Train net output #0: loss = 0.072969 (* 1 = 0.072969 loss)
I0403 07:57:02.364559 29785 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 07:57:13.775332 29785 solver.cpp:228] Iteration 1712, loss = 0.120773
I0403 07:57:13.775429 29785 solver.cpp:244]     Train net output #0: loss = 0.120773 (* 1 = 0.120773 loss)
I0403 07:57:13.999897 29785 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 07:57:25.567769 29785 solver.cpp:228] Iteration 1728, loss = 0.149621
I0403 07:57:25.568091 29785 solver.cpp:244]     Train net output #0: loss = 0.149621 (* 1 = 0.149621 loss)
I0403 07:57:25.775400 29785 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 07:57:37.313941 29785 solver.cpp:228] Iteration 1744, loss = 0.141036
I0403 07:57:37.314038 29785 solver.cpp:244]     Train net output #0: loss = 0.141036 (* 1 = 0.141036 loss)
I0403 07:57:37.497617 29785 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 07:57:48.941613 29785 solver.cpp:228] Iteration 1760, loss = 0.0922714
I0403 07:57:48.941709 29785 solver.cpp:244]     Train net output #0: loss = 0.0922715 (* 1 = 0.0922715 loss)
I0403 07:57:49.169797 29785 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 07:58:00.629298 29785 solver.cpp:228] Iteration 1776, loss = 0.108157
I0403 07:58:00.629616 29785 solver.cpp:244]     Train net output #0: loss = 0.108158 (* 1 = 0.108158 loss)
I0403 07:58:00.806816 29785 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 07:58:12.283597 29785 solver.cpp:228] Iteration 1792, loss = 0.138552
I0403 07:58:12.283694 29785 solver.cpp:244]     Train net output #0: loss = 0.138553 (* 1 = 0.138553 loss)
I0403 07:58:12.526890 29785 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 07:58:23.924782 29785 solver.cpp:228] Iteration 1808, loss = 0.216183
I0403 07:58:23.924882 29785 solver.cpp:244]     Train net output #0: loss = 0.216183 (* 1 = 0.216183 loss)
I0403 07:58:24.109434 29785 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 07:58:35.548269 29785 solver.cpp:228] Iteration 1824, loss = 0.116108
I0403 07:58:35.552225 29785 solver.cpp:244]     Train net output #0: loss = 0.116108 (* 1 = 0.116108 loss)
I0403 07:58:35.771307 29785 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 07:58:47.305071 29785 solver.cpp:228] Iteration 1840, loss = 0.0848191
I0403 07:58:47.305184 29785 solver.cpp:244]     Train net output #0: loss = 0.0848193 (* 1 = 0.0848193 loss)
I0403 07:58:47.495263 29785 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 07:58:58.861441 29785 solver.cpp:228] Iteration 1856, loss = 0.0548107
I0403 07:58:58.861536 29785 solver.cpp:244]     Train net output #0: loss = 0.0548109 (* 1 = 0.0548109 loss)
I0403 07:58:59.072960 29785 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 07:59:10.467906 29785 solver.cpp:228] Iteration 1872, loss = 0.146624
I0403 07:59:10.468210 29785 solver.cpp:244]     Train net output #0: loss = 0.146624 (* 1 = 0.146624 loss)
I0403 07:59:10.652755 29785 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 07:59:22.043665 29785 solver.cpp:228] Iteration 1888, loss = 0.121814
I0403 07:59:22.043761 29785 solver.cpp:244]     Train net output #0: loss = 0.121814 (* 1 = 0.121814 loss)
I0403 07:59:22.229121 29785 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 07:59:33.636306 29785 solver.cpp:228] Iteration 1904, loss = 0.125464
I0403 07:59:33.636392 29785 solver.cpp:244]     Train net output #0: loss = 0.125464 (* 1 = 0.125464 loss)
I0403 07:59:33.798384 29785 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 07:59:45.247936 29785 solver.cpp:228] Iteration 1920, loss = 0.174218
I0403 07:59:45.248229 29785 solver.cpp:244]     Train net output #0: loss = 0.174218 (* 1 = 0.174218 loss)
I0403 07:59:45.411450 29785 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 07:59:56.989892 29785 solver.cpp:228] Iteration 1936, loss = 0.233657
I0403 07:59:56.989990 29785 solver.cpp:244]     Train net output #0: loss = 0.233657 (* 1 = 0.233657 loss)
I0403 07:59:57.185889 29785 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 08:00:06.635478 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1950.caffemodel
I0403 08:00:09.416821 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_1950.solverstate
I0403 08:00:11.319044 29785 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 08:00:59.985083 29785 solver.cpp:404]     Test net output #0: accuracy = 0.940276
I0403 08:00:59.985445 29785 solver.cpp:404]     Test net output #1: loss = 0.188915 (* 1 = 0.188915 loss)
I0403 08:01:01.925132 29785 solver.cpp:228] Iteration 1952, loss = 0.134095
I0403 08:01:01.925257 29785 solver.cpp:244]     Train net output #0: loss = 0.134095 (* 1 = 0.134095 loss)
I0403 08:01:02.120604 29785 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 08:01:13.518741 29785 solver.cpp:228] Iteration 1968, loss = 0.101137
I0403 08:01:13.518841 29785 solver.cpp:244]     Train net output #0: loss = 0.101138 (* 1 = 0.101138 loss)
I0403 08:01:13.712929 29785 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 08:01:25.150288 29785 solver.cpp:228] Iteration 1984, loss = 0.151432
I0403 08:01:25.150384 29785 solver.cpp:244]     Train net output #0: loss = 0.151432 (* 1 = 0.151432 loss)
I0403 08:01:25.348367 29785 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 08:01:36.664049 29785 solver.cpp:228] Iteration 2000, loss = 0.176324
I0403 08:01:36.664340 29785 solver.cpp:244]     Train net output #0: loss = 0.176324 (* 1 = 0.176324 loss)
I0403 08:01:36.853776 29785 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 08:01:48.277565 29785 solver.cpp:228] Iteration 2016, loss = 0.163174
I0403 08:01:48.277664 29785 solver.cpp:244]     Train net output #0: loss = 0.163175 (* 1 = 0.163175 loss)
I0403 08:01:48.467850 29785 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 08:01:59.943300 29785 solver.cpp:228] Iteration 2032, loss = 0.0440568
I0403 08:01:59.943387 29785 solver.cpp:244]     Train net output #0: loss = 0.044057 (* 1 = 0.044057 loss)
I0403 08:02:00.129686 29785 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 08:02:11.584974 29785 solver.cpp:228] Iteration 2048, loss = 0.0740085
I0403 08:02:11.585270 29785 solver.cpp:244]     Train net output #0: loss = 0.0740087 (* 1 = 0.0740087 loss)
I0403 08:02:11.766782 29785 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 08:02:23.237530 29785 solver.cpp:228] Iteration 2064, loss = 0.0641106
I0403 08:02:23.237627 29785 solver.cpp:244]     Train net output #0: loss = 0.0641108 (* 1 = 0.0641108 loss)
I0403 08:02:23.430208 29785 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 08:02:35.038130 29785 solver.cpp:228] Iteration 2080, loss = 0.120314
I0403 08:02:35.038218 29785 solver.cpp:244]     Train net output #0: loss = 0.120314 (* 1 = 0.120314 loss)
I0403 08:02:35.197480 29785 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 08:02:46.780726 29785 solver.cpp:228] Iteration 2096, loss = 0.128444
I0403 08:02:46.781003 29785 solver.cpp:244]     Train net output #0: loss = 0.128445 (* 1 = 0.128445 loss)
I0403 08:02:46.947947 29785 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 08:02:58.365744 29785 solver.cpp:228] Iteration 2112, loss = 0.147563
I0403 08:02:58.365839 29785 solver.cpp:244]     Train net output #0: loss = 0.147563 (* 1 = 0.147563 loss)
I0403 08:02:58.558605 29785 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 08:03:09.996309 29785 solver.cpp:228] Iteration 2128, loss = 0.127402
I0403 08:03:09.996407 29785 solver.cpp:244]     Train net output #0: loss = 0.127403 (* 1 = 0.127403 loss)
I0403 08:03:10.249567 29785 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 08:03:21.586594 29785 solver.cpp:228] Iteration 2144, loss = 0.0465468
I0403 08:03:21.586894 29785 solver.cpp:244]     Train net output #0: loss = 0.046547 (* 1 = 0.046547 loss)
I0403 08:03:21.768407 29785 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 08:03:33.410217 29785 solver.cpp:228] Iteration 2160, loss = 0.0456529
I0403 08:03:33.410302 29785 solver.cpp:244]     Train net output #0: loss = 0.0456531 (* 1 = 0.0456531 loss)
I0403 08:03:33.585613 29785 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 08:03:44.972837 29785 solver.cpp:228] Iteration 2176, loss = 0.0906937
I0403 08:03:44.972934 29785 solver.cpp:244]     Train net output #0: loss = 0.090694 (* 1 = 0.090694 loss)
I0403 08:03:45.200280 29785 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 08:03:56.731058 29785 solver.cpp:228] Iteration 2192, loss = 0.140646
I0403 08:03:56.731339 29785 solver.cpp:244]     Train net output #0: loss = 0.140646 (* 1 = 0.140646 loss)
I0403 08:03:56.908660 29785 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 08:04:08.542390 29785 solver.cpp:228] Iteration 2208, loss = 0.0510022
I0403 08:04:08.542475 29785 solver.cpp:244]     Train net output #0: loss = 0.0510024 (* 1 = 0.0510024 loss)
I0403 08:04:08.722867 29785 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 08:04:20.204216 29785 solver.cpp:228] Iteration 2224, loss = 0.0695153
I0403 08:04:20.204313 29785 solver.cpp:244]     Train net output #0: loss = 0.0695155 (* 1 = 0.0695155 loss)
I0403 08:04:20.404598 29785 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 08:04:31.870774 29785 solver.cpp:228] Iteration 2240, loss = 0.16426
I0403 08:04:31.871100 29785 solver.cpp:244]     Train net output #0: loss = 0.164261 (* 1 = 0.164261 loss)
I0403 08:04:32.069797 29785 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 08:04:43.527350 29785 solver.cpp:228] Iteration 2256, loss = 0.146445
I0403 08:04:43.527437 29785 solver.cpp:244]     Train net output #0: loss = 0.146446 (* 1 = 0.146446 loss)
I0403 08:04:43.677851 29785 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 08:04:55.229660 29785 solver.cpp:228] Iteration 2272, loss = 0.116216
I0403 08:04:55.229756 29785 solver.cpp:244]     Train net output #0: loss = 0.116216 (* 1 = 0.116216 loss)
I0403 08:04:55.413759 29785 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 08:04:56.847245 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2275.caffemodel
I0403 08:04:59.548833 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2275.solverstate
I0403 08:05:01.393410 29785 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 08:05:50.083926 29785 solver.cpp:404]     Test net output #0: accuracy = 0.944378
I0403 08:05:50.084228 29785 solver.cpp:404]     Test net output #1: loss = 0.18391 (* 1 = 0.18391 loss)
I0403 08:06:00.108239 29785 solver.cpp:228] Iteration 2288, loss = 0.137026
I0403 08:06:00.108340 29785 solver.cpp:244]     Train net output #0: loss = 0.137026 (* 1 = 0.137026 loss)
I0403 08:06:00.309978 29785 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 08:06:11.741881 29785 solver.cpp:228] Iteration 2304, loss = 0.100667
I0403 08:06:11.741967 29785 solver.cpp:244]     Train net output #0: loss = 0.100667 (* 1 = 0.100667 loss)
I0403 08:06:11.914454 29785 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 08:06:23.304570 29785 solver.cpp:228] Iteration 2320, loss = 0.0967174
I0403 08:06:23.304848 29785 solver.cpp:244]     Train net output #0: loss = 0.0967176 (* 1 = 0.0967176 loss)
I0403 08:06:23.482290 29785 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 08:06:34.874568 29785 solver.cpp:228] Iteration 2336, loss = 0.0979249
I0403 08:06:34.874678 29785 solver.cpp:244]     Train net output #0: loss = 0.0979251 (* 1 = 0.0979251 loss)
I0403 08:06:35.063480 29785 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 08:06:46.623153 29785 solver.cpp:228] Iteration 2352, loss = 0.0956964
I0403 08:06:46.623251 29785 solver.cpp:244]     Train net output #0: loss = 0.0956966 (* 1 = 0.0956966 loss)
I0403 08:06:46.816373 29785 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 08:06:58.265233 29785 solver.cpp:228] Iteration 2368, loss = 0.0965091
I0403 08:06:58.265537 29785 solver.cpp:244]     Train net output #0: loss = 0.0965093 (* 1 = 0.0965093 loss)
I0403 08:06:58.472199 29785 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 08:07:09.838287 29785 solver.cpp:228] Iteration 2384, loss = 0.081735
I0403 08:07:09.838376 29785 solver.cpp:244]     Train net output #0: loss = 0.0817352 (* 1 = 0.0817352 loss)
I0403 08:07:10.011998 29785 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 08:07:21.540850 29785 solver.cpp:228] Iteration 2400, loss = 0.073154
I0403 08:07:21.540945 29785 solver.cpp:244]     Train net output #0: loss = 0.0731542 (* 1 = 0.0731542 loss)
I0403 08:07:21.736454 29785 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 08:07:33.314636 29785 solver.cpp:228] Iteration 2416, loss = 0.0659056
I0403 08:07:33.314945 29785 solver.cpp:244]     Train net output #0: loss = 0.0659058 (* 1 = 0.0659058 loss)
I0403 08:07:33.496974 29785 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 08:07:44.922555 29785 solver.cpp:228] Iteration 2432, loss = 0.0559647
I0403 08:07:44.922652 29785 solver.cpp:244]     Train net output #0: loss = 0.0559649 (* 1 = 0.0559649 loss)
I0403 08:07:45.134315 29785 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 08:07:56.605706 29785 solver.cpp:228] Iteration 2448, loss = 0.195937
I0403 08:07:56.605801 29785 solver.cpp:244]     Train net output #0: loss = 0.195937 (* 1 = 0.195937 loss)
I0403 08:07:56.814714 29785 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 08:08:08.115305 29785 solver.cpp:228] Iteration 2464, loss = 0.135575
I0403 08:08:08.115622 29785 solver.cpp:244]     Train net output #0: loss = 0.135575 (* 1 = 0.135575 loss)
I0403 08:08:08.296492 29785 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 08:08:19.687295 29785 solver.cpp:228] Iteration 2480, loss = 0.190173
I0403 08:08:19.687383 29785 solver.cpp:244]     Train net output #0: loss = 0.190173 (* 1 = 0.190173 loss)
I0403 08:08:19.867424 29785 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 08:08:31.334846 29785 solver.cpp:228] Iteration 2496, loss = 0.0721816
I0403 08:08:31.334940 29785 solver.cpp:244]     Train net output #0: loss = 0.0721818 (* 1 = 0.0721818 loss)
I0403 08:08:31.526494 29785 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 08:08:43.016304 29785 solver.cpp:228] Iteration 2512, loss = 0.0479279
I0403 08:08:43.016603 29785 solver.cpp:244]     Train net output #0: loss = 0.0479282 (* 1 = 0.0479282 loss)
I0403 08:08:43.240291 29785 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 08:08:54.613214 29785 solver.cpp:228] Iteration 2528, loss = 0.0437695
I0403 08:08:54.613307 29785 solver.cpp:244]     Train net output #0: loss = 0.0437697 (* 1 = 0.0437697 loss)
I0403 08:08:54.803023 29785 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 08:09:06.326720 29785 solver.cpp:228] Iteration 2544, loss = 0.0446463
I0403 08:09:06.326812 29785 solver.cpp:244]     Train net output #0: loss = 0.0446465 (* 1 = 0.0446465 loss)
I0403 08:09:06.534240 29785 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 08:09:17.920145 29785 solver.cpp:228] Iteration 2560, loss = 0.0928356
I0403 08:09:17.920444 29785 solver.cpp:244]     Train net output #0: loss = 0.0928358 (* 1 = 0.0928358 loss)
I0403 08:09:18.123196 29785 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 08:09:29.650284 29785 solver.cpp:228] Iteration 2576, loss = 0.12648
I0403 08:09:29.650389 29785 solver.cpp:244]     Train net output #0: loss = 0.12648 (* 1 = 0.12648 loss)
I0403 08:09:29.849645 29785 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 08:09:41.305069 29785 solver.cpp:228] Iteration 2592, loss = 0.0539931
I0403 08:09:41.305172 29785 solver.cpp:244]     Train net output #0: loss = 0.0539933 (* 1 = 0.0539933 loss)
I0403 08:09:41.526934 29785 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 08:09:46.626821 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2600.caffemodel
I0403 08:09:49.418081 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2600.solverstate
I0403 08:09:51.270529 29785 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 08:10:39.947650 29785 solver.cpp:404]     Test net output #0: accuracy = 0.940783
I0403 08:10:39.947942 29785 solver.cpp:404]     Test net output #1: loss = 0.215192 (* 1 = 0.215192 loss)
I0403 08:10:46.251051 29785 solver.cpp:228] Iteration 2608, loss = 0.105864
I0403 08:10:46.251163 29785 solver.cpp:244]     Train net output #0: loss = 0.105864 (* 1 = 0.105864 loss)
I0403 08:10:46.442670 29785 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 08:10:57.911288 29785 solver.cpp:228] Iteration 2624, loss = 0.0924289
I0403 08:10:57.911391 29785 solver.cpp:244]     Train net output #0: loss = 0.0924292 (* 1 = 0.0924292 loss)
I0403 08:10:58.116138 29785 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 08:11:09.593101 29785 solver.cpp:228] Iteration 2640, loss = 0.111096
I0403 08:11:09.593204 29785 solver.cpp:244]     Train net output #0: loss = 0.111096 (* 1 = 0.111096 loss)
I0403 08:11:09.776847 29785 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 08:11:21.120291 29785 solver.cpp:228] Iteration 2656, loss = 0.0437078
I0403 08:11:21.120581 29785 solver.cpp:244]     Train net output #0: loss = 0.0437081 (* 1 = 0.0437081 loss)
I0403 08:11:21.369583 29785 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 08:11:32.861312 29785 solver.cpp:228] Iteration 2672, loss = 0.1174
I0403 08:11:32.861408 29785 solver.cpp:244]     Train net output #0: loss = 0.1174 (* 1 = 0.1174 loss)
I0403 08:11:33.057739 29785 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 08:11:44.523035 29785 solver.cpp:228] Iteration 2688, loss = 0.167109
I0403 08:11:44.523138 29785 solver.cpp:244]     Train net output #0: loss = 0.167109 (* 1 = 0.167109 loss)
I0403 08:11:44.726577 29785 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 08:11:56.242936 29785 solver.cpp:228] Iteration 2704, loss = 0.127169
I0403 08:11:56.243245 29785 solver.cpp:244]     Train net output #0: loss = 0.127169 (* 1 = 0.127169 loss)
I0403 08:11:56.425982 29785 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 08:12:07.891548 29785 solver.cpp:228] Iteration 2720, loss = 0.0974683
I0403 08:12:07.891646 29785 solver.cpp:244]     Train net output #0: loss = 0.0974685 (* 1 = 0.0974685 loss)
I0403 08:12:08.087985 29785 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 08:12:19.562419 29785 solver.cpp:228] Iteration 2736, loss = 0.0666778
I0403 08:12:19.562515 29785 solver.cpp:244]     Train net output #0: loss = 0.0666781 (* 1 = 0.0666781 loss)
I0403 08:12:19.769830 29785 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 08:12:31.183192 29785 solver.cpp:228] Iteration 2752, loss = 0.122128
I0403 08:12:31.183486 29785 solver.cpp:244]     Train net output #0: loss = 0.122128 (* 1 = 0.122128 loss)
I0403 08:12:31.351313 29785 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 08:12:42.812185 29785 solver.cpp:228] Iteration 2768, loss = 0.187254
I0403 08:12:42.812270 29785 solver.cpp:244]     Train net output #0: loss = 0.187254 (* 1 = 0.187254 loss)
I0403 08:12:42.959425 29785 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 08:12:54.405520 29785 solver.cpp:228] Iteration 2784, loss = 0.0526975
I0403 08:12:54.405617 29785 solver.cpp:244]     Train net output #0: loss = 0.0526978 (* 1 = 0.0526978 loss)
I0403 08:12:54.595643 29785 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 08:13:06.157013 29785 solver.cpp:228] Iteration 2800, loss = 0.0597819
I0403 08:13:06.157304 29785 solver.cpp:244]     Train net output #0: loss = 0.0597822 (* 1 = 0.0597822 loss)
I0403 08:13:06.337697 29785 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 08:13:17.885356 29785 solver.cpp:228] Iteration 2816, loss = 0.0370048
I0403 08:13:17.885452 29785 solver.cpp:244]     Train net output #0: loss = 0.037005 (* 1 = 0.037005 loss)
I0403 08:13:18.079308 29785 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 08:13:29.474498 29785 solver.cpp:228] Iteration 2832, loss = 0.0277581
I0403 08:13:29.474596 29785 solver.cpp:244]     Train net output #0: loss = 0.0277583 (* 1 = 0.0277583 loss)
I0403 08:13:29.702622 29785 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 08:13:41.274456 29785 solver.cpp:228] Iteration 2848, loss = 0.0819121
I0403 08:13:41.274757 29785 solver.cpp:244]     Train net output #0: loss = 0.0819124 (* 1 = 0.0819124 loss)
I0403 08:13:41.510778 29785 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 08:13:52.902302 29785 solver.cpp:228] Iteration 2864, loss = 0.0631843
I0403 08:13:52.902400 29785 solver.cpp:244]     Train net output #0: loss = 0.0631845 (* 1 = 0.0631845 loss)
I0403 08:13:53.086900 29785 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 08:14:04.761117 29785 solver.cpp:228] Iteration 2880, loss = 0.154419
I0403 08:14:04.761210 29785 solver.cpp:244]     Train net output #0: loss = 0.154419 (* 1 = 0.154419 loss)
I0403 08:14:04.943750 29785 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 08:14:16.760033 29785 solver.cpp:228] Iteration 2896, loss = 0.148876
I0403 08:14:16.760354 29785 solver.cpp:244]     Train net output #0: loss = 0.148876 (* 1 = 0.148876 loss)
I0403 08:14:16.967484 29785 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 08:14:28.402307 29785 solver.cpp:228] Iteration 2912, loss = 0.0743116
I0403 08:14:28.402405 29785 solver.cpp:244]     Train net output #0: loss = 0.0743119 (* 1 = 0.0743119 loss)
I0403 08:14:28.588254 29785 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 08:14:37.348850 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2925.caffemodel
I0403 08:14:40.104845 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_2925.solverstate
I0403 08:14:41.982435 29785 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 08:15:30.654419 29785 solver.cpp:404]     Test net output #0: accuracy = 0.948571
I0403 08:15:30.654768 29785 solver.cpp:404]     Test net output #1: loss = 0.183496 (* 1 = 0.183496 loss)
I0403 08:15:33.424597 29785 solver.cpp:228] Iteration 2928, loss = 0.0494048
I0403 08:15:33.424692 29785 solver.cpp:244]     Train net output #0: loss = 0.0494051 (* 1 = 0.0494051 loss)
I0403 08:15:33.607511 29785 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 08:15:45.203296 29785 solver.cpp:228] Iteration 2944, loss = 0.0452888
I0403 08:15:45.203382 29785 solver.cpp:244]     Train net output #0: loss = 0.0452891 (* 1 = 0.0452891 loss)
I0403 08:15:45.379580 29785 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 08:15:56.947697 29785 solver.cpp:228] Iteration 2960, loss = 0.124215
I0403 08:15:56.947783 29785 solver.cpp:244]     Train net output #0: loss = 0.124215 (* 1 = 0.124215 loss)
I0403 08:15:57.109952 29785 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 08:16:08.604493 29785 solver.cpp:228] Iteration 2976, loss = 0.113066
I0403 08:16:08.604784 29785 solver.cpp:244]     Train net output #0: loss = 0.113066 (* 1 = 0.113066 loss)
I0403 08:16:08.778154 29785 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 08:16:20.150717 29785 solver.cpp:228] Iteration 2992, loss = 0.043862
I0403 08:16:20.150806 29785 solver.cpp:244]     Train net output #0: loss = 0.0438624 (* 1 = 0.0438624 loss)
I0403 08:16:20.309662 29785 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 08:16:31.721395 29785 solver.cpp:228] Iteration 3008, loss = 0.0555904
I0403 08:16:31.721485 29785 solver.cpp:244]     Train net output #0: loss = 0.0555907 (* 1 = 0.0555907 loss)
I0403 08:16:31.902794 29785 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 08:16:43.262044 29785 solver.cpp:228] Iteration 3024, loss = 0.0715272
I0403 08:16:43.262348 29785 solver.cpp:244]     Train net output #0: loss = 0.0715275 (* 1 = 0.0715275 loss)
I0403 08:16:43.473196 29785 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 08:16:55.117897 29785 solver.cpp:228] Iteration 3040, loss = 0.0682573
I0403 08:16:55.117983 29785 solver.cpp:244]     Train net output #0: loss = 0.0682576 (* 1 = 0.0682576 loss)
I0403 08:16:55.238256 29785 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 08:17:06.776607 29785 solver.cpp:228] Iteration 3056, loss = 0.058604
I0403 08:17:06.776692 29785 solver.cpp:244]     Train net output #0: loss = 0.0586043 (* 1 = 0.0586043 loss)
I0403 08:17:06.941278 29785 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 08:17:18.411651 29785 solver.cpp:228] Iteration 3072, loss = 0.0884107
I0403 08:17:18.411952 29785 solver.cpp:244]     Train net output #0: loss = 0.088411 (* 1 = 0.088411 loss)
I0403 08:17:18.594075 29785 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 08:17:29.963099 29785 solver.cpp:228] Iteration 3088, loss = 0.05921
I0403 08:17:29.963196 29785 solver.cpp:244]     Train net output #0: loss = 0.0592103 (* 1 = 0.0592103 loss)
I0403 08:17:30.239038 29785 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 08:17:41.562680 29785 solver.cpp:228] Iteration 3104, loss = 0.0587193
I0403 08:17:41.562777 29785 solver.cpp:244]     Train net output #0: loss = 0.0587196 (* 1 = 0.0587196 loss)
I0403 08:17:41.762467 29785 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 08:17:53.347898 29785 solver.cpp:228] Iteration 3120, loss = 0.00965161
I0403 08:17:53.348165 29785 solver.cpp:244]     Train net output #0: loss = 0.00965192 (* 1 = 0.00965192 loss)
I0403 08:17:53.522549 29785 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 08:18:05.053979 29785 solver.cpp:228] Iteration 3136, loss = 0.0604003
I0403 08:18:05.054075 29785 solver.cpp:244]     Train net output #0: loss = 0.0604006 (* 1 = 0.0604006 loss)
I0403 08:18:05.237781 29785 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 08:18:16.748772 29785 solver.cpp:228] Iteration 3152, loss = 0.0410955
I0403 08:18:16.748859 29785 solver.cpp:244]     Train net output #0: loss = 0.0410958 (* 1 = 0.0410958 loss)
I0403 08:18:16.930176 29785 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 08:18:28.570801 29785 solver.cpp:228] Iteration 3168, loss = 0.0241777
I0403 08:18:28.571084 29785 solver.cpp:244]     Train net output #0: loss = 0.024178 (* 1 = 0.024178 loss)
I0403 08:18:28.784528 29785 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 08:18:40.153918 29785 solver.cpp:228] Iteration 3184, loss = 0.030095
I0403 08:18:40.154006 29785 solver.cpp:244]     Train net output #0: loss = 0.0300954 (* 1 = 0.0300954 loss)
I0403 08:18:40.328734 29785 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 08:18:51.695088 29785 solver.cpp:228] Iteration 3200, loss = 0.0385198
I0403 08:18:51.695189 29785 solver.cpp:244]     Train net output #0: loss = 0.0385201 (* 1 = 0.0385201 loss)
I0403 08:18:51.887161 29785 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 08:19:03.201632 29785 solver.cpp:228] Iteration 3216, loss = 0.131245
I0403 08:19:03.201872 29785 solver.cpp:244]     Train net output #0: loss = 0.131245 (* 1 = 0.131245 loss)
I0403 08:19:03.387742 29785 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 08:19:15.020563 29785 solver.cpp:228] Iteration 3232, loss = 0.0764416
I0403 08:19:15.020660 29785 solver.cpp:244]     Train net output #0: loss = 0.0764419 (* 1 = 0.0764419 loss)
I0403 08:19:15.206291 29785 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 08:19:26.940945 29785 solver.cpp:228] Iteration 3248, loss = 0.0305123
I0403 08:19:26.941035 29785 solver.cpp:244]     Train net output #0: loss = 0.0305125 (* 1 = 0.0305125 loss)
I0403 08:19:27.116245 29785 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 08:19:27.859571 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3250.caffemodel
I0403 08:19:30.608624 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3250.solverstate
I0403 08:19:32.512634 29785 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 08:20:21.190728 29785 solver.cpp:404]     Test net output #0: accuracy = 0.956452
I0403 08:20:21.191076 29785 solver.cpp:404]     Test net output #1: loss = 0.156871 (* 1 = 0.156871 loss)
I0403 08:20:31.972842 29785 solver.cpp:228] Iteration 3264, loss = 0.0947402
I0403 08:20:31.972936 29785 solver.cpp:244]     Train net output #0: loss = 0.0947405 (* 1 = 0.0947405 loss)
I0403 08:20:32.195893 29785 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 08:20:43.536589 29785 solver.cpp:228] Iteration 3280, loss = 0.0170788
I0403 08:20:43.536687 29785 solver.cpp:244]     Train net output #0: loss = 0.0170791 (* 1 = 0.0170791 loss)
I0403 08:20:43.743327 29785 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 08:20:55.275538 29785 solver.cpp:228] Iteration 3296, loss = 0.0605251
I0403 08:20:55.275843 29785 solver.cpp:244]     Train net output #0: loss = 0.0605254 (* 1 = 0.0605254 loss)
I0403 08:20:55.463362 29785 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 08:21:06.970243 29785 solver.cpp:228] Iteration 3312, loss = 0.0231711
I0403 08:21:06.970334 29785 solver.cpp:244]     Train net output #0: loss = 0.0231714 (* 1 = 0.0231714 loss)
I0403 08:21:07.146219 29785 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 08:21:18.527636 29785 solver.cpp:228] Iteration 3328, loss = 0.0294248
I0403 08:21:18.527734 29785 solver.cpp:244]     Train net output #0: loss = 0.0294251 (* 1 = 0.0294251 loss)
I0403 08:21:18.749161 29785 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 08:21:30.184432 29785 solver.cpp:228] Iteration 3344, loss = 0.0108723
I0403 08:21:30.184756 29785 solver.cpp:244]     Train net output #0: loss = 0.0108726 (* 1 = 0.0108726 loss)
I0403 08:21:30.366547 29785 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 08:21:41.874454 29785 solver.cpp:228] Iteration 3360, loss = 0.0160453
I0403 08:21:41.874550 29785 solver.cpp:244]     Train net output #0: loss = 0.0160456 (* 1 = 0.0160456 loss)
I0403 08:21:42.056892 29785 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 08:21:53.382181 29785 solver.cpp:228] Iteration 3376, loss = 0.0137983
I0403 08:21:53.382278 29785 solver.cpp:244]     Train net output #0: loss = 0.0137986 (* 1 = 0.0137986 loss)
I0403 08:21:53.564051 29785 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 08:22:05.308781 29785 solver.cpp:228] Iteration 3392, loss = 0.0414582
I0403 08:22:05.309033 29785 solver.cpp:244]     Train net output #0: loss = 0.0414585 (* 1 = 0.0414585 loss)
I0403 08:22:05.515851 29785 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 08:22:16.854296 29785 solver.cpp:228] Iteration 3408, loss = 0.00468863
I0403 08:22:16.854382 29785 solver.cpp:244]     Train net output #0: loss = 0.00468894 (* 1 = 0.00468894 loss)
I0403 08:22:17.035845 29785 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 08:22:28.436916 29785 solver.cpp:228] Iteration 3424, loss = 0.0514448
I0403 08:22:28.437016 29785 solver.cpp:244]     Train net output #0: loss = 0.0514451 (* 1 = 0.0514451 loss)
I0403 08:22:28.620101 29785 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 08:22:40.238914 29785 solver.cpp:228] Iteration 3440, loss = 0.0273015
I0403 08:22:40.239208 29785 solver.cpp:244]     Train net output #0: loss = 0.0273017 (* 1 = 0.0273017 loss)
I0403 08:22:40.407198 29785 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 08:22:51.824995 29785 solver.cpp:228] Iteration 3456, loss = 0.00665077
I0403 08:22:51.825085 29785 solver.cpp:244]     Train net output #0: loss = 0.00665107 (* 1 = 0.00665107 loss)
I0403 08:22:52.006156 29785 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 08:23:03.385567 29785 solver.cpp:228] Iteration 3472, loss = 0.0464502
I0403 08:23:03.385654 29785 solver.cpp:244]     Train net output #0: loss = 0.0464505 (* 1 = 0.0464505 loss)
I0403 08:23:03.526805 29785 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 08:23:15.108144 29785 solver.cpp:228] Iteration 3488, loss = 0.0127674
I0403 08:23:15.108444 29785 solver.cpp:244]     Train net output #0: loss = 0.0127677 (* 1 = 0.0127677 loss)
I0403 08:23:15.300827 29785 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 08:23:26.683156 29785 solver.cpp:228] Iteration 3504, loss = 0.0280925
I0403 08:23:26.683244 29785 solver.cpp:244]     Train net output #0: loss = 0.0280928 (* 1 = 0.0280928 loss)
I0403 08:23:26.856683 29785 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 08:23:38.252046 29785 solver.cpp:228] Iteration 3520, loss = 0.00389554
I0403 08:23:38.252138 29785 solver.cpp:244]     Train net output #0: loss = 0.00389584 (* 1 = 0.00389584 loss)
I0403 08:23:38.426960 29785 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 08:23:49.915565 29785 solver.cpp:228] Iteration 3536, loss = 0.0281542
I0403 08:23:49.915868 29785 solver.cpp:244]     Train net output #0: loss = 0.0281545 (* 1 = 0.0281545 loss)
I0403 08:23:50.119457 29785 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 08:24:01.744302 29785 solver.cpp:228] Iteration 3552, loss = 0.0160113
I0403 08:24:01.744388 29785 solver.cpp:244]     Train net output #0: loss = 0.0160116 (* 1 = 0.0160116 loss)
I0403 08:24:01.897651 29785 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 08:24:13.455267 29785 solver.cpp:228] Iteration 3568, loss = 0.0222582
I0403 08:24:13.455368 29785 solver.cpp:244]     Train net output #0: loss = 0.0222585 (* 1 = 0.0222585 loss)
I0403 08:24:13.644265 29785 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 08:24:18.027999 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3575.caffemodel
I0403 08:24:20.754338 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3575.solverstate
I0403 08:24:22.594689 29785 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 08:25:11.275388 29785 solver.cpp:404]     Test net output #0: accuracy = 0.967696
I0403 08:25:11.275732 29785 solver.cpp:404]     Test net output #1: loss = 0.117358 (* 1 = 0.117358 loss)
I0403 08:25:18.423467 29785 solver.cpp:228] Iteration 3584, loss = 0.0354777
I0403 08:25:18.423566 29785 solver.cpp:244]     Train net output #0: loss = 0.035478 (* 1 = 0.035478 loss)
I0403 08:25:18.613041 29785 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 08:25:30.112118 29785 solver.cpp:228] Iteration 3600, loss = 0.0111367
I0403 08:25:30.112211 29785 solver.cpp:244]     Train net output #0: loss = 0.0111371 (* 1 = 0.0111371 loss)
I0403 08:25:30.312844 29785 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 08:25:41.594285 29785 solver.cpp:228] Iteration 3616, loss = 0.00252902
I0403 08:25:41.594550 29785 solver.cpp:244]     Train net output #0: loss = 0.00252933 (* 1 = 0.00252933 loss)
I0403 08:25:41.768175 29785 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 08:25:53.166477 29785 solver.cpp:228] Iteration 3632, loss = 0.023604
I0403 08:25:53.166574 29785 solver.cpp:244]     Train net output #0: loss = 0.0236043 (* 1 = 0.0236043 loss)
I0403 08:25:53.350190 29785 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 08:26:05.026793 29785 solver.cpp:228] Iteration 3648, loss = 0.0538998
I0403 08:26:05.026878 29785 solver.cpp:244]     Train net output #0: loss = 0.0539001 (* 1 = 0.0539001 loss)
I0403 08:26:05.205638 29785 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 08:26:16.649683 29785 solver.cpp:228] Iteration 3664, loss = 0.0180294
I0403 08:26:16.649986 29785 solver.cpp:244]     Train net output #0: loss = 0.0180297 (* 1 = 0.0180297 loss)
I0403 08:26:16.839145 29785 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 08:26:28.164075 29785 solver.cpp:228] Iteration 3680, loss = 0.014591
I0403 08:26:28.164175 29785 solver.cpp:244]     Train net output #0: loss = 0.0145913 (* 1 = 0.0145913 loss)
I0403 08:26:28.376600 29785 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 08:26:39.851518 29785 solver.cpp:228] Iteration 3696, loss = 0.0238609
I0403 08:26:39.851614 29785 solver.cpp:244]     Train net output #0: loss = 0.0238613 (* 1 = 0.0238613 loss)
I0403 08:26:40.037631 29785 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 08:26:51.446905 29785 solver.cpp:228] Iteration 3712, loss = 0.00705271
I0403 08:26:51.447204 29785 solver.cpp:244]     Train net output #0: loss = 0.00705303 (* 1 = 0.00705303 loss)
I0403 08:26:51.619786 29785 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 08:27:03.010335 29785 solver.cpp:228] Iteration 3728, loss = 0.0203402
I0403 08:27:03.010432 29785 solver.cpp:244]     Train net output #0: loss = 0.0203405 (* 1 = 0.0203405 loss)
I0403 08:27:03.202555 29785 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 08:27:14.601624 29785 solver.cpp:228] Iteration 3744, loss = 0.0463913
I0403 08:27:14.601722 29785 solver.cpp:244]     Train net output #0: loss = 0.0463916 (* 1 = 0.0463916 loss)
I0403 08:27:14.786268 29785 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 08:27:26.182133 29785 solver.cpp:228] Iteration 3760, loss = 0.0664092
I0403 08:27:26.182441 29785 solver.cpp:244]     Train net output #0: loss = 0.0664095 (* 1 = 0.0664095 loss)
I0403 08:27:26.393167 29785 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 08:27:37.986150 29785 solver.cpp:228] Iteration 3776, loss = 0.0416679
I0403 08:27:37.986243 29785 solver.cpp:244]     Train net output #0: loss = 0.0416682 (* 1 = 0.0416682 loss)
I0403 08:27:38.174942 29785 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 08:27:49.669394 29785 solver.cpp:228] Iteration 3792, loss = 0.0105804
I0403 08:27:49.669491 29785 solver.cpp:244]     Train net output #0: loss = 0.0105807 (* 1 = 0.0105807 loss)
I0403 08:27:49.906548 29785 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 08:28:01.533686 29785 solver.cpp:228] Iteration 3808, loss = 0.0150602
I0403 08:28:01.533996 29785 solver.cpp:244]     Train net output #0: loss = 0.0150606 (* 1 = 0.0150606 loss)
I0403 08:28:01.695534 29785 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 08:28:13.309742 29785 solver.cpp:228] Iteration 3824, loss = 0.0290741
I0403 08:28:13.309840 29785 solver.cpp:244]     Train net output #0: loss = 0.0290744 (* 1 = 0.0290744 loss)
I0403 08:28:13.542680 29785 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 08:28:24.878132 29785 solver.cpp:228] Iteration 3840, loss = 0.00678299
I0403 08:28:24.878226 29785 solver.cpp:244]     Train net output #0: loss = 0.00678331 (* 1 = 0.00678331 loss)
I0403 08:28:25.070955 29785 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 08:28:36.491724 29785 solver.cpp:228] Iteration 3856, loss = 0.0549265
I0403 08:28:36.492025 29785 solver.cpp:244]     Train net output #0: loss = 0.0549269 (* 1 = 0.0549269 loss)
I0403 08:28:36.678184 29785 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 08:28:48.033156 29785 solver.cpp:228] Iteration 3872, loss = 0.0109574
I0403 08:28:48.033253 29785 solver.cpp:244]     Train net output #0: loss = 0.0109577 (* 1 = 0.0109577 loss)
I0403 08:28:48.232337 29785 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 08:28:59.709370 29785 solver.cpp:228] Iteration 3888, loss = 0.00680092
I0403 08:28:59.709456 29785 solver.cpp:244]     Train net output #0: loss = 0.00680124 (* 1 = 0.00680124 loss)
I0403 08:28:59.885468 29785 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 08:29:07.844146 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3900.caffemodel
I0403 08:29:10.593853 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_3900.solverstate
I0403 08:29:12.409373 29785 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 08:30:01.096065 29785 solver.cpp:404]     Test net output #0: accuracy = 0.969401
I0403 08:30:01.096369 29785 solver.cpp:404]     Test net output #1: loss = 0.116084 (* 1 = 0.116084 loss)
I0403 08:30:04.510442 29785 solver.cpp:228] Iteration 3904, loss = 0.0041934
I0403 08:30:04.510536 29785 solver.cpp:244]     Train net output #0: loss = 0.00419373 (* 1 = 0.00419373 loss)
I0403 08:30:04.699878 29785 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 08:30:16.096796 29785 solver.cpp:228] Iteration 3920, loss = 0.00675701
I0403 08:30:16.096889 29785 solver.cpp:244]     Train net output #0: loss = 0.00675733 (* 1 = 0.00675733 loss)
I0403 08:30:16.289302 29785 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 08:30:27.734824 29785 solver.cpp:228] Iteration 3936, loss = 0.0246485
I0403 08:30:27.734918 29785 solver.cpp:244]     Train net output #0: loss = 0.0246488 (* 1 = 0.0246488 loss)
I0403 08:30:27.929533 29785 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 08:30:39.293921 29785 solver.cpp:228] Iteration 3952, loss = 0.0138162
I0403 08:30:39.294219 29785 solver.cpp:244]     Train net output #0: loss = 0.0138166 (* 1 = 0.0138166 loss)
I0403 08:30:39.529474 29785 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 08:30:50.939326 29785 solver.cpp:228] Iteration 3968, loss = 0.00671767
I0403 08:30:50.939424 29785 solver.cpp:244]     Train net output #0: loss = 0.00671798 (* 1 = 0.00671798 loss)
I0403 08:30:51.150921 29785 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 08:31:02.560159 29785 solver.cpp:228] Iteration 3984, loss = 0.0136376
I0403 08:31:02.560248 29785 solver.cpp:244]     Train net output #0: loss = 0.0136379 (* 1 = 0.0136379 loss)
I0403 08:31:02.738984 29785 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 08:31:14.241261 29785 solver.cpp:228] Iteration 4000, loss = 0.0132794
I0403 08:31:14.241582 29785 solver.cpp:244]     Train net output #0: loss = 0.0132797 (* 1 = 0.0132797 loss)
I0403 08:31:14.423960 29785 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 08:31:25.770936 29785 solver.cpp:228] Iteration 4016, loss = 0.0193234
I0403 08:31:25.771034 29785 solver.cpp:244]     Train net output #0: loss = 0.0193237 (* 1 = 0.0193237 loss)
I0403 08:31:25.990391 29785 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 08:31:37.296293 29785 solver.cpp:228] Iteration 4032, loss = 0.0022005
I0403 08:31:37.311841 29785 solver.cpp:244]     Train net output #0: loss = 0.00220082 (* 1 = 0.00220082 loss)
I0403 08:31:37.477397 29785 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 08:31:48.899632 29785 solver.cpp:228] Iteration 4048, loss = 0.0602947
I0403 08:31:48.899945 29785 solver.cpp:244]     Train net output #0: loss = 0.060295 (* 1 = 0.060295 loss)
I0403 08:31:49.134263 29785 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 08:32:00.584733 29785 solver.cpp:228] Iteration 4064, loss = 0.0159181
I0403 08:32:00.584831 29785 solver.cpp:244]     Train net output #0: loss = 0.0159184 (* 1 = 0.0159184 loss)
I0403 08:32:00.767771 29785 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 08:32:12.157570 29785 solver.cpp:228] Iteration 4080, loss = 0.0312709
I0403 08:32:12.157666 29785 solver.cpp:244]     Train net output #0: loss = 0.0312712 (* 1 = 0.0312712 loss)
I0403 08:32:12.368324 29785 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 08:32:23.756572 29785 solver.cpp:228] Iteration 4096, loss = 0.00150511
I0403 08:32:23.756870 29785 solver.cpp:244]     Train net output #0: loss = 0.00150543 (* 1 = 0.00150543 loss)
I0403 08:32:23.950228 29785 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 08:32:35.409054 29785 solver.cpp:228] Iteration 4112, loss = 0.0314203
I0403 08:32:35.409154 29785 solver.cpp:244]     Train net output #0: loss = 0.0314206 (* 1 = 0.0314206 loss)
I0403 08:32:35.595278 29785 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 08:32:47.068042 29785 solver.cpp:228] Iteration 4128, loss = 0.0114868
I0403 08:32:47.068140 29785 solver.cpp:244]     Train net output #0: loss = 0.0114871 (* 1 = 0.0114871 loss)
I0403 08:32:47.256974 29785 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 08:32:58.854998 29785 solver.cpp:228] Iteration 4144, loss = 0.0095393
I0403 08:32:58.855252 29785 solver.cpp:244]     Train net output #0: loss = 0.00953962 (* 1 = 0.00953962 loss)
I0403 08:32:59.035944 29785 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 08:33:10.397446 29785 solver.cpp:228] Iteration 4160, loss = 0.00257958
I0403 08:33:10.397533 29785 solver.cpp:244]     Train net output #0: loss = 0.0025799 (* 1 = 0.0025799 loss)
I0403 08:33:10.562194 29785 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 08:33:22.057255 29785 solver.cpp:228] Iteration 4176, loss = 0.011697
I0403 08:33:22.057363 29785 solver.cpp:244]     Train net output #0: loss = 0.0116973 (* 1 = 0.0116973 loss)
I0403 08:33:22.239706 29785 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 08:33:33.677568 29785 solver.cpp:228] Iteration 4192, loss = 0.0203192
I0403 08:33:33.677868 29785 solver.cpp:244]     Train net output #0: loss = 0.0203195 (* 1 = 0.0203195 loss)
I0403 08:33:33.889087 29785 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 08:33:45.293681 29785 solver.cpp:228] Iteration 4208, loss = 0.0263479
I0403 08:33:45.293781 29785 solver.cpp:244]     Train net output #0: loss = 0.0263482 (* 1 = 0.0263482 loss)
I0403 08:33:45.486284 29785 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 08:33:56.951553 29785 solver.cpp:228] Iteration 4224, loss = 0.0219814
I0403 08:33:56.951649 29785 solver.cpp:244]     Train net output #0: loss = 0.0219818 (* 1 = 0.0219818 loss)
I0403 08:33:57.146556 29785 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 08:33:57.146795 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4225.caffemodel
I0403 08:33:59.920707 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4225.solverstate
I0403 08:34:01.732812 29785 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 08:34:50.421746 29785 solver.cpp:404]     Test net output #0: accuracy = 0.968572
I0403 08:34:50.422127 29785 solver.cpp:404]     Test net output #1: loss = 0.115806 (* 1 = 0.115806 loss)
I0403 08:35:01.824540 29785 solver.cpp:228] Iteration 4240, loss = 0.00913695
I0403 08:35:01.824633 29785 solver.cpp:244]     Train net output #0: loss = 0.00913726 (* 1 = 0.00913726 loss)
I0403 08:35:02.016240 29785 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 08:35:13.578028 29785 solver.cpp:228] Iteration 4256, loss = 0.0516731
I0403 08:35:13.578122 29785 solver.cpp:244]     Train net output #0: loss = 0.0516734 (* 1 = 0.0516734 loss)
I0403 08:35:13.759519 29785 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 08:35:25.293226 29785 solver.cpp:228] Iteration 4272, loss = 0.0291703
I0403 08:35:25.293532 29785 solver.cpp:244]     Train net output #0: loss = 0.0291706 (* 1 = 0.0291706 loss)
I0403 08:35:25.508795 29785 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 08:35:36.971906 29785 solver.cpp:228] Iteration 4288, loss = 0.0337301
I0403 08:35:36.972008 29785 solver.cpp:244]     Train net output #0: loss = 0.0337304 (* 1 = 0.0337304 loss)
I0403 08:35:37.152581 29785 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 08:35:48.650444 29785 solver.cpp:228] Iteration 4304, loss = 0.026941
I0403 08:35:48.650538 29785 solver.cpp:244]     Train net output #0: loss = 0.0269413 (* 1 = 0.0269413 loss)
I0403 08:35:48.846091 29785 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 08:36:00.300789 29785 solver.cpp:228] Iteration 4320, loss = 0.0125567
I0403 08:36:00.301102 29785 solver.cpp:244]     Train net output #0: loss = 0.012557 (* 1 = 0.012557 loss)
I0403 08:36:00.464711 29785 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 08:36:12.310933 29785 solver.cpp:228] Iteration 4336, loss = 0.0307286
I0403 08:36:12.311023 29785 solver.cpp:244]     Train net output #0: loss = 0.0307289 (* 1 = 0.0307289 loss)
I0403 08:36:12.475950 29785 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 08:36:24.063894 29785 solver.cpp:228] Iteration 4352, loss = 0.00436904
I0403 08:36:24.063990 29785 solver.cpp:244]     Train net output #0: loss = 0.00436934 (* 1 = 0.00436934 loss)
I0403 08:36:24.257535 29785 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 08:36:35.604990 29785 solver.cpp:228] Iteration 4368, loss = 0.0107278
I0403 08:36:35.605285 29785 solver.cpp:244]     Train net output #0: loss = 0.010728 (* 1 = 0.010728 loss)
I0403 08:36:35.786309 29785 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 08:36:47.164124 29785 solver.cpp:228] Iteration 4384, loss = 0.00726191
I0403 08:36:47.164222 29785 solver.cpp:244]     Train net output #0: loss = 0.0072622 (* 1 = 0.0072622 loss)
I0403 08:36:47.355465 29785 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 08:36:58.738339 29785 solver.cpp:228] Iteration 4400, loss = 0.0486007
I0403 08:36:58.738450 29785 solver.cpp:244]     Train net output #0: loss = 0.048601 (* 1 = 0.048601 loss)
I0403 08:36:58.965924 29785 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 08:37:10.479244 29785 solver.cpp:228] Iteration 4416, loss = 0.0105852
I0403 08:37:10.479552 29785 solver.cpp:244]     Train net output #0: loss = 0.0105855 (* 1 = 0.0105855 loss)
I0403 08:37:10.696807 29785 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 08:37:22.089639 29785 solver.cpp:228] Iteration 4432, loss = 0.00517398
I0403 08:37:22.089740 29785 solver.cpp:244]     Train net output #0: loss = 0.00517427 (* 1 = 0.00517427 loss)
I0403 08:37:22.286319 29785 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 08:37:33.784147 29785 solver.cpp:228] Iteration 4448, loss = 0.00348104
I0403 08:37:33.784242 29785 solver.cpp:244]     Train net output #0: loss = 0.00348132 (* 1 = 0.00348132 loss)
I0403 08:37:33.972542 29785 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 08:37:45.571404 29785 solver.cpp:228] Iteration 4464, loss = 0.00985441
I0403 08:37:45.571725 29785 solver.cpp:244]     Train net output #0: loss = 0.0098547 (* 1 = 0.0098547 loss)
I0403 08:37:45.743860 29785 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 08:37:57.126371 29785 solver.cpp:228] Iteration 4480, loss = 0.00534247
I0403 08:37:57.126468 29785 solver.cpp:244]     Train net output #0: loss = 0.00534276 (* 1 = 0.00534276 loss)
I0403 08:37:57.313761 29785 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 08:38:08.804013 29785 solver.cpp:228] Iteration 4496, loss = 0.00677053
I0403 08:38:08.804116 29785 solver.cpp:244]     Train net output #0: loss = 0.00677082 (* 1 = 0.00677082 loss)
I0403 08:38:08.987690 29785 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 08:38:20.352241 29785 solver.cpp:228] Iteration 4512, loss = 0.00546701
I0403 08:38:20.352524 29785 solver.cpp:244]     Train net output #0: loss = 0.0054673 (* 1 = 0.0054673 loss)
I0403 08:38:20.552938 29785 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 08:38:31.973825 29785 solver.cpp:228] Iteration 4528, loss = 0.00239775
I0403 08:38:31.973922 29785 solver.cpp:244]     Train net output #0: loss = 0.00239804 (* 1 = 0.00239804 loss)
I0403 08:38:32.168129 29785 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 08:38:43.632329 29785 solver.cpp:228] Iteration 4544, loss = 0.00685985
I0403 08:38:43.632426 29785 solver.cpp:244]     Train net output #0: loss = 0.00686014 (* 1 = 0.00686014 loss)
I0403 08:38:43.814515 29785 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 08:38:47.496481 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4550.caffemodel
I0403 08:38:50.299073 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4550.solverstate
I0403 08:38:52.201267 29785 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 08:39:40.869877 29785 solver.cpp:404]     Test net output #0: accuracy = 0.970139
I0403 08:39:40.870168 29785 solver.cpp:404]     Test net output #1: loss = 0.112578 (* 1 = 0.112578 loss)
I0403 08:39:48.622973 29785 solver.cpp:228] Iteration 4560, loss = 0.0195547
I0403 08:39:48.623070 29785 solver.cpp:244]     Train net output #0: loss = 0.019555 (* 1 = 0.019555 loss)
I0403 08:39:48.816421 29785 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 08:40:00.277544 29785 solver.cpp:228] Iteration 4576, loss = 0.0301111
I0403 08:40:00.277640 29785 solver.cpp:244]     Train net output #0: loss = 0.0301114 (* 1 = 0.0301114 loss)
I0403 08:40:00.459662 29785 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 08:40:11.841645 29785 solver.cpp:228] Iteration 4592, loss = 0.00931288
I0403 08:40:11.841929 29785 solver.cpp:244]     Train net output #0: loss = 0.00931318 (* 1 = 0.00931318 loss)
I0403 08:40:12.061882 29785 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 08:40:23.517124 29785 solver.cpp:228] Iteration 4608, loss = 0.00371885
I0403 08:40:23.517220 29785 solver.cpp:244]     Train net output #0: loss = 0.00371915 (* 1 = 0.00371915 loss)
I0403 08:40:23.719374 29785 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 08:40:35.060122 29785 solver.cpp:228] Iteration 4624, loss = 0.00827898
I0403 08:40:35.060209 29785 solver.cpp:244]     Train net output #0: loss = 0.00827927 (* 1 = 0.00827927 loss)
I0403 08:40:35.235822 29785 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 08:40:46.513378 29785 solver.cpp:228] Iteration 4640, loss = 0.0466663
I0403 08:40:46.513703 29785 solver.cpp:244]     Train net output #0: loss = 0.0466666 (* 1 = 0.0466666 loss)
I0403 08:40:46.694428 29785 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 08:40:58.210155 29785 solver.cpp:228] Iteration 4656, loss = 0.00917165
I0403 08:40:58.210239 29785 solver.cpp:244]     Train net output #0: loss = 0.00917195 (* 1 = 0.00917195 loss)
I0403 08:40:58.361605 29785 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 08:41:09.777339 29785 solver.cpp:228] Iteration 4672, loss = 0.00946942
I0403 08:41:09.777459 29785 solver.cpp:244]     Train net output #0: loss = 0.00946972 (* 1 = 0.00946972 loss)
I0403 08:41:09.977902 29785 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 08:41:21.712270 29785 solver.cpp:228] Iteration 4688, loss = 0.0133424
I0403 08:41:21.712581 29785 solver.cpp:244]     Train net output #0: loss = 0.0133427 (* 1 = 0.0133427 loss)
I0403 08:41:21.939463 29785 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 08:41:33.311779 29785 solver.cpp:228] Iteration 4704, loss = 0.0125313
I0403 08:41:33.311872 29785 solver.cpp:244]     Train net output #0: loss = 0.0125316 (* 1 = 0.0125316 loss)
I0403 08:41:33.514513 29785 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 08:41:45.123786 29785 solver.cpp:228] Iteration 4720, loss = 0.0342516
I0403 08:41:45.123885 29785 solver.cpp:244]     Train net output #0: loss = 0.0342519 (* 1 = 0.0342519 loss)
I0403 08:41:45.326937 29785 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 08:41:56.692553 29785 solver.cpp:228] Iteration 4736, loss = 0.0188329
I0403 08:41:56.692857 29785 solver.cpp:244]     Train net output #0: loss = 0.0188332 (* 1 = 0.0188332 loss)
I0403 08:41:56.950060 29785 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 08:42:08.307060 29785 solver.cpp:228] Iteration 4752, loss = 0.00919564
I0403 08:42:08.307160 29785 solver.cpp:244]     Train net output #0: loss = 0.00919595 (* 1 = 0.00919595 loss)
I0403 08:42:08.516700 29785 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 08:42:19.892385 29785 solver.cpp:228] Iteration 4768, loss = 0.00152375
I0403 08:42:19.892479 29785 solver.cpp:244]     Train net output #0: loss = 0.00152406 (* 1 = 0.00152406 loss)
I0403 08:42:20.099943 29785 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 08:42:31.634476 29785 solver.cpp:228] Iteration 4784, loss = 0.00489193
I0403 08:42:31.634805 29785 solver.cpp:244]     Train net output #0: loss = 0.00489224 (* 1 = 0.00489224 loss)
I0403 08:42:31.817991 29785 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 08:42:43.379662 29785 solver.cpp:228] Iteration 4800, loss = 0.00723289
I0403 08:42:43.379756 29785 solver.cpp:244]     Train net output #0: loss = 0.0072332 (* 1 = 0.0072332 loss)
I0403 08:42:43.566507 29785 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 08:42:55.003269 29785 solver.cpp:228] Iteration 4816, loss = 0.0365596
I0403 08:42:55.003367 29785 solver.cpp:244]     Train net output #0: loss = 0.03656 (* 1 = 0.03656 loss)
I0403 08:42:55.195647 29785 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 08:43:06.763602 29785 solver.cpp:228] Iteration 4832, loss = 0.0256094
I0403 08:43:06.763895 29785 solver.cpp:244]     Train net output #0: loss = 0.0256097 (* 1 = 0.0256097 loss)
I0403 08:43:06.915172 29785 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 08:43:18.687129 29785 solver.cpp:228] Iteration 4848, loss = 0.0122537
I0403 08:43:18.687227 29785 solver.cpp:244]     Train net output #0: loss = 0.0122541 (* 1 = 0.0122541 loss)
I0403 08:43:18.893651 29785 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 08:43:30.575882 29785 solver.cpp:228] Iteration 4864, loss = 0.0110432
I0403 08:43:30.575970 29785 solver.cpp:244]     Train net output #0: loss = 0.0110436 (* 1 = 0.0110436 loss)
I0403 08:43:30.756572 29785 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 08:43:38.035074 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4875.caffemodel
I0403 08:43:40.749133 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_4875.solverstate
I0403 08:43:42.576004 29785 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 08:44:31.249104 29785 solver.cpp:404]     Test net output #0: accuracy = 0.969954
I0403 08:44:31.249407 29785 solver.cpp:404]     Test net output #1: loss = 0.114952 (* 1 = 0.114952 loss)
I0403 08:44:35.395391 29785 solver.cpp:228] Iteration 4880, loss = 0.00483983
I0403 08:44:35.395488 29785 solver.cpp:244]     Train net output #0: loss = 0.00484014 (* 1 = 0.00484014 loss)
I0403 08:44:35.612946 29785 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 08:44:46.996454 29785 solver.cpp:228] Iteration 4896, loss = 0.0150025
I0403 08:44:46.996548 29785 solver.cpp:244]     Train net output #0: loss = 0.0150028 (* 1 = 0.0150028 loss)
I0403 08:44:47.183882 29785 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 08:44:58.694098 29785 solver.cpp:228] Iteration 4912, loss = 0.0153863
I0403 08:44:58.694202 29785 solver.cpp:244]     Train net output #0: loss = 0.0153866 (* 1 = 0.0153866 loss)
I0403 08:44:58.874631 29785 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 08:45:10.334971 29785 solver.cpp:228] Iteration 4928, loss = 0.0120587
I0403 08:45:10.335276 29785 solver.cpp:244]     Train net output #0: loss = 0.012059 (* 1 = 0.012059 loss)
I0403 08:45:10.541025 29785 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 08:45:21.970163 29785 solver.cpp:228] Iteration 4944, loss = 0.00964004
I0403 08:45:21.970250 29785 solver.cpp:244]     Train net output #0: loss = 0.00964035 (* 1 = 0.00964035 loss)
I0403 08:45:22.136997 29785 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 08:45:33.684566 29785 solver.cpp:228] Iteration 4960, loss = 0.037862
I0403 08:45:33.684664 29785 solver.cpp:244]     Train net output #0: loss = 0.0378623 (* 1 = 0.0378623 loss)
I0403 08:45:33.920161 29785 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 08:45:45.464884 29785 solver.cpp:228] Iteration 4976, loss = 0.0281846
I0403 08:45:45.467188 29785 solver.cpp:244]     Train net output #0: loss = 0.0281849 (* 1 = 0.0281849 loss)
I0403 08:45:45.676440 29785 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 08:45:57.160513 29785 solver.cpp:228] Iteration 4992, loss = 0.0221997
I0403 08:45:57.160609 29785 solver.cpp:244]     Train net output #0: loss = 0.0222001 (* 1 = 0.0222001 loss)
I0403 08:45:57.359371 29785 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 08:46:08.890664 29785 solver.cpp:228] Iteration 5008, loss = 0.00176808
I0403 08:46:08.890760 29785 solver.cpp:244]     Train net output #0: loss = 0.00176839 (* 1 = 0.00176839 loss)
I0403 08:46:09.076745 29785 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 08:46:20.761337 29785 solver.cpp:228] Iteration 5024, loss = 0.0070154
I0403 08:46:20.761620 29785 solver.cpp:244]     Train net output #0: loss = 0.00701571 (* 1 = 0.00701571 loss)
I0403 08:46:20.917898 29785 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 08:46:32.571193 29785 solver.cpp:228] Iteration 5040, loss = 0.00624389
I0403 08:46:32.571292 29785 solver.cpp:244]     Train net output #0: loss = 0.0062442 (* 1 = 0.0062442 loss)
I0403 08:46:32.758306 29785 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 08:46:44.141898 29785 solver.cpp:228] Iteration 5056, loss = 0.004069
I0403 08:46:44.141995 29785 solver.cpp:244]     Train net output #0: loss = 0.00406931 (* 1 = 0.00406931 loss)
I0403 08:46:44.343026 29785 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 08:46:55.760697 29785 solver.cpp:228] Iteration 5072, loss = 0.00961975
I0403 08:46:55.760987 29785 solver.cpp:244]     Train net output #0: loss = 0.00962006 (* 1 = 0.00962006 loss)
I0403 08:46:55.937785 29785 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 08:47:07.348606 29785 solver.cpp:228] Iteration 5088, loss = 0.0131063
I0403 08:47:07.348695 29785 solver.cpp:244]     Train net output #0: loss = 0.0131066 (* 1 = 0.0131066 loss)
I0403 08:47:07.524104 29785 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 08:47:18.888087 29785 solver.cpp:228] Iteration 5104, loss = 0.0138662
I0403 08:47:18.888190 29785 solver.cpp:244]     Train net output #0: loss = 0.0138665 (* 1 = 0.0138665 loss)
I0403 08:47:19.109771 29785 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 08:47:30.546864 29785 solver.cpp:228] Iteration 5120, loss = 0.00844071
I0403 08:47:30.547193 29785 solver.cpp:244]     Train net output #0: loss = 0.00844102 (* 1 = 0.00844102 loss)
I0403 08:47:30.732883 29785 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 08:47:42.376569 29785 solver.cpp:228] Iteration 5136, loss = 0.0294103
I0403 08:47:42.376657 29785 solver.cpp:244]     Train net output #0: loss = 0.0294106 (* 1 = 0.0294106 loss)
I0403 08:47:42.557461 29785 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 08:47:53.950600 29785 solver.cpp:228] Iteration 5152, loss = 0.00896702
I0403 08:47:53.950697 29785 solver.cpp:244]     Train net output #0: loss = 0.00896734 (* 1 = 0.00896734 loss)
I0403 08:47:54.132421 29785 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 08:48:05.541635 29785 solver.cpp:228] Iteration 5168, loss = 0.00809098
I0403 08:48:05.541945 29785 solver.cpp:244]     Train net output #0: loss = 0.00809129 (* 1 = 0.00809129 loss)
I0403 08:48:05.735962 29785 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 08:48:17.205718 29785 solver.cpp:228] Iteration 5184, loss = 0.00234658
I0403 08:48:17.205807 29785 solver.cpp:244]     Train net output #0: loss = 0.00234689 (* 1 = 0.00234689 loss)
I0403 08:48:17.365438 29785 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 08:48:28.368069 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5200.caffemodel
I0403 08:48:31.234046 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5200.solverstate
I0403 08:48:33.117089 29785 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 08:49:21.796999 29785 solver.cpp:404]     Test net output #0: accuracy = 0.970231
I0403 08:49:21.798970 29785 solver.cpp:404]     Test net output #1: loss = 0.113725 (* 1 = 0.113725 loss)
I0403 08:49:22.314043 29785 solver.cpp:228] Iteration 5200, loss = 0.017692
I0403 08:49:22.314131 29785 solver.cpp:244]     Train net output #0: loss = 0.0176923 (* 1 = 0.0176923 loss)
I0403 08:49:22.488101 29785 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 08:49:33.920786 29785 solver.cpp:228] Iteration 5216, loss = 0.00878871
I0403 08:49:33.920873 29785 solver.cpp:244]     Train net output #0: loss = 0.00878902 (* 1 = 0.00878902 loss)
I0403 08:49:34.095463 29785 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 08:49:45.627180 29785 solver.cpp:228] Iteration 5232, loss = 0.00225935
I0403 08:49:45.627279 29785 solver.cpp:244]     Train net output #0: loss = 0.00225966 (* 1 = 0.00225966 loss)
I0403 08:49:45.830418 29785 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 08:49:57.255897 29785 solver.cpp:228] Iteration 5248, loss = 0.029067
I0403 08:49:57.256193 29785 solver.cpp:244]     Train net output #0: loss = 0.0290673 (* 1 = 0.0290673 loss)
I0403 08:49:57.412690 29785 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 08:50:08.890264 29785 solver.cpp:228] Iteration 5264, loss = 0.0765129
I0403 08:50:08.890353 29785 solver.cpp:244]     Train net output #0: loss = 0.0765132 (* 1 = 0.0765132 loss)
I0403 08:50:09.068147 29785 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 08:50:20.452193 29785 solver.cpp:228] Iteration 5280, loss = 0.0350492
I0403 08:50:20.452289 29785 solver.cpp:244]     Train net output #0: loss = 0.0350496 (* 1 = 0.0350496 loss)
I0403 08:50:20.646630 29785 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 08:50:32.152681 29785 solver.cpp:228] Iteration 5296, loss = 0.00455372
I0403 08:50:32.153009 29785 solver.cpp:244]     Train net output #0: loss = 0.00455404 (* 1 = 0.00455404 loss)
I0403 08:50:32.344159 29785 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 08:50:43.816119 29785 solver.cpp:228] Iteration 5312, loss = 0.0502793
I0403 08:50:43.816217 29785 solver.cpp:244]     Train net output #0: loss = 0.0502797 (* 1 = 0.0502797 loss)
I0403 08:50:44.008126 29785 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 08:50:55.441941 29785 solver.cpp:228] Iteration 5328, loss = 0.00973161
I0403 08:50:55.442035 29785 solver.cpp:244]     Train net output #0: loss = 0.00973193 (* 1 = 0.00973193 loss)
I0403 08:50:55.627594 29785 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 08:51:07.024560 29785 solver.cpp:228] Iteration 5344, loss = 0.0192162
I0403 08:51:07.024895 29785 solver.cpp:244]     Train net output #0: loss = 0.0192166 (* 1 = 0.0192166 loss)
I0403 08:51:07.227128 29785 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 08:51:18.613204 29785 solver.cpp:228] Iteration 5360, loss = 0.00614641
I0403 08:51:18.613306 29785 solver.cpp:244]     Train net output #0: loss = 0.00614673 (* 1 = 0.00614673 loss)
I0403 08:51:18.821544 29785 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 08:51:30.283046 29785 solver.cpp:228] Iteration 5376, loss = 0.00598522
I0403 08:51:30.283136 29785 solver.cpp:244]     Train net output #0: loss = 0.00598554 (* 1 = 0.00598554 loss)
I0403 08:51:30.458788 29785 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 08:51:41.945603 29785 solver.cpp:228] Iteration 5392, loss = 0.00755049
I0403 08:51:41.945910 29785 solver.cpp:244]     Train net output #0: loss = 0.00755081 (* 1 = 0.00755081 loss)
I0403 08:51:42.153059 29785 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 08:51:53.560571 29785 solver.cpp:228] Iteration 5408, loss = 0.00282253
I0403 08:51:53.560673 29785 solver.cpp:244]     Train net output #0: loss = 0.00282285 (* 1 = 0.00282285 loss)
I0403 08:51:53.795608 29785 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 08:52:05.244321 29785 solver.cpp:228] Iteration 5424, loss = 0.0125765
I0403 08:52:05.244418 29785 solver.cpp:244]     Train net output #0: loss = 0.0125768 (* 1 = 0.0125768 loss)
I0403 08:52:05.439373 29785 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 08:52:16.725668 29785 solver.cpp:228] Iteration 5440, loss = 0.0261811
I0403 08:52:16.725961 29785 solver.cpp:244]     Train net output #0: loss = 0.0261814 (* 1 = 0.0261814 loss)
I0403 08:52:16.935600 29785 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 08:52:28.474308 29785 solver.cpp:228] Iteration 5456, loss = 0.0197728
I0403 08:52:28.474407 29785 solver.cpp:244]     Train net output #0: loss = 0.0197731 (* 1 = 0.0197731 loss)
I0403 08:52:28.656846 29785 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 08:52:40.185869 29785 solver.cpp:228] Iteration 5472, loss = 0.0164564
I0403 08:52:40.185971 29785 solver.cpp:244]     Train net output #0: loss = 0.0164567 (* 1 = 0.0164567 loss)
I0403 08:52:40.375560 29785 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 08:52:51.766474 29785 solver.cpp:228] Iteration 5488, loss = 0.0244695
I0403 08:52:51.766770 29785 solver.cpp:244]     Train net output #0: loss = 0.0244698 (* 1 = 0.0244698 loss)
I0403 08:52:51.968142 29785 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 08:53:03.510252 29785 solver.cpp:228] Iteration 5504, loss = 0.00525652
I0403 08:53:03.510349 29785 solver.cpp:244]     Train net output #0: loss = 0.00525684 (* 1 = 0.00525684 loss)
I0403 08:53:03.710480 29785 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 08:53:15.077884 29785 solver.cpp:228] Iteration 5520, loss = 0.0377944
I0403 08:53:15.077982 29785 solver.cpp:244]     Train net output #0: loss = 0.0377947 (* 1 = 0.0377947 loss)
I0403 08:53:15.340634 29785 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 08:53:18.287034 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5525.caffemodel
I0403 08:53:21.036422 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5525.solverstate
I0403 08:53:22.917939 29785 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 08:54:11.577884 29785 solver.cpp:404]     Test net output #0: accuracy = 0.971245
I0403 08:54:11.578184 29785 solver.cpp:404]     Test net output #1: loss = 0.110086 (* 1 = 0.110086 loss)
I0403 08:54:20.069103 29785 solver.cpp:228] Iteration 5536, loss = 0.0382164
I0403 08:54:20.069205 29785 solver.cpp:244]     Train net output #0: loss = 0.0382167 (* 1 = 0.0382167 loss)
I0403 08:54:20.253309 29785 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 08:54:31.655612 29785 solver.cpp:228] Iteration 5552, loss = 0.0239347
I0403 08:54:31.655709 29785 solver.cpp:244]     Train net output #0: loss = 0.023935 (* 1 = 0.023935 loss)
I0403 08:54:31.916901 29785 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 08:54:43.485239 29785 solver.cpp:228] Iteration 5568, loss = 0.00214995
I0403 08:54:43.485553 29785 solver.cpp:244]     Train net output #0: loss = 0.00215026 (* 1 = 0.00215026 loss)
I0403 08:54:43.697305 29785 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 08:54:55.054488 29785 solver.cpp:228] Iteration 5584, loss = 0.00854808
I0403 08:54:55.054577 29785 solver.cpp:244]     Train net output #0: loss = 0.00854838 (* 1 = 0.00854838 loss)
I0403 08:54:55.174650 29785 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 08:55:06.806996 29785 solver.cpp:228] Iteration 5600, loss = 0.0187042
I0403 08:55:06.807092 29785 solver.cpp:244]     Train net output #0: loss = 0.0187046 (* 1 = 0.0187046 loss)
I0403 08:55:07.005317 29785 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 08:55:18.434103 29785 solver.cpp:228] Iteration 5616, loss = 0.00959235
I0403 08:55:18.434406 29785 solver.cpp:244]     Train net output #0: loss = 0.00959266 (* 1 = 0.00959266 loss)
I0403 08:55:18.619913 29785 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 08:55:30.207993 29785 solver.cpp:228] Iteration 5632, loss = 0.0257041
I0403 08:55:30.208076 29785 solver.cpp:244]     Train net output #0: loss = 0.0257044 (* 1 = 0.0257044 loss)
I0403 08:55:30.370421 29785 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 08:55:41.935281 29785 solver.cpp:228] Iteration 5648, loss = 0.0651564
I0403 08:55:41.935371 29785 solver.cpp:244]     Train net output #0: loss = 0.0651567 (* 1 = 0.0651567 loss)
I0403 08:55:42.061106 29785 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 08:55:53.553427 29785 solver.cpp:228] Iteration 5664, loss = 0.0124907
I0403 08:55:53.553699 29785 solver.cpp:244]     Train net output #0: loss = 0.012491 (* 1 = 0.012491 loss)
I0403 08:55:53.771205 29785 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 08:56:05.156556 29785 solver.cpp:228] Iteration 5680, loss = 0.0322186
I0403 08:56:05.156653 29785 solver.cpp:244]     Train net output #0: loss = 0.0322189 (* 1 = 0.0322189 loss)
I0403 08:56:05.346190 29785 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 08:56:16.753304 29785 solver.cpp:228] Iteration 5696, loss = 0.0136146
I0403 08:56:16.753402 29785 solver.cpp:244]     Train net output #0: loss = 0.0136148 (* 1 = 0.0136148 loss)
I0403 08:56:16.985514 29785 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 08:56:28.406244 29785 solver.cpp:228] Iteration 5712, loss = 0.0037303
I0403 08:56:28.408149 29785 solver.cpp:244]     Train net output #0: loss = 0.0037306 (* 1 = 0.0037306 loss)
I0403 08:56:28.641387 29785 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 08:56:40.181414 29785 solver.cpp:228] Iteration 5728, loss = 0.00327705
I0403 08:56:40.181509 29785 solver.cpp:244]     Train net output #0: loss = 0.00327733 (* 1 = 0.00327733 loss)
I0403 08:56:40.373950 29785 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 08:56:51.777734 29785 solver.cpp:228] Iteration 5744, loss = 0.00207141
I0403 08:56:51.777832 29785 solver.cpp:244]     Train net output #0: loss = 0.00207169 (* 1 = 0.00207169 loss)
I0403 08:56:51.963419 29785 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 08:57:03.509948 29785 solver.cpp:228] Iteration 5760, loss = 0.0269651
I0403 08:57:03.510274 29785 solver.cpp:244]     Train net output #0: loss = 0.0269654 (* 1 = 0.0269654 loss)
I0403 08:57:03.725404 29785 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 08:57:15.299424 29785 solver.cpp:228] Iteration 5776, loss = 0.00608836
I0403 08:57:15.299522 29785 solver.cpp:244]     Train net output #0: loss = 0.00608865 (* 1 = 0.00608865 loss)
I0403 08:57:15.483937 29785 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 08:57:26.990133 29785 solver.cpp:228] Iteration 5792, loss = 0.00243627
I0403 08:57:26.990231 29785 solver.cpp:244]     Train net output #0: loss = 0.00243656 (* 1 = 0.00243656 loss)
I0403 08:57:27.177067 29785 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 08:57:38.663893 29785 solver.cpp:228] Iteration 5808, loss = 0.00303422
I0403 08:57:38.664191 29785 solver.cpp:244]     Train net output #0: loss = 0.00303451 (* 1 = 0.00303451 loss)
I0403 08:57:38.843046 29785 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 08:57:50.224376 29785 solver.cpp:228] Iteration 5824, loss = 0.051475
I0403 08:57:50.224477 29785 solver.cpp:244]     Train net output #0: loss = 0.0514753 (* 1 = 0.0514753 loss)
I0403 08:57:50.439406 29785 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 08:58:01.832343 29785 solver.cpp:228] Iteration 5840, loss = 0.0122798
I0403 08:58:01.832427 29785 solver.cpp:244]     Train net output #0: loss = 0.0122801 (* 1 = 0.0122801 loss)
I0403 08:58:02.008577 29785 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 08:58:08.567019 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5850.caffemodel
I0403 08:58:11.450525 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_5850.solverstate
I0403 08:58:13.348126 29785 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 08:59:02.024657 29785 solver.cpp:404]     Test net output #0: accuracy = 0.969678
I0403 08:59:02.025020 29785 solver.cpp:404]     Test net output #1: loss = 0.119407 (* 1 = 0.119407 loss)
I0403 08:59:06.853202 29785 solver.cpp:228] Iteration 5856, loss = 0.00165266
I0403 08:59:06.853294 29785 solver.cpp:244]     Train net output #0: loss = 0.00165295 (* 1 = 0.00165295 loss)
I0403 08:59:07.060319 29785 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 08:59:18.503587 29785 solver.cpp:228] Iteration 5872, loss = 0.0207186
I0403 08:59:18.503676 29785 solver.cpp:244]     Train net output #0: loss = 0.0207188 (* 1 = 0.0207188 loss)
I0403 08:59:18.681161 29785 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 08:59:30.164229 29785 solver.cpp:228] Iteration 5888, loss = 0.00214569
I0403 08:59:30.164322 29785 solver.cpp:244]     Train net output #0: loss = 0.00214598 (* 1 = 0.00214598 loss)
I0403 08:59:30.357399 29785 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 08:59:41.850031 29785 solver.cpp:228] Iteration 5904, loss = 0.00462737
I0403 08:59:41.850335 29785 solver.cpp:244]     Train net output #0: loss = 0.00462765 (* 1 = 0.00462765 loss)
I0403 08:59:42.032290 29785 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 08:59:53.504026 29785 solver.cpp:228] Iteration 5920, loss = 0.0235828
I0403 08:59:53.504129 29785 solver.cpp:244]     Train net output #0: loss = 0.0235831 (* 1 = 0.0235831 loss)
I0403 08:59:53.704025 29785 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 09:00:05.185648 29785 solver.cpp:228] Iteration 5936, loss = 0.029134
I0403 09:00:05.185735 29785 solver.cpp:244]     Train net output #0: loss = 0.0291342 (* 1 = 0.0291342 loss)
I0403 09:00:05.366869 29785 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 09:00:16.860412 29785 solver.cpp:228] Iteration 5952, loss = 0.0333812
I0403 09:00:16.860702 29785 solver.cpp:244]     Train net output #0: loss = 0.0333814 (* 1 = 0.0333814 loss)
I0403 09:00:17.057051 29785 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 09:00:28.477411 29785 solver.cpp:228] Iteration 5968, loss = 0.00359926
I0403 09:00:28.477500 29785 solver.cpp:244]     Train net output #0: loss = 0.00359954 (* 1 = 0.00359954 loss)
I0403 09:00:28.626941 29785 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 09:00:40.102571 29785 solver.cpp:228] Iteration 5984, loss = 0.0029331
I0403 09:00:40.102660 29785 solver.cpp:244]     Train net output #0: loss = 0.00293339 (* 1 = 0.00293339 loss)
I0403 09:00:40.291154 29785 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 09:00:51.666450 29785 solver.cpp:228] Iteration 6000, loss = 0.0117656
I0403 09:00:51.666785 29785 solver.cpp:244]     Train net output #0: loss = 0.0117659 (* 1 = 0.0117659 loss)
I0403 09:00:51.879432 29785 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 09:01:03.246815 29785 solver.cpp:228] Iteration 6016, loss = 0.00510482
I0403 09:01:03.246913 29785 solver.cpp:244]     Train net output #0: loss = 0.0051051 (* 1 = 0.0051051 loss)
I0403 09:01:03.429890 29785 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 09:01:15.049209 29785 solver.cpp:228] Iteration 6032, loss = 0.00223944
I0403 09:01:15.049294 29785 solver.cpp:244]     Train net output #0: loss = 0.00223973 (* 1 = 0.00223973 loss)
I0403 09:01:15.227951 29785 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 09:01:26.775698 29785 solver.cpp:228] Iteration 6048, loss = 0.00753005
I0403 09:01:26.775997 29785 solver.cpp:244]     Train net output #0: loss = 0.00753034 (* 1 = 0.00753034 loss)
I0403 09:01:26.962790 29785 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 09:01:38.290999 29785 solver.cpp:228] Iteration 6064, loss = 0.0231982
I0403 09:01:38.291098 29785 solver.cpp:244]     Train net output #0: loss = 0.0231985 (* 1 = 0.0231985 loss)
I0403 09:01:38.487144 29785 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 09:01:50.002279 29785 solver.cpp:228] Iteration 6080, loss = 0.0269739
I0403 09:01:50.002373 29785 solver.cpp:244]     Train net output #0: loss = 0.0269742 (* 1 = 0.0269742 loss)
I0403 09:01:50.198557 29785 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 09:02:01.691222 29785 solver.cpp:228] Iteration 6096, loss = 0.0305373
I0403 09:02:01.691521 29785 solver.cpp:244]     Train net output #0: loss = 0.0305376 (* 1 = 0.0305376 loss)
I0403 09:02:01.873234 29785 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 09:02:13.243623 29785 solver.cpp:228] Iteration 6112, loss = 0.00320553
I0403 09:02:13.243721 29785 solver.cpp:244]     Train net output #0: loss = 0.00320582 (* 1 = 0.00320582 loss)
I0403 09:02:13.469475 29785 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 09:02:24.839653 29785 solver.cpp:228] Iteration 6128, loss = 0.00655242
I0403 09:02:24.839745 29785 solver.cpp:244]     Train net output #0: loss = 0.00655271 (* 1 = 0.00655271 loss)
I0403 09:02:25.021962 29785 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 09:02:36.473592 29785 solver.cpp:228] Iteration 6144, loss = 0.00778065
I0403 09:02:36.473888 29785 solver.cpp:244]     Train net output #0: loss = 0.00778094 (* 1 = 0.00778094 loss)
I0403 09:02:36.674283 29785 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 09:02:48.136636 29785 solver.cpp:228] Iteration 6160, loss = 0.00112474
I0403 09:02:48.136731 29785 solver.cpp:244]     Train net output #0: loss = 0.00112503 (* 1 = 0.00112503 loss)
I0403 09:02:48.330704 29785 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 09:02:58.642937 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6175.caffemodel
I0403 09:03:01.386029 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6175.solverstate
I0403 09:03:03.255518 29785 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 09:03:51.930212 29785 solver.cpp:404]     Test net output #0: accuracy = 0.971568
I0403 09:03:51.930506 29785 solver.cpp:404]     Test net output #1: loss = 0.112292 (* 1 = 0.112292 loss)
I0403 09:03:53.154717 29785 solver.cpp:228] Iteration 6176, loss = 0.00569453
I0403 09:03:53.154811 29785 solver.cpp:244]     Train net output #0: loss = 0.00569483 (* 1 = 0.00569483 loss)
I0403 09:03:53.343039 29785 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 09:04:04.916885 29785 solver.cpp:228] Iteration 6192, loss = 0.00562147
I0403 09:04:04.916980 29785 solver.cpp:244]     Train net output #0: loss = 0.00562176 (* 1 = 0.00562176 loss)
I0403 09:04:05.098943 29785 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 09:04:16.445566 29785 solver.cpp:228] Iteration 6208, loss = 0.00176116
I0403 09:04:16.445669 29785 solver.cpp:244]     Train net output #0: loss = 0.00176145 (* 1 = 0.00176145 loss)
I0403 09:04:16.666952 29785 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 09:04:28.155360 29785 solver.cpp:228] Iteration 6224, loss = 0.0383182
I0403 09:04:28.155683 29785 solver.cpp:244]     Train net output #0: loss = 0.0383185 (* 1 = 0.0383185 loss)
I0403 09:04:28.329278 29785 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 09:04:39.695142 29785 solver.cpp:228] Iteration 6240, loss = 0.0240206
I0403 09:04:39.695242 29785 solver.cpp:244]     Train net output #0: loss = 0.0240209 (* 1 = 0.0240209 loss)
I0403 09:04:39.879740 29785 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 09:04:51.505951 29785 solver.cpp:228] Iteration 6256, loss = 0.00388781
I0403 09:04:51.506052 29785 solver.cpp:244]     Train net output #0: loss = 0.00388811 (* 1 = 0.00388811 loss)
I0403 09:04:51.737598 29785 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 09:05:03.134804 29785 solver.cpp:228] Iteration 6272, loss = 0.00152144
I0403 09:05:03.135112 29785 solver.cpp:244]     Train net output #0: loss = 0.00152173 (* 1 = 0.00152173 loss)
I0403 09:05:03.338593 29785 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 09:05:14.872993 29785 solver.cpp:228] Iteration 6288, loss = 0.00369244
I0403 09:05:14.873095 29785 solver.cpp:244]     Train net output #0: loss = 0.00369274 (* 1 = 0.00369274 loss)
I0403 09:05:15.104928 29785 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 09:05:26.810505 29785 solver.cpp:228] Iteration 6304, loss = 0.0207644
I0403 09:05:26.810595 29785 solver.cpp:244]     Train net output #0: loss = 0.0207647 (* 1 = 0.0207647 loss)
I0403 09:05:26.969890 29785 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 09:05:38.388490 29785 solver.cpp:228] Iteration 6320, loss = 0.00400714
I0403 09:05:38.388782 29785 solver.cpp:244]     Train net output #0: loss = 0.00400744 (* 1 = 0.00400744 loss)
I0403 09:05:38.551188 29785 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 09:05:49.982341 29785 solver.cpp:228] Iteration 6336, loss = 0.00889454
I0403 09:05:49.982436 29785 solver.cpp:244]     Train net output #0: loss = 0.00889484 (* 1 = 0.00889484 loss)
I0403 09:05:50.160607 29785 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 09:06:01.630919 29785 solver.cpp:228] Iteration 6352, loss = 0.00753879
I0403 09:06:01.631021 29785 solver.cpp:244]     Train net output #0: loss = 0.00753909 (* 1 = 0.00753909 loss)
I0403 09:06:01.863015 29785 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 09:06:13.383765 29785 solver.cpp:228] Iteration 6368, loss = 0.0154582
I0403 09:06:13.384066 29785 solver.cpp:244]     Train net output #0: loss = 0.0154585 (* 1 = 0.0154585 loss)
I0403 09:06:13.578129 29785 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 09:06:24.914436 29785 solver.cpp:228] Iteration 6384, loss = 0.0026287
I0403 09:06:24.914532 29785 solver.cpp:244]     Train net output #0: loss = 0.002629 (* 1 = 0.002629 loss)
I0403 09:06:25.112026 29785 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 09:06:36.525107 29785 solver.cpp:228] Iteration 6400, loss = 0.0139803
I0403 09:06:36.525202 29785 solver.cpp:244]     Train net output #0: loss = 0.0139806 (* 1 = 0.0139806 loss)
I0403 09:06:36.718154 29785 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 09:06:48.311458 29785 solver.cpp:228] Iteration 6416, loss = 0.00429014
I0403 09:06:48.311760 29785 solver.cpp:244]     Train net output #0: loss = 0.00429043 (* 1 = 0.00429043 loss)
I0403 09:06:48.505143 29785 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 09:06:59.901057 29785 solver.cpp:228] Iteration 6432, loss = 0.00426996
I0403 09:06:59.901160 29785 solver.cpp:244]     Train net output #0: loss = 0.00427026 (* 1 = 0.00427026 loss)
I0403 09:07:00.103790 29785 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 09:07:11.476117 29785 solver.cpp:228] Iteration 6448, loss = 0.00133718
I0403 09:07:11.476217 29785 solver.cpp:244]     Train net output #0: loss = 0.00133748 (* 1 = 0.00133748 loss)
I0403 09:07:11.714671 29785 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 09:07:23.362778 29785 solver.cpp:228] Iteration 6464, loss = 0.0284365
I0403 09:07:23.363114 29785 solver.cpp:244]     Train net output #0: loss = 0.0284368 (* 1 = 0.0284368 loss)
I0403 09:07:23.546696 29785 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 09:07:34.962649 29785 solver.cpp:228] Iteration 6480, loss = 0.0331889
I0403 09:07:34.962749 29785 solver.cpp:244]     Train net output #0: loss = 0.0331892 (* 1 = 0.0331892 loss)
I0403 09:07:35.145010 29785 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 09:07:46.670786 29785 solver.cpp:228] Iteration 6496, loss = 0.0141644
I0403 09:07:46.670883 29785 solver.cpp:244]     Train net output #0: loss = 0.0141647 (* 1 = 0.0141647 loss)
I0403 09:07:46.858672 29785 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 09:07:49.023936 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6500.caffemodel
I0403 09:07:51.754750 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6500.solverstate
I0403 09:07:53.631398 29785 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 09:08:42.301836 29785 solver.cpp:404]     Test net output #0: accuracy = 0.97083
I0403 09:08:42.302181 29785 solver.cpp:404]     Test net output #1: loss = 0.117891 (* 1 = 0.117891 loss)
I0403 09:08:51.626045 29785 solver.cpp:228] Iteration 6512, loss = 0.00474896
I0403 09:08:51.626152 29785 solver.cpp:244]     Train net output #0: loss = 0.00474925 (* 1 = 0.00474925 loss)
I0403 09:08:51.869757 29785 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 09:09:03.319989 29785 solver.cpp:228] Iteration 6528, loss = 0.0119535
I0403 09:09:03.320088 29785 solver.cpp:244]     Train net output #0: loss = 0.0119538 (* 1 = 0.0119538 loss)
I0403 09:09:03.502236 29785 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 09:09:14.901973 29785 solver.cpp:228] Iteration 6544, loss = 0.0232996
I0403 09:09:14.902274 29785 solver.cpp:244]     Train net output #0: loss = 0.0232999 (* 1 = 0.0232999 loss)
I0403 09:09:15.092599 29785 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 09:09:26.817567 29785 solver.cpp:228] Iteration 6560, loss = 0.0172132
I0403 09:09:26.817667 29785 solver.cpp:244]     Train net output #0: loss = 0.0172135 (* 1 = 0.0172135 loss)
I0403 09:09:27.003772 29785 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 09:09:38.331149 29785 solver.cpp:228] Iteration 6576, loss = 0.0250143
I0403 09:09:38.331248 29785 solver.cpp:244]     Train net output #0: loss = 0.0250146 (* 1 = 0.0250146 loss)
I0403 09:09:38.518858 29785 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 09:09:49.905786 29785 solver.cpp:228] Iteration 6592, loss = 0.00139506
I0403 09:09:49.906085 29785 solver.cpp:244]     Train net output #0: loss = 0.00139537 (* 1 = 0.00139537 loss)
I0403 09:09:50.083376 29785 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 09:10:01.463172 29785 solver.cpp:228] Iteration 6608, loss = 0.0307123
I0403 09:10:01.463269 29785 solver.cpp:244]     Train net output #0: loss = 0.0307126 (* 1 = 0.0307126 loss)
I0403 09:10:01.650121 29785 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 09:10:13.185487 29785 solver.cpp:228] Iteration 6624, loss = 0.0206
I0403 09:10:13.185582 29785 solver.cpp:244]     Train net output #0: loss = 0.0206003 (* 1 = 0.0206003 loss)
I0403 09:10:13.392700 29785 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 09:10:24.813040 29785 solver.cpp:228] Iteration 6640, loss = 0.00883032
I0403 09:10:24.813356 29785 solver.cpp:244]     Train net output #0: loss = 0.00883064 (* 1 = 0.00883064 loss)
I0403 09:10:25.008327 29785 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 09:10:36.448179 29785 solver.cpp:228] Iteration 6656, loss = 0.00565992
I0403 09:10:36.448271 29785 solver.cpp:244]     Train net output #0: loss = 0.00566024 (* 1 = 0.00566024 loss)
I0403 09:10:36.659144 29785 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 09:10:48.142408 29785 solver.cpp:228] Iteration 6672, loss = 0.00423512
I0403 09:10:48.142508 29785 solver.cpp:244]     Train net output #0: loss = 0.00423543 (* 1 = 0.00423543 loss)
I0403 09:10:48.324443 29785 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 09:10:59.786299 29785 solver.cpp:228] Iteration 6688, loss = 0.0118775
I0403 09:10:59.786602 29785 solver.cpp:244]     Train net output #0: loss = 0.0118778 (* 1 = 0.0118778 loss)
I0403 09:10:59.976491 29785 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 09:11:11.312923 29785 solver.cpp:228] Iteration 6704, loss = 0.0102018
I0403 09:11:11.313026 29785 solver.cpp:244]     Train net output #0: loss = 0.0102021 (* 1 = 0.0102021 loss)
I0403 09:11:11.544939 29785 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 09:11:23.059059 29785 solver.cpp:228] Iteration 6720, loss = 0.00763985
I0403 09:11:23.059149 29785 solver.cpp:244]     Train net output #0: loss = 0.00764016 (* 1 = 0.00764016 loss)
I0403 09:11:23.236973 29785 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 09:11:34.716439 29785 solver.cpp:228] Iteration 6736, loss = 0.0150346
I0403 09:11:34.716722 29785 solver.cpp:244]     Train net output #0: loss = 0.0150349 (* 1 = 0.0150349 loss)
I0403 09:11:34.920286 29785 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 09:11:46.584019 29785 solver.cpp:228] Iteration 6752, loss = 0.00600823
I0403 09:11:46.584115 29785 solver.cpp:244]     Train net output #0: loss = 0.00600854 (* 1 = 0.00600854 loss)
I0403 09:11:46.752673 29785 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 09:11:58.221863 29785 solver.cpp:228] Iteration 6768, loss = 0.00344579
I0403 09:11:58.221951 29785 solver.cpp:244]     Train net output #0: loss = 0.00344611 (* 1 = 0.00344611 loss)
I0403 09:11:58.365056 29785 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 09:12:10.054309 29785 solver.cpp:228] Iteration 6784, loss = 0.00381425
I0403 09:12:10.054608 29785 solver.cpp:244]     Train net output #0: loss = 0.00381456 (* 1 = 0.00381456 loss)
I0403 09:12:10.257074 29785 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 09:12:21.805480 29785 solver.cpp:228] Iteration 6800, loss = 0.00283381
I0403 09:12:21.805575 29785 solver.cpp:244]     Train net output #0: loss = 0.00283412 (* 1 = 0.00283412 loss)
I0403 09:12:21.989156 29785 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 09:12:33.453263 29785 solver.cpp:228] Iteration 6816, loss = 0.0125748
I0403 09:12:33.453357 29785 solver.cpp:244]     Train net output #0: loss = 0.0125751 (* 1 = 0.0125751 loss)
I0403 09:12:33.655282 29785 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 09:12:39.604171 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6825.caffemodel
I0403 09:12:42.377611 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_6825.solverstate
I0403 09:12:44.203784 29785 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 09:13:32.899473 29785 solver.cpp:404]     Test net output #0: accuracy = 0.97189
I0403 09:13:32.899760 29785 solver.cpp:404]     Test net output #1: loss = 0.115029 (* 1 = 0.115029 loss)
I0403 09:13:38.424475 29785 solver.cpp:228] Iteration 6832, loss = 0.00494813
I0403 09:13:38.424571 29785 solver.cpp:244]     Train net output #0: loss = 0.00494844 (* 1 = 0.00494844 loss)
I0403 09:13:38.639312 29785 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 09:13:50.035011 29785 solver.cpp:228] Iteration 6848, loss = 0.0136483
I0403 09:13:50.035112 29785 solver.cpp:244]     Train net output #0: loss = 0.0136486 (* 1 = 0.0136486 loss)
I0403 09:13:50.217633 29785 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 09:14:01.733535 29785 solver.cpp:228] Iteration 6864, loss = 0.0124338
I0403 09:14:01.733630 29785 solver.cpp:244]     Train net output #0: loss = 0.0124341 (* 1 = 0.0124341 loss)
I0403 09:14:01.936647 29785 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 09:14:13.329156 29785 solver.cpp:228] Iteration 6880, loss = 0.022978
I0403 09:14:13.329494 29785 solver.cpp:244]     Train net output #0: loss = 0.0229783 (* 1 = 0.0229783 loss)
I0403 09:14:13.519294 29785 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 09:14:24.865761 29785 solver.cpp:228] Iteration 6896, loss = 0.00230735
I0403 09:14:24.865857 29785 solver.cpp:244]     Train net output #0: loss = 0.00230766 (* 1 = 0.00230766 loss)
I0403 09:14:25.068228 29785 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 09:14:36.399067 29785 solver.cpp:228] Iteration 6912, loss = 0.00132285
I0403 09:14:36.399169 29785 solver.cpp:244]     Train net output #0: loss = 0.00132316 (* 1 = 0.00132316 loss)
I0403 09:14:36.581423 29785 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 09:14:48.094264 29785 solver.cpp:228] Iteration 6928, loss = 0.014247
I0403 09:14:48.094573 29785 solver.cpp:244]     Train net output #0: loss = 0.0142473 (* 1 = 0.0142473 loss)
I0403 09:14:48.339575 29785 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 09:14:59.685137 29785 solver.cpp:228] Iteration 6944, loss = 0.0143401
I0403 09:14:59.685233 29785 solver.cpp:244]     Train net output #0: loss = 0.0143404 (* 1 = 0.0143404 loss)
I0403 09:14:59.878239 29785 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 09:15:11.506780 29785 solver.cpp:228] Iteration 6960, loss = 0.0105335
I0403 09:15:11.506876 29785 solver.cpp:244]     Train net output #0: loss = 0.0105338 (* 1 = 0.0105338 loss)
I0403 09:15:11.706327 29785 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 09:15:23.179513 29785 solver.cpp:228] Iteration 6976, loss = 0.00325619
I0403 09:15:23.179759 29785 solver.cpp:244]     Train net output #0: loss = 0.00325651 (* 1 = 0.00325651 loss)
I0403 09:15:23.333830 29785 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 09:15:34.785240 29785 solver.cpp:228] Iteration 6992, loss = 0.00156471
I0403 09:15:34.785337 29785 solver.cpp:244]     Train net output #0: loss = 0.00156503 (* 1 = 0.00156503 loss)
I0403 09:15:34.974141 29785 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 09:15:46.614439 29785 solver.cpp:228] Iteration 7008, loss = 0.00172151
I0403 09:15:46.614533 29785 solver.cpp:244]     Train net output #0: loss = 0.00172182 (* 1 = 0.00172182 loss)
I0403 09:15:46.802590 29785 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 09:15:58.281702 29785 solver.cpp:228] Iteration 7024, loss = 0.0110833
I0403 09:15:58.281998 29785 solver.cpp:244]     Train net output #0: loss = 0.0110836 (* 1 = 0.0110836 loss)
I0403 09:15:58.501459 29785 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 09:16:09.957051 29785 solver.cpp:228] Iteration 7040, loss = 0.00197433
I0403 09:16:09.957150 29785 solver.cpp:244]     Train net output #0: loss = 0.00197464 (* 1 = 0.00197464 loss)
I0403 09:16:10.105656 29785 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 09:16:21.637734 29785 solver.cpp:228] Iteration 7056, loss = 0.0208158
I0403 09:16:21.637831 29785 solver.cpp:244]     Train net output #0: loss = 0.0208161 (* 1 = 0.0208161 loss)
I0403 09:16:21.832728 29785 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 09:16:33.217399 29785 solver.cpp:228] Iteration 7072, loss = 0.0065317
I0403 09:16:33.217705 29785 solver.cpp:244]     Train net output #0: loss = 0.00653202 (* 1 = 0.00653202 loss)
I0403 09:16:33.405361 29785 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 09:16:44.734565 29785 solver.cpp:228] Iteration 7088, loss = 0.00246718
I0403 09:16:44.734673 29785 solver.cpp:244]     Train net output #0: loss = 0.00246749 (* 1 = 0.00246749 loss)
I0403 09:16:44.935353 29785 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 09:16:56.517583 29785 solver.cpp:228] Iteration 7104, loss = 0.00311047
I0403 09:16:56.517668 29785 solver.cpp:244]     Train net output #0: loss = 0.00311079 (* 1 = 0.00311079 loss)
I0403 09:16:56.654325 29785 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 09:17:08.316936 29785 solver.cpp:228] Iteration 7120, loss = 0.00329056
I0403 09:17:08.317271 29785 solver.cpp:244]     Train net output #0: loss = 0.00329087 (* 1 = 0.00329087 loss)
I0403 09:17:08.523562 29785 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 09:17:19.948680 29785 solver.cpp:228] Iteration 7136, loss = 0.00284201
I0403 09:17:19.948770 29785 solver.cpp:244]     Train net output #0: loss = 0.00284232 (* 1 = 0.00284232 loss)
I0403 09:17:20.115556 29785 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 09:17:29.523622 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7150.caffemodel
I0403 09:17:32.301144 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7150.solverstate
I0403 09:17:34.191193 29785 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 09:18:22.868098 29785 solver.cpp:404]     Test net output #0: accuracy = 0.971705
I0403 09:18:22.868386 29785 solver.cpp:404]     Test net output #1: loss = 0.116351 (* 1 = 0.116351 loss)
I0403 09:18:24.837450 29785 solver.cpp:228] Iteration 7152, loss = 0.0184731
I0403 09:18:24.837538 29785 solver.cpp:244]     Train net output #0: loss = 0.0184734 (* 1 = 0.0184734 loss)
I0403 09:18:25.033625 29785 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 09:18:36.611745 29785 solver.cpp:228] Iteration 7168, loss = 0.000878621
I0403 09:18:36.611842 29785 solver.cpp:244]     Train net output #0: loss = 0.00087893 (* 1 = 0.00087893 loss)
I0403 09:18:36.795491 29785 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 09:18:48.191609 29785 solver.cpp:228] Iteration 7184, loss = 0.0126798
I0403 09:18:48.191706 29785 solver.cpp:244]     Train net output #0: loss = 0.0126802 (* 1 = 0.0126802 loss)
I0403 09:18:48.395011 29785 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 09:18:59.912978 29785 solver.cpp:228] Iteration 7200, loss = 0.00503414
I0403 09:18:59.913292 29785 solver.cpp:244]     Train net output #0: loss = 0.00503445 (* 1 = 0.00503445 loss)
I0403 09:19:00.125164 29785 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 09:19:11.539952 29785 solver.cpp:228] Iteration 7216, loss = 0.0168839
I0403 09:19:11.540079 29785 solver.cpp:244]     Train net output #0: loss = 0.0168842 (* 1 = 0.0168842 loss)
I0403 09:19:11.764783 29785 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 09:19:23.363603 29785 solver.cpp:228] Iteration 7232, loss = 0.00780514
I0403 09:19:23.363701 29785 solver.cpp:244]     Train net output #0: loss = 0.00780544 (* 1 = 0.00780544 loss)
I0403 09:19:23.550529 29785 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 09:19:34.874418 29785 solver.cpp:228] Iteration 7248, loss = 0.00651343
I0403 09:19:34.874704 29785 solver.cpp:244]     Train net output #0: loss = 0.00651374 (* 1 = 0.00651374 loss)
I0403 09:19:35.056517 29785 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 09:19:46.485829 29785 solver.cpp:228] Iteration 7264, loss = 0.0157322
I0403 09:19:46.485924 29785 solver.cpp:244]     Train net output #0: loss = 0.0157325 (* 1 = 0.0157325 loss)
I0403 09:19:46.667763 29785 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 09:19:58.060106 29785 solver.cpp:228] Iteration 7280, loss = 0.00847088
I0403 09:19:58.060194 29785 solver.cpp:244]     Train net output #0: loss = 0.00847119 (* 1 = 0.00847119 loss)
I0403 09:19:58.236513 29785 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 09:20:09.815192 29785 solver.cpp:228] Iteration 7296, loss = 0.00242251
I0403 09:20:09.815533 29785 solver.cpp:244]     Train net output #0: loss = 0.00242282 (* 1 = 0.00242282 loss)
I0403 09:20:10.041551 29785 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 09:20:21.404975 29785 solver.cpp:228] Iteration 7312, loss = 0.0183693
I0403 09:20:21.405073 29785 solver.cpp:244]     Train net output #0: loss = 0.0183696 (* 1 = 0.0183696 loss)
I0403 09:20:21.586747 29785 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 09:20:32.992400 29785 solver.cpp:228] Iteration 7328, loss = 0.0124206
I0403 09:20:32.992508 29785 solver.cpp:244]     Train net output #0: loss = 0.0124209 (* 1 = 0.0124209 loss)
I0403 09:20:33.195782 29785 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 09:20:44.575809 29785 solver.cpp:228] Iteration 7344, loss = 0.0277723
I0403 09:20:44.576145 29785 solver.cpp:244]     Train net output #0: loss = 0.0277726 (* 1 = 0.0277726 loss)
I0403 09:20:44.767215 29785 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 09:20:56.185596 29785 solver.cpp:228] Iteration 7360, loss = 0.000850639
I0403 09:20:56.185691 29785 solver.cpp:244]     Train net output #0: loss = 0.000850952 (* 1 = 0.000850952 loss)
I0403 09:20:56.388690 29785 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 09:21:07.730203 29785 solver.cpp:228] Iteration 7376, loss = 0.0116084
I0403 09:21:07.730304 29785 solver.cpp:244]     Train net output #0: loss = 0.0116087 (* 1 = 0.0116087 loss)
I0403 09:21:07.914695 29785 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 09:21:19.396175 29785 solver.cpp:228] Iteration 7392, loss = 0.00587122
I0403 09:21:19.396441 29785 solver.cpp:244]     Train net output #0: loss = 0.00587154 (* 1 = 0.00587154 loss)
I0403 09:21:19.560147 29785 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 09:21:31.081099 29785 solver.cpp:228] Iteration 7408, loss = 0.0155023
I0403 09:21:31.081198 29785 solver.cpp:244]     Train net output #0: loss = 0.0155027 (* 1 = 0.0155027 loss)
I0403 09:21:31.320710 29785 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 09:21:42.650775 29785 solver.cpp:228] Iteration 7424, loss = 0.00567326
I0403 09:21:42.650874 29785 solver.cpp:244]     Train net output #0: loss = 0.00567357 (* 1 = 0.00567357 loss)
I0403 09:21:42.836323 29785 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 09:21:54.425933 29785 solver.cpp:228] Iteration 7440, loss = 0.0276235
I0403 09:21:54.426225 29785 solver.cpp:244]     Train net output #0: loss = 0.0276239 (* 1 = 0.0276239 loss)
I0403 09:21:54.597879 29785 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 09:22:06.054374 29785 solver.cpp:228] Iteration 7456, loss = 0.00348498
I0403 09:22:06.054472 29785 solver.cpp:244]     Train net output #0: loss = 0.00348529 (* 1 = 0.00348529 loss)
I0403 09:22:06.254407 29785 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 09:22:17.639866 29785 solver.cpp:228] Iteration 7472, loss = 0.00541998
I0403 09:22:17.639952 29785 solver.cpp:244]     Train net output #0: loss = 0.00542029 (* 1 = 0.00542029 loss)
I0403 09:22:17.815351 29785 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 09:22:19.273295 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7475.caffemodel
I0403 09:22:21.960381 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7475.solverstate
I0403 09:22:23.815752 29785 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 09:23:12.507457 29785 solver.cpp:404]     Test net output #0: accuracy = 0.971752
I0403 09:23:12.507757 29785 solver.cpp:404]     Test net output #1: loss = 0.11594 (* 1 = 0.11594 loss)
I0403 09:23:22.617990 29785 solver.cpp:228] Iteration 7488, loss = 0.00908341
I0403 09:23:22.618088 29785 solver.cpp:244]     Train net output #0: loss = 0.00908372 (* 1 = 0.00908372 loss)
I0403 09:23:22.803570 29785 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 09:23:34.197439 29785 solver.cpp:228] Iteration 7504, loss = 0.00449142
I0403 09:23:34.197537 29785 solver.cpp:244]     Train net output #0: loss = 0.00449173 (* 1 = 0.00449173 loss)
I0403 09:23:34.395653 29785 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 09:23:45.797405 29785 solver.cpp:228] Iteration 7520, loss = 0.00602217
I0403 09:23:45.797730 29785 solver.cpp:244]     Train net output #0: loss = 0.00602247 (* 1 = 0.00602247 loss)
I0403 09:23:45.994815 29785 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 09:23:57.462924 29785 solver.cpp:228] Iteration 7536, loss = 0.0349666
I0403 09:23:57.463021 29785 solver.cpp:244]     Train net output #0: loss = 0.0349669 (* 1 = 0.0349669 loss)
I0403 09:23:57.655843 29785 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 09:24:09.032232 29785 solver.cpp:228] Iteration 7552, loss = 0.0113221
I0403 09:24:09.032330 29785 solver.cpp:244]     Train net output #0: loss = 0.0113224 (* 1 = 0.0113224 loss)
I0403 09:24:09.216168 29785 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 09:24:20.684058 29785 solver.cpp:228] Iteration 7568, loss = 0.0022192
I0403 09:24:20.684381 29785 solver.cpp:244]     Train net output #0: loss = 0.0022195 (* 1 = 0.0022195 loss)
I0403 09:24:20.909596 29785 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 09:24:32.320583 29785 solver.cpp:228] Iteration 7584, loss = 0.00400852
I0403 09:24:32.320677 29785 solver.cpp:244]     Train net output #0: loss = 0.00400882 (* 1 = 0.00400882 loss)
I0403 09:24:32.502832 29785 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 09:24:43.942739 29785 solver.cpp:228] Iteration 7600, loss = 0.00280443
I0403 09:24:43.942826 29785 solver.cpp:244]     Train net output #0: loss = 0.00280473 (* 1 = 0.00280473 loss)
I0403 09:24:44.096038 29785 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 09:24:55.693742 29785 solver.cpp:228] Iteration 7616, loss = 0.00230818
I0403 09:24:55.694046 29785 solver.cpp:244]     Train net output #0: loss = 0.00230849 (* 1 = 0.00230849 loss)
I0403 09:24:55.876622 29785 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 09:25:07.185461 29785 solver.cpp:228] Iteration 7632, loss = 0.00198843
I0403 09:25:07.185556 29785 solver.cpp:244]     Train net output #0: loss = 0.00198873 (* 1 = 0.00198873 loss)
I0403 09:25:07.392709 29785 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 09:25:18.787406 29785 solver.cpp:228] Iteration 7648, loss = 0.00349321
I0403 09:25:18.787494 29785 solver.cpp:244]     Train net output #0: loss = 0.00349352 (* 1 = 0.00349352 loss)
I0403 09:25:18.934231 29785 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 09:25:30.672904 29785 solver.cpp:228] Iteration 7664, loss = 0.0141096
I0403 09:25:30.673202 29785 solver.cpp:244]     Train net output #0: loss = 0.0141099 (* 1 = 0.0141099 loss)
I0403 09:25:30.881253 29785 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 09:25:42.265581 29785 solver.cpp:228] Iteration 7680, loss = 0.00330452
I0403 09:25:42.265677 29785 solver.cpp:244]     Train net output #0: loss = 0.00330483 (* 1 = 0.00330483 loss)
I0403 09:25:42.471078 29785 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 09:25:53.868281 29785 solver.cpp:228] Iteration 7696, loss = 0.0348978
I0403 09:25:53.868376 29785 solver.cpp:244]     Train net output #0: loss = 0.0348982 (* 1 = 0.0348982 loss)
I0403 09:25:54.057438 29785 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 09:26:05.782754 29785 solver.cpp:228] Iteration 7712, loss = 0.00402572
I0403 09:26:05.783030 29785 solver.cpp:244]     Train net output #0: loss = 0.00402602 (* 1 = 0.00402602 loss)
I0403 09:26:05.980693 29785 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 09:26:17.473287 29785 solver.cpp:228] Iteration 7728, loss = 0.0154824
I0403 09:26:17.473373 29785 solver.cpp:244]     Train net output #0: loss = 0.0154827 (* 1 = 0.0154827 loss)
I0403 09:26:17.639648 29785 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 09:26:29.171365 29785 solver.cpp:228] Iteration 7744, loss = 0.0176515
I0403 09:26:29.171460 29785 solver.cpp:244]     Train net output #0: loss = 0.0176518 (* 1 = 0.0176518 loss)
I0403 09:26:29.368221 29785 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 09:26:40.905388 29785 solver.cpp:228] Iteration 7760, loss = 0.00214217
I0403 09:26:40.905725 29785 solver.cpp:244]     Train net output #0: loss = 0.00214248 (* 1 = 0.00214248 loss)
I0403 09:26:41.112694 29785 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 09:26:52.475821 29785 solver.cpp:228] Iteration 7776, loss = 0.010071
I0403 09:26:52.475917 29785 solver.cpp:244]     Train net output #0: loss = 0.0100713 (* 1 = 0.0100713 loss)
I0403 09:26:52.663280 29785 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 09:27:04.309033 29785 solver.cpp:228] Iteration 7792, loss = 0.00652213
I0403 09:27:04.309125 29785 solver.cpp:244]     Train net output #0: loss = 0.00652243 (* 1 = 0.00652243 loss)
I0403 09:27:04.478205 29785 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 09:27:09.594929 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7800.caffemodel
I0403 09:27:12.364279 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_7800.solverstate
I0403 09:27:14.252514 29785 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 09:28:02.917538 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972028
I0403 09:28:02.917824 29785 solver.cpp:404]     Test net output #1: loss = 0.115033 (* 1 = 0.115033 loss)
I0403 09:28:09.245932 29785 solver.cpp:228] Iteration 7808, loss = 0.0204828
I0403 09:28:09.246022 29785 solver.cpp:244]     Train net output #0: loss = 0.0204831 (* 1 = 0.0204831 loss)
I0403 09:28:09.395767 29785 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 09:28:21.095419 29785 solver.cpp:228] Iteration 7824, loss = 0.00925414
I0403 09:28:21.095518 29785 solver.cpp:244]     Train net output #0: loss = 0.00925445 (* 1 = 0.00925445 loss)
I0403 09:28:21.300204 29785 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 09:28:32.821704 29785 solver.cpp:228] Iteration 7840, loss = 0.00269776
I0403 09:28:32.821801 29785 solver.cpp:244]     Train net output #0: loss = 0.00269806 (* 1 = 0.00269806 loss)
I0403 09:28:33.025890 29785 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 09:28:44.553678 29785 solver.cpp:228] Iteration 7856, loss = 0.019452
I0403 09:28:44.553776 29785 solver.cpp:244]     Train net output #0: loss = 0.0194523 (* 1 = 0.0194523 loss)
I0403 09:28:44.735860 29785 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 09:28:56.130045 29785 solver.cpp:228] Iteration 7872, loss = 0.00779395
I0403 09:28:56.130136 29785 solver.cpp:244]     Train net output #0: loss = 0.00779425 (* 1 = 0.00779425 loss)
I0403 09:28:56.297410 29785 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 09:29:07.762881 29785 solver.cpp:228] Iteration 7888, loss = 0.00434705
I0403 09:29:07.763162 29785 solver.cpp:244]     Train net output #0: loss = 0.00434736 (* 1 = 0.00434736 loss)
I0403 09:29:07.972635 29785 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 09:29:19.583601 29785 solver.cpp:228] Iteration 7904, loss = 0.00916619
I0403 09:29:19.583700 29785 solver.cpp:244]     Train net output #0: loss = 0.0091665 (* 1 = 0.0091665 loss)
I0403 09:29:19.778470 29785 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 09:29:31.319178 29785 solver.cpp:228] Iteration 7920, loss = 0.026681
I0403 09:29:31.319274 29785 solver.cpp:244]     Train net output #0: loss = 0.0266813 (* 1 = 0.0266813 loss)
I0403 09:29:31.536206 29785 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 09:29:43.071025 29785 solver.cpp:228] Iteration 7936, loss = 0.00651017
I0403 09:29:43.071326 29785 solver.cpp:244]     Train net output #0: loss = 0.00651048 (* 1 = 0.00651048 loss)
I0403 09:29:43.270395 29785 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 09:29:54.613313 29785 solver.cpp:228] Iteration 7952, loss = 0.0136823
I0403 09:29:54.613415 29785 solver.cpp:244]     Train net output #0: loss = 0.0136826 (* 1 = 0.0136826 loss)
I0403 09:29:54.889652 29785 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 09:30:06.302284 29785 solver.cpp:228] Iteration 7968, loss = 0.00301557
I0403 09:30:06.302379 29785 solver.cpp:244]     Train net output #0: loss = 0.00301587 (* 1 = 0.00301587 loss)
I0403 09:30:06.501687 29785 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 09:30:17.968685 29785 solver.cpp:228] Iteration 7984, loss = 0.00476806
I0403 09:30:17.969007 29785 solver.cpp:244]     Train net output #0: loss = 0.00476837 (* 1 = 0.00476837 loss)
I0403 09:30:18.143013 29785 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 09:30:29.751935 29785 solver.cpp:228] Iteration 8000, loss = 0.00675015
I0403 09:30:29.752029 29785 solver.cpp:244]     Train net output #0: loss = 0.00675046 (* 1 = 0.00675046 loss)
I0403 09:30:29.952340 29785 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 09:30:41.337402 29785 solver.cpp:228] Iteration 8016, loss = 0.00255395
I0403 09:30:41.337502 29785 solver.cpp:244]     Train net output #0: loss = 0.00255426 (* 1 = 0.00255426 loss)
I0403 09:30:41.540776 29785 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 09:30:52.862313 29785 solver.cpp:228] Iteration 8032, loss = 0.00153886
I0403 09:30:52.862639 29785 solver.cpp:244]     Train net output #0: loss = 0.00153916 (* 1 = 0.00153916 loss)
I0403 09:30:53.068320 29785 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 09:31:04.495959 29785 solver.cpp:228] Iteration 8048, loss = 0.00512449
I0403 09:31:04.496052 29785 solver.cpp:244]     Train net output #0: loss = 0.00512479 (* 1 = 0.00512479 loss)
I0403 09:31:04.677634 29785 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 09:31:16.064478 29785 solver.cpp:228] Iteration 8064, loss = 0.0313226
I0403 09:31:16.064575 29785 solver.cpp:244]     Train net output #0: loss = 0.0313229 (* 1 = 0.0313229 loss)
I0403 09:31:16.259897 29785 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 09:31:27.774392 29785 solver.cpp:228] Iteration 8080, loss = 0.016243
I0403 09:31:27.774693 29785 solver.cpp:244]     Train net output #0: loss = 0.0162433 (* 1 = 0.0162433 loss)
I0403 09:31:27.973721 29785 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 09:31:39.802767 29785 solver.cpp:228] Iteration 8096, loss = 0.00451859
I0403 09:31:39.802866 29785 solver.cpp:244]     Train net output #0: loss = 0.0045189 (* 1 = 0.0045189 loss)
I0403 09:31:40.004308 29785 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 09:31:51.376889 29785 solver.cpp:228] Iteration 8112, loss = 0.0441887
I0403 09:31:51.376988 29785 solver.cpp:244]     Train net output #0: loss = 0.044189 (* 1 = 0.044189 loss)
I0403 09:31:51.598855 29785 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 09:32:00.258625 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8125.caffemodel
I0403 09:32:03.014016 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8125.solverstate
I0403 09:32:04.891304 29785 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 09:32:53.567392 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972121
I0403 09:32:53.567701 29785 solver.cpp:404]     Test net output #1: loss = 0.115223 (* 1 = 0.115223 loss)
I0403 09:32:56.352213 29785 solver.cpp:228] Iteration 8128, loss = 0.012336
I0403 09:32:56.352309 29785 solver.cpp:244]     Train net output #0: loss = 0.0123363 (* 1 = 0.0123363 loss)
I0403 09:32:56.536555 29785 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 09:33:07.920697 29785 solver.cpp:228] Iteration 8144, loss = 0.00820292
I0403 09:33:07.920794 29785 solver.cpp:244]     Train net output #0: loss = 0.00820322 (* 1 = 0.00820322 loss)
I0403 09:33:08.119622 29785 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 09:33:19.642313 29785 solver.cpp:228] Iteration 8160, loss = 0.00498709
I0403 09:33:19.642400 29785 solver.cpp:244]     Train net output #0: loss = 0.00498739 (* 1 = 0.00498739 loss)
I0403 09:33:19.819083 29785 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 09:33:31.397377 29785 solver.cpp:228] Iteration 8176, loss = 0.0172693
I0403 09:33:31.397692 29785 solver.cpp:244]     Train net output #0: loss = 0.0172696 (* 1 = 0.0172696 loss)
I0403 09:33:31.548224 29785 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 09:33:43.160187 29785 solver.cpp:228] Iteration 8192, loss = 0.00996879
I0403 09:33:43.160280 29785 solver.cpp:244]     Train net output #0: loss = 0.00996909 (* 1 = 0.00996909 loss)
I0403 09:33:43.359669 29785 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 09:33:54.952296 29785 solver.cpp:228] Iteration 8208, loss = 0.00691974
I0403 09:33:54.952394 29785 solver.cpp:244]     Train net output #0: loss = 0.00692004 (* 1 = 0.00692004 loss)
I0403 09:33:55.146013 29785 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 09:34:06.547987 29785 solver.cpp:228] Iteration 8224, loss = 0.00312719
I0403 09:34:06.548279 29785 solver.cpp:244]     Train net output #0: loss = 0.00312749 (* 1 = 0.00312749 loss)
I0403 09:34:06.723772 29785 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 09:34:18.325454 29785 solver.cpp:228] Iteration 8240, loss = 0.0241163
I0403 09:34:18.325551 29785 solver.cpp:244]     Train net output #0: loss = 0.0241166 (* 1 = 0.0241166 loss)
I0403 09:34:18.514299 29785 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 09:34:29.998561 29785 solver.cpp:228] Iteration 8256, loss = 0.0242952
I0403 09:34:29.998647 29785 solver.cpp:244]     Train net output #0: loss = 0.0242955 (* 1 = 0.0242955 loss)
I0403 09:34:30.110256 29785 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 09:34:41.784407 29785 solver.cpp:228] Iteration 8272, loss = 0.00117326
I0403 09:34:41.784646 29785 solver.cpp:244]     Train net output #0: loss = 0.00117356 (* 1 = 0.00117356 loss)
I0403 09:34:41.980049 29785 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 09:34:53.442769 29785 solver.cpp:228] Iteration 8288, loss = 0.00419129
I0403 09:34:53.442865 29785 solver.cpp:244]     Train net output #0: loss = 0.00419159 (* 1 = 0.00419159 loss)
I0403 09:34:53.645339 29785 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 09:35:05.114223 29785 solver.cpp:228] Iteration 8304, loss = 0.00554642
I0403 09:35:05.114320 29785 solver.cpp:244]     Train net output #0: loss = 0.00554672 (* 1 = 0.00554672 loss)
I0403 09:35:05.345896 29785 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 09:35:16.755028 29785 solver.cpp:228] Iteration 8320, loss = 0.00324837
I0403 09:35:16.755308 29785 solver.cpp:244]     Train net output #0: loss = 0.00324868 (* 1 = 0.00324868 loss)
I0403 09:35:16.943672 29785 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 09:35:28.365509 29785 solver.cpp:228] Iteration 8336, loss = 0.00252811
I0403 09:35:28.365605 29785 solver.cpp:244]     Train net output #0: loss = 0.00252842 (* 1 = 0.00252842 loss)
I0403 09:35:28.554458 29785 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 09:35:39.847209 29785 solver.cpp:228] Iteration 8352, loss = 0.0106528
I0403 09:35:39.847308 29785 solver.cpp:244]     Train net output #0: loss = 0.0106531 (* 1 = 0.0106531 loss)
I0403 09:35:40.033280 29785 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 09:35:51.595026 29785 solver.cpp:228] Iteration 8368, loss = 0.00340368
I0403 09:35:51.595335 29785 solver.cpp:244]     Train net output #0: loss = 0.00340399 (* 1 = 0.00340399 loss)
I0403 09:35:51.793896 29785 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 09:36:03.355556 29785 solver.cpp:228] Iteration 8384, loss = 0.0203682
I0403 09:36:03.355654 29785 solver.cpp:244]     Train net output #0: loss = 0.0203685 (* 1 = 0.0203685 loss)
I0403 09:36:03.538075 29785 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 09:36:15.263584 29785 solver.cpp:228] Iteration 8400, loss = 0.00257589
I0403 09:36:15.263684 29785 solver.cpp:244]     Train net output #0: loss = 0.0025762 (* 1 = 0.0025762 loss)
I0403 09:36:15.463326 29785 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 09:36:26.815644 29785 solver.cpp:228] Iteration 8416, loss = 0.00153433
I0403 09:36:26.815944 29785 solver.cpp:244]     Train net output #0: loss = 0.00153463 (* 1 = 0.00153463 loss)
I0403 09:36:27.047955 29785 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 09:36:38.443389 29785 solver.cpp:228] Iteration 8432, loss = 0.0105068
I0403 09:36:38.443475 29785 solver.cpp:244]     Train net output #0: loss = 0.0105071 (* 1 = 0.0105071 loss)
I0403 09:36:38.598496 29785 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 09:36:50.040241 29785 solver.cpp:228] Iteration 8448, loss = 0.0164681
I0403 09:36:50.040343 29785 solver.cpp:244]     Train net output #0: loss = 0.0164684 (* 1 = 0.0164684 loss)
I0403 09:36:50.244161 29785 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 09:36:50.961272 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8450.caffemodel
I0403 09:36:53.814355 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8450.solverstate
I0403 09:36:55.703255 29785 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 09:37:44.384635 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972397
I0403 09:37:44.385010 29785 solver.cpp:404]     Test net output #1: loss = 0.114761 (* 1 = 0.114761 loss)
I0403 09:37:55.069836 29785 solver.cpp:228] Iteration 8464, loss = 0.00918475
I0403 09:37:55.069932 29785 solver.cpp:244]     Train net output #0: loss = 0.00918506 (* 1 = 0.00918506 loss)
I0403 09:37:55.254914 29785 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 09:38:06.688395 29785 solver.cpp:228] Iteration 8480, loss = 0.00430357
I0403 09:38:06.688505 29785 solver.cpp:244]     Train net output #0: loss = 0.00430387 (* 1 = 0.00430387 loss)
I0403 09:38:06.891492 29785 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 09:38:18.224465 29785 solver.cpp:228] Iteration 8496, loss = 0.00682645
I0403 09:38:18.224761 29785 solver.cpp:244]     Train net output #0: loss = 0.00682676 (* 1 = 0.00682676 loss)
I0403 09:38:18.414810 29785 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 09:38:29.839076 29785 solver.cpp:228] Iteration 8512, loss = 0.0148359
I0403 09:38:29.839176 29785 solver.cpp:244]     Train net output #0: loss = 0.0148362 (* 1 = 0.0148362 loss)
I0403 09:38:30.028898 29785 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 09:38:41.503726 29785 solver.cpp:228] Iteration 8528, loss = 0.0157736
I0403 09:38:41.503811 29785 solver.cpp:244]     Train net output #0: loss = 0.0157739 (* 1 = 0.0157739 loss)
I0403 09:38:41.682039 29785 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 09:38:53.152374 29785 solver.cpp:228] Iteration 8544, loss = 0.000644874
I0403 09:38:53.153066 29785 solver.cpp:244]     Train net output #0: loss = 0.000645179 (* 1 = 0.000645179 loss)
I0403 09:38:53.381007 29785 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 09:39:04.758958 29785 solver.cpp:228] Iteration 8560, loss = 0.00144778
I0403 09:39:04.759055 29785 solver.cpp:244]     Train net output #0: loss = 0.00144809 (* 1 = 0.00144809 loss)
I0403 09:39:04.957455 29785 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 09:39:16.315747 29785 solver.cpp:228] Iteration 8576, loss = 0.0186409
I0403 09:39:16.315843 29785 solver.cpp:244]     Train net output #0: loss = 0.0186412 (* 1 = 0.0186412 loss)
I0403 09:39:16.500361 29785 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 09:39:28.152751 29785 solver.cpp:228] Iteration 8592, loss = 0.00716643
I0403 09:39:28.153054 29785 solver.cpp:244]     Train net output #0: loss = 0.00716673 (* 1 = 0.00716673 loss)
I0403 09:39:28.400140 29785 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 09:39:39.820250 29785 solver.cpp:228] Iteration 8608, loss = 0.00385993
I0403 09:39:39.820348 29785 solver.cpp:244]     Train net output #0: loss = 0.00386023 (* 1 = 0.00386023 loss)
I0403 09:39:40.002761 29785 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 09:39:51.465821 29785 solver.cpp:228] Iteration 8624, loss = 0.0018585
I0403 09:39:51.465919 29785 solver.cpp:244]     Train net output #0: loss = 0.0018588 (* 1 = 0.0018588 loss)
I0403 09:39:51.664548 29785 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 09:40:03.200608 29785 solver.cpp:228] Iteration 8640, loss = 0.0127018
I0403 09:40:03.200944 29785 solver.cpp:244]     Train net output #0: loss = 0.0127021 (* 1 = 0.0127021 loss)
I0403 09:40:03.389333 29785 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 09:40:14.920718 29785 solver.cpp:228] Iteration 8656, loss = 0.00234879
I0403 09:40:14.920814 29785 solver.cpp:244]     Train net output #0: loss = 0.00234909 (* 1 = 0.00234909 loss)
I0403 09:40:15.103461 29785 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 09:40:26.534447 29785 solver.cpp:228] Iteration 8672, loss = 0.00332629
I0403 09:40:26.534541 29785 solver.cpp:244]     Train net output #0: loss = 0.0033266 (* 1 = 0.0033266 loss)
I0403 09:40:26.728584 29785 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 09:40:38.152704 29785 solver.cpp:228] Iteration 8688, loss = 0.0117583
I0403 09:40:38.153041 29785 solver.cpp:244]     Train net output #0: loss = 0.0117586 (* 1 = 0.0117586 loss)
I0403 09:40:38.342631 29785 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 09:40:49.847441 29785 solver.cpp:228] Iteration 8704, loss = 0.00416562
I0403 09:40:49.847535 29785 solver.cpp:244]     Train net output #0: loss = 0.00416593 (* 1 = 0.00416593 loss)
I0403 09:40:50.041218 29785 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 09:41:01.427659 29785 solver.cpp:228] Iteration 8720, loss = 0.00650249
I0403 09:41:01.427747 29785 solver.cpp:244]     Train net output #0: loss = 0.0065028 (* 1 = 0.0065028 loss)
I0403 09:41:01.556519 29785 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 09:41:13.199661 29785 solver.cpp:228] Iteration 8736, loss = 0.000941665
I0403 09:41:13.199966 29785 solver.cpp:244]     Train net output #0: loss = 0.000941973 (* 1 = 0.000941973 loss)
I0403 09:41:13.400324 29785 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 09:41:24.802690 29785 solver.cpp:228] Iteration 8752, loss = 0.000465675
I0403 09:41:24.802784 29785 solver.cpp:244]     Train net output #0: loss = 0.000465986 (* 1 = 0.000465986 loss)
I0403 09:41:24.996978 29785 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 09:41:36.404698 29785 solver.cpp:228] Iteration 8768, loss = 0.00394968
I0403 09:41:36.404794 29785 solver.cpp:244]     Train net output #0: loss = 0.00394999 (* 1 = 0.00394999 loss)
I0403 09:41:36.606119 29785 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 09:41:41.005189 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8775.caffemodel
I0403 09:41:43.791230 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_8775.solverstate
I0403 09:41:45.610430 29785 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 09:42:34.315960 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972397
I0403 09:42:34.316982 29785 solver.cpp:404]     Test net output #1: loss = 0.114781 (* 1 = 0.114781 loss)
I0403 09:42:41.434613 29785 solver.cpp:228] Iteration 8784, loss = 0.00336511
I0403 09:42:41.434710 29785 solver.cpp:244]     Train net output #0: loss = 0.00336542 (* 1 = 0.00336542 loss)
I0403 09:42:41.623534 29785 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 09:42:53.018360 29785 solver.cpp:228] Iteration 8800, loss = 0.00518882
I0403 09:42:53.018457 29785 solver.cpp:244]     Train net output #0: loss = 0.00518913 (* 1 = 0.00518913 loss)
I0403 09:42:53.200857 29785 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 09:43:04.559654 29785 solver.cpp:228] Iteration 8816, loss = 0.0475572
I0403 09:43:04.559939 29785 solver.cpp:244]     Train net output #0: loss = 0.0475575 (* 1 = 0.0475575 loss)
I0403 09:43:04.711134 29785 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 09:43:16.106251 29785 solver.cpp:228] Iteration 8832, loss = 0.00120706
I0403 09:43:16.106344 29785 solver.cpp:244]     Train net output #0: loss = 0.00120736 (* 1 = 0.00120736 loss)
I0403 09:43:16.300005 29785 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 09:43:28.044430 29785 solver.cpp:228] Iteration 8848, loss = 0.00260363
I0403 09:43:28.044526 29785 solver.cpp:244]     Train net output #0: loss = 0.00260393 (* 1 = 0.00260393 loss)
I0403 09:43:28.253756 29785 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 09:43:39.702297 29785 solver.cpp:228] Iteration 8864, loss = 0.00602213
I0403 09:43:39.702620 29785 solver.cpp:244]     Train net output #0: loss = 0.00602243 (* 1 = 0.00602243 loss)
I0403 09:43:39.855482 29785 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 09:43:51.262773 29785 solver.cpp:228] Iteration 8880, loss = 0.0143035
I0403 09:43:51.262866 29785 solver.cpp:244]     Train net output #0: loss = 0.0143039 (* 1 = 0.0143039 loss)
I0403 09:43:51.444560 29785 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 09:44:03.001368 29785 solver.cpp:228] Iteration 8896, loss = 0.0139531
I0403 09:44:03.001464 29785 solver.cpp:244]     Train net output #0: loss = 0.0139535 (* 1 = 0.0139535 loss)
I0403 09:44:03.187688 29785 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 09:44:14.731448 29785 solver.cpp:228] Iteration 8912, loss = 0.0111006
I0403 09:44:14.731746 29785 solver.cpp:244]     Train net output #0: loss = 0.0111009 (* 1 = 0.0111009 loss)
I0403 09:44:14.918545 29785 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 09:44:26.439959 29785 solver.cpp:228] Iteration 8928, loss = 0.0121339
I0403 09:44:26.440044 29785 solver.cpp:244]     Train net output #0: loss = 0.0121342 (* 1 = 0.0121342 loss)
I0403 09:44:26.606264 29785 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 09:44:38.331748 29785 solver.cpp:228] Iteration 8944, loss = 0.00399391
I0403 09:44:38.331837 29785 solver.cpp:244]     Train net output #0: loss = 0.00399422 (* 1 = 0.00399422 loss)
I0403 09:44:38.499740 29785 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 09:44:50.031157 29785 solver.cpp:228] Iteration 8960, loss = 0.00283138
I0403 09:44:50.031452 29785 solver.cpp:244]     Train net output #0: loss = 0.00283169 (* 1 = 0.00283169 loss)
I0403 09:44:50.218278 29785 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 09:45:01.704427 29785 solver.cpp:228] Iteration 8976, loss = 0.00330344
I0403 09:45:01.704522 29785 solver.cpp:244]     Train net output #0: loss = 0.00330374 (* 1 = 0.00330374 loss)
I0403 09:45:01.886003 29785 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 09:45:13.291968 29785 solver.cpp:228] Iteration 8992, loss = 0.006615
I0403 09:45:13.292064 29785 solver.cpp:244]     Train net output #0: loss = 0.0066153 (* 1 = 0.0066153 loss)
I0403 09:45:13.474012 29785 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 09:45:24.972146 29785 solver.cpp:228] Iteration 9008, loss = 0.00507301
I0403 09:45:24.972398 29785 solver.cpp:244]     Train net output #0: loss = 0.00507331 (* 1 = 0.00507331 loss)
I0403 09:45:25.162710 29785 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 09:45:36.484967 29785 solver.cpp:228] Iteration 9024, loss = 0.0120137
I0403 09:45:36.485064 29785 solver.cpp:244]     Train net output #0: loss = 0.012014 (* 1 = 0.012014 loss)
I0403 09:45:36.682045 29785 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 09:45:48.335096 29785 solver.cpp:228] Iteration 9040, loss = 0.00141821
I0403 09:45:48.335188 29785 solver.cpp:244]     Train net output #0: loss = 0.00141851 (* 1 = 0.00141851 loss)
I0403 09:45:48.483636 29785 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 09:46:00.206897 29785 solver.cpp:228] Iteration 9056, loss = 0.00598966
I0403 09:46:00.207186 29785 solver.cpp:244]     Train net output #0: loss = 0.00598997 (* 1 = 0.00598997 loss)
I0403 09:46:00.351105 29785 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 09:46:11.788004 29785 solver.cpp:228] Iteration 9072, loss = 0.00149064
I0403 09:46:11.788097 29785 solver.cpp:244]     Train net output #0: loss = 0.00149094 (* 1 = 0.00149094 loss)
I0403 09:46:11.945663 29785 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 09:46:23.496155 29785 solver.cpp:228] Iteration 9088, loss = 0.00175798
I0403 09:46:23.496253 29785 solver.cpp:244]     Train net output #0: loss = 0.00175828 (* 1 = 0.00175828 loss)
I0403 09:46:23.717591 29785 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 09:46:31.611222 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9100.caffemodel
I0403 09:46:34.353391 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9100.solverstate
I0403 09:46:36.570037 29785 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 09:47:25.237331 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972259
I0403 09:47:25.237637 29785 solver.cpp:404]     Test net output #1: loss = 0.115505 (* 1 = 0.115505 loss)
I0403 09:47:28.790894 29785 solver.cpp:228] Iteration 9104, loss = 0.00642986
I0403 09:47:28.790990 29785 solver.cpp:244]     Train net output #0: loss = 0.00643016 (* 1 = 0.00643016 loss)
I0403 09:47:28.972143 29785 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 09:47:40.293263 29785 solver.cpp:228] Iteration 9120, loss = 0.00379126
I0403 09:47:40.293356 29785 solver.cpp:244]     Train net output #0: loss = 0.00379155 (* 1 = 0.00379155 loss)
I0403 09:47:40.477391 29785 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 09:47:52.009554 29785 solver.cpp:228] Iteration 9136, loss = 0.00130063
I0403 09:47:52.009641 29785 solver.cpp:244]     Train net output #0: loss = 0.00130093 (* 1 = 0.00130093 loss)
I0403 09:47:52.187577 29785 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 09:48:03.590294 29785 solver.cpp:228] Iteration 9152, loss = 0.016315
I0403 09:48:03.590589 29785 solver.cpp:244]     Train net output #0: loss = 0.0163153 (* 1 = 0.0163153 loss)
I0403 09:48:03.783517 29785 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 09:48:15.243809 29785 solver.cpp:228] Iteration 9168, loss = 0.00698515
I0403 09:48:15.243909 29785 solver.cpp:244]     Train net output #0: loss = 0.00698545 (* 1 = 0.00698545 loss)
I0403 09:48:15.527958 29785 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 09:48:27.131445 29785 solver.cpp:228] Iteration 9184, loss = 0.0197972
I0403 09:48:27.131544 29785 solver.cpp:244]     Train net output #0: loss = 0.0197975 (* 1 = 0.0197975 loss)
I0403 09:48:27.334960 29785 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 09:48:39.011728 29785 solver.cpp:228] Iteration 9200, loss = 0.000489831
I0403 09:48:39.012027 29785 solver.cpp:244]     Train net output #0: loss = 0.00049013 (* 1 = 0.00049013 loss)
I0403 09:48:39.189537 29785 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 09:48:50.536697 29785 solver.cpp:228] Iteration 9216, loss = 0.00570995
I0403 09:48:50.536792 29785 solver.cpp:244]     Train net output #0: loss = 0.00571025 (* 1 = 0.00571025 loss)
I0403 09:48:50.727648 29785 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 09:49:02.121865 29785 solver.cpp:228] Iteration 9232, loss = 0.00967508
I0403 09:49:02.121963 29785 solver.cpp:244]     Train net output #0: loss = 0.00967538 (* 1 = 0.00967538 loss)
I0403 09:49:02.308616 29785 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 09:49:13.772717 29785 solver.cpp:228] Iteration 9248, loss = 0.0043389
I0403 09:49:13.773020 29785 solver.cpp:244]     Train net output #0: loss = 0.0043392 (* 1 = 0.0043392 loss)
I0403 09:49:13.961127 29785 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 09:49:25.475059 29785 solver.cpp:228] Iteration 9264, loss = 0.00587999
I0403 09:49:25.475162 29785 solver.cpp:244]     Train net output #0: loss = 0.00588029 (* 1 = 0.00588029 loss)
I0403 09:49:25.739151 29785 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 09:49:37.297490 29785 solver.cpp:228] Iteration 9280, loss = 0.000600163
I0403 09:49:37.297587 29785 solver.cpp:244]     Train net output #0: loss = 0.000600459 (* 1 = 0.000600459 loss)
I0403 09:49:37.486153 29785 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 09:49:49.031718 29785 solver.cpp:228] Iteration 9296, loss = 0.00197139
I0403 09:49:49.031993 29785 solver.cpp:244]     Train net output #0: loss = 0.00197169 (* 1 = 0.00197169 loss)
I0403 09:49:49.226846 29785 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 09:50:00.653631 29785 solver.cpp:228] Iteration 9312, loss = 0.00374649
I0403 09:50:00.653728 29785 solver.cpp:244]     Train net output #0: loss = 0.00374679 (* 1 = 0.00374679 loss)
I0403 09:50:00.853492 29785 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 09:50:12.361714 29785 solver.cpp:228] Iteration 9328, loss = 0.00772315
I0403 09:50:12.361814 29785 solver.cpp:244]     Train net output #0: loss = 0.00772344 (* 1 = 0.00772344 loss)
I0403 09:50:12.614243 29785 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 09:50:24.119844 29785 solver.cpp:228] Iteration 9344, loss = 0.0103327
I0403 09:50:24.120152 29785 solver.cpp:244]     Train net output #0: loss = 0.010333 (* 1 = 0.010333 loss)
I0403 09:50:24.305264 29785 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 09:50:35.766476 29785 solver.cpp:228] Iteration 9360, loss = 0.0142398
I0403 09:50:35.766574 29785 solver.cpp:244]     Train net output #0: loss = 0.0142401 (* 1 = 0.0142401 loss)
I0403 09:50:35.958608 29785 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 09:50:47.370859 29785 solver.cpp:228] Iteration 9376, loss = 0.002389
I0403 09:50:47.370954 29785 solver.cpp:244]     Train net output #0: loss = 0.00238929 (* 1 = 0.00238929 loss)
I0403 09:50:47.562568 29785 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 09:50:59.009652 29785 solver.cpp:228] Iteration 9392, loss = 0.000870458
I0403 09:50:59.009951 29785 solver.cpp:244]     Train net output #0: loss = 0.000870755 (* 1 = 0.000870755 loss)
I0403 09:50:59.209821 29785 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 09:51:10.512557 29785 solver.cpp:228] Iteration 9408, loss = 0.00951715
I0403 09:51:10.512653 29785 solver.cpp:244]     Train net output #0: loss = 0.00951745 (* 1 = 0.00951745 loss)
I0403 09:51:10.739974 29785 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 09:51:22.135015 29785 solver.cpp:228] Iteration 9424, loss = 0.0330715
I0403 09:51:22.135118 29785 solver.cpp:244]     Train net output #0: loss = 0.0330718 (* 1 = 0.0330718 loss)
I0403 09:51:22.347733 29785 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 09:51:22.347965 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9425.caffemodel
I0403 09:51:25.117339 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9425.solverstate
I0403 09:51:27.045464 29785 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 09:52:15.723664 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972074
I0403 09:52:15.723935 29785 solver.cpp:404]     Test net output #1: loss = 0.11597 (* 1 = 0.11597 loss)
I0403 09:52:27.070288 29785 solver.cpp:228] Iteration 9440, loss = 0.018057
I0403 09:52:27.070395 29785 solver.cpp:244]     Train net output #0: loss = 0.0180573 (* 1 = 0.0180573 loss)
I0403 09:52:27.261670 29785 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 09:52:38.661556 29785 solver.cpp:228] Iteration 9456, loss = 0.00557773
I0403 09:52:38.661665 29785 solver.cpp:244]     Train net output #0: loss = 0.00557803 (* 1 = 0.00557803 loss)
I0403 09:52:38.852746 29785 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 09:52:50.230772 29785 solver.cpp:228] Iteration 9472, loss = 0.00343977
I0403 09:52:50.231071 29785 solver.cpp:244]     Train net output #0: loss = 0.00344007 (* 1 = 0.00344007 loss)
I0403 09:52:50.430622 29785 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 09:53:02.028517 29785 solver.cpp:228] Iteration 9488, loss = 0.0385591
I0403 09:53:02.028615 29785 solver.cpp:244]     Train net output #0: loss = 0.0385594 (* 1 = 0.0385594 loss)
I0403 09:53:02.231326 29785 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 09:53:13.652228 29785 solver.cpp:228] Iteration 9504, loss = 0.0034477
I0403 09:53:13.652325 29785 solver.cpp:244]     Train net output #0: loss = 0.003448 (* 1 = 0.003448 loss)
I0403 09:53:13.854121 29785 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 09:53:25.472898 29785 solver.cpp:228] Iteration 9520, loss = 0.00248643
I0403 09:53:25.476161 29785 solver.cpp:244]     Train net output #0: loss = 0.00248673 (* 1 = 0.00248673 loss)
I0403 09:53:25.696183 29785 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 09:53:37.030525 29785 solver.cpp:228] Iteration 9536, loss = 0.00348143
I0403 09:53:37.030623 29785 solver.cpp:244]     Train net output #0: loss = 0.00348173 (* 1 = 0.00348173 loss)
I0403 09:53:37.241752 29785 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 09:53:48.680759 29785 solver.cpp:228] Iteration 9552, loss = 0.00209113
I0403 09:53:48.680862 29785 solver.cpp:244]     Train net output #0: loss = 0.00209143 (* 1 = 0.00209143 loss)
I0403 09:53:48.893767 29785 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 09:54:00.351478 29785 solver.cpp:228] Iteration 9568, loss = 0.000989961
I0403 09:54:00.351811 29785 solver.cpp:244]     Train net output #0: loss = 0.000990263 (* 1 = 0.000990263 loss)
I0403 09:54:00.561622 29785 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 09:54:11.977095 29785 solver.cpp:228] Iteration 9584, loss = 0.00716695
I0403 09:54:11.977198 29785 solver.cpp:244]     Train net output #0: loss = 0.00716725 (* 1 = 0.00716725 loss)
I0403 09:54:12.236608 29785 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 09:54:23.654274 29785 solver.cpp:228] Iteration 9600, loss = 0.0106072
I0403 09:54:23.654386 29785 solver.cpp:244]     Train net output #0: loss = 0.0106075 (* 1 = 0.0106075 loss)
I0403 09:54:23.854300 29785 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 09:54:35.452788 29785 solver.cpp:228] Iteration 9616, loss = 0.0027632
I0403 09:54:35.453095 29785 solver.cpp:244]     Train net output #0: loss = 0.0027635 (* 1 = 0.0027635 loss)
I0403 09:54:35.645715 29785 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 09:54:47.108002 29785 solver.cpp:228] Iteration 9632, loss = 0.0158053
I0403 09:54:47.108105 29785 solver.cpp:244]     Train net output #0: loss = 0.0158056 (* 1 = 0.0158056 loss)
I0403 09:54:47.298353 29785 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 09:54:58.699782 29785 solver.cpp:228] Iteration 9648, loss = 0.0137797
I0403 09:54:58.699869 29785 solver.cpp:244]     Train net output #0: loss = 0.01378 (* 1 = 0.01378 loss)
I0403 09:54:58.879706 29785 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 09:55:10.320309 29785 solver.cpp:228] Iteration 9664, loss = 0.0145295
I0403 09:55:10.320607 29785 solver.cpp:244]     Train net output #0: loss = 0.0145298 (* 1 = 0.0145298 loss)
I0403 09:55:10.523643 29785 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 09:55:21.909788 29785 solver.cpp:228] Iteration 9680, loss = 0.0144365
I0403 09:55:21.909888 29785 solver.cpp:244]     Train net output #0: loss = 0.0144368 (* 1 = 0.0144368 loss)
I0403 09:55:22.112972 29785 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 09:55:33.505844 29785 solver.cpp:228] Iteration 9696, loss = 0.0153023
I0403 09:55:33.505939 29785 solver.cpp:244]     Train net output #0: loss = 0.0153026 (* 1 = 0.0153026 loss)
I0403 09:55:33.703011 29785 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 09:55:45.503355 29785 solver.cpp:228] Iteration 9712, loss = 0.00361016
I0403 09:55:45.503656 29785 solver.cpp:244]     Train net output #0: loss = 0.00361047 (* 1 = 0.00361047 loss)
I0403 09:55:45.699378 29785 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 09:55:57.265475 29785 solver.cpp:228] Iteration 9728, loss = 0.00366692
I0403 09:55:57.265564 29785 solver.cpp:244]     Train net output #0: loss = 0.00366722 (* 1 = 0.00366722 loss)
I0403 09:55:57.438881 29785 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 09:56:08.978974 29785 solver.cpp:228] Iteration 9744, loss = 0.00365319
I0403 09:56:08.979071 29785 solver.cpp:244]     Train net output #0: loss = 0.00365349 (* 1 = 0.00365349 loss)
I0403 09:56:09.162760 29785 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 09:56:12.773223 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9750.caffemodel
I0403 09:56:15.556789 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9750.solverstate
I0403 09:56:17.438411 29785 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 09:57:06.109323 29785 solver.cpp:404]     Test net output #0: accuracy = 0.972535
I0403 09:57:06.109637 29785 solver.cpp:404]     Test net output #1: loss = 0.11531 (* 1 = 0.11531 loss)
I0403 09:57:10.525620 29785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9756.caffemodel
I0403 09:57:13.269075 29785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-60-40_train_from_scratch/snapshots__iter_9756.solverstate
I0403 09:57:15.140688 29785 solver.cpp:322] Optimization Done.
I0403 09:57:15.223003 29785 caffe.cpp:222] Optimization Done.
