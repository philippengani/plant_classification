I0403 02:30:28.132017 16972 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.135668 16972 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.135700 16972 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.217478 16972 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.218994 16972 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.220464 16972 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.080246 16972 solver.cpp:48] Initializing solver from parameters: 
test_iter: 434
test_interval: 108
base_lr: 0.005
display: 5
max_iter: 3251
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1083
snapshot: 108
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.103427 16972 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.113879 16972 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.114022 16972 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.115761 16972 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-20-80/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.116978 16972 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.118643 16972 net.cpp:91] Creating Layer data
I0403 02:30:37.118804 16972 net.cpp:399] data -> data
I0403 02:30:37.118942 16972 net.cpp:399] data -> label
I0403 02:30:37.119037 16972 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto
I0403 02:30:37.162235 16980 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-20-80/train_db
I0403 02:30:37.169121 16972 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.326380 16972 net.cpp:141] Setting up data
I0403 02:30:37.326488 16972 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.326515 16972 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.326534 16972 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.326581 16972 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.326630 16972 net.cpp:91] Creating Layer conv1
I0403 02:30:37.326658 16972 net.cpp:425] conv1 <- data
I0403 02:30:37.326695 16972 net.cpp:399] conv1 -> conv1
I0403 02:30:37.329913 16972 net.cpp:141] Setting up conv1
I0403 02:30:37.329953 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.329975 16972 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.330020 16972 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.330055 16972 net.cpp:91] Creating Layer relu1
I0403 02:30:37.330080 16972 net.cpp:425] relu1 <- conv1
I0403 02:30:37.330106 16972 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.330135 16972 net.cpp:141] Setting up relu1
I0403 02:30:37.330162 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.330180 16972 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.330200 16972 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.330226 16972 net.cpp:91] Creating Layer norm1
I0403 02:30:37.330296 16972 net.cpp:425] norm1 <- conv1
I0403 02:30:37.330322 16972 net.cpp:399] norm1 -> norm1
I0403 02:30:37.339409 16972 net.cpp:141] Setting up norm1
I0403 02:30:37.339452 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.339473 16972 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.339493 16972 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.339524 16972 net.cpp:91] Creating Layer pool1
I0403 02:30:37.339545 16972 net.cpp:425] pool1 <- norm1
I0403 02:30:37.339567 16972 net.cpp:399] pool1 -> pool1
I0403 02:30:37.339643 16972 net.cpp:141] Setting up pool1
I0403 02:30:37.339673 16972 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.339692 16972 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.339711 16972 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.339740 16972 net.cpp:91] Creating Layer conv2
I0403 02:30:37.339759 16972 net.cpp:425] conv2 <- pool1
I0403 02:30:37.339784 16972 net.cpp:399] conv2 -> conv2
I0403 02:30:37.341513 16982 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.356070 16972 net.cpp:141] Setting up conv2
I0403 02:30:37.356109 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.356132 16972 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.356158 16972 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.356183 16972 net.cpp:91] Creating Layer relu2
I0403 02:30:37.356204 16972 net.cpp:425] relu2 <- conv2
I0403 02:30:37.356226 16972 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.356248 16972 net.cpp:141] Setting up relu2
I0403 02:30:37.356277 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.356295 16972 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.356312 16972 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.356335 16972 net.cpp:91] Creating Layer norm2
I0403 02:30:37.356356 16972 net.cpp:425] norm2 <- conv2
I0403 02:30:37.356379 16972 net.cpp:399] norm2 -> norm2
I0403 02:30:37.356434 16972 net.cpp:141] Setting up norm2
I0403 02:30:37.356462 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.356480 16972 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.356498 16972 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.356525 16972 net.cpp:91] Creating Layer pool2
I0403 02:30:37.356547 16972 net.cpp:425] pool2 <- norm2
I0403 02:30:37.356570 16972 net.cpp:399] pool2 -> pool2
I0403 02:30:37.356623 16972 net.cpp:141] Setting up pool2
I0403 02:30:37.356650 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.356668 16972 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.356688 16972 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.356714 16972 net.cpp:91] Creating Layer conv3
I0403 02:30:37.356734 16972 net.cpp:425] conv3 <- pool2
I0403 02:30:37.356760 16972 net.cpp:399] conv3 -> conv3
I0403 02:30:37.398489 16972 net.cpp:141] Setting up conv3
I0403 02:30:37.398531 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.398552 16972 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.398579 16972 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.398602 16972 net.cpp:91] Creating Layer relu3
I0403 02:30:37.398622 16972 net.cpp:425] relu3 <- conv3
I0403 02:30:37.398643 16972 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.398668 16972 net.cpp:141] Setting up relu3
I0403 02:30:37.398690 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.398710 16972 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.398727 16972 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.398756 16972 net.cpp:91] Creating Layer conv4
I0403 02:30:37.398777 16972 net.cpp:425] conv4 <- conv3
I0403 02:30:37.398800 16972 net.cpp:399] conv4 -> conv4
I0403 02:30:37.430147 16972 net.cpp:141] Setting up conv4
I0403 02:30:37.430186 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.430205 16972 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.430227 16972 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.430279 16972 net.cpp:91] Creating Layer relu4
I0403 02:30:37.430301 16972 net.cpp:425] relu4 <- conv4
I0403 02:30:37.430325 16972 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.430348 16972 net.cpp:141] Setting up relu4
I0403 02:30:37.430371 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.430388 16972 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.430407 16972 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.430433 16972 net.cpp:91] Creating Layer conv5
I0403 02:30:37.430451 16972 net.cpp:425] conv5 <- conv4
I0403 02:30:37.430477 16972 net.cpp:399] conv5 -> conv5
I0403 02:30:37.451503 16972 net.cpp:141] Setting up conv5
I0403 02:30:37.451541 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.451561 16972 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.451588 16972 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.451613 16972 net.cpp:91] Creating Layer relu5
I0403 02:30:37.451633 16972 net.cpp:425] relu5 <- conv5
I0403 02:30:37.451655 16972 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.451679 16972 net.cpp:141] Setting up relu5
I0403 02:30:37.451700 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.451719 16972 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.451737 16972 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.451758 16972 net.cpp:91] Creating Layer pool5
I0403 02:30:37.451776 16972 net.cpp:425] pool5 <- conv5
I0403 02:30:37.451800 16972 net.cpp:399] pool5 -> pool5
I0403 02:30:37.451858 16972 net.cpp:141] Setting up pool5
I0403 02:30:37.451885 16972 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.451905 16972 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.451923 16972 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.451958 16972 net.cpp:91] Creating Layer fc6
I0403 02:30:37.451982 16972 net.cpp:425] fc6 <- pool5
I0403 02:30:37.452008 16972 net.cpp:399] fc6 -> fc6
I0403 02:30:39.045506 16972 net.cpp:141] Setting up fc6
I0403 02:30:39.045591 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.045608 16972 net.cpp:156] Memory required for data: 823332800
I0403 02:30:39.045630 16972 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:39.045657 16972 net.cpp:91] Creating Layer relu6
I0403 02:30:39.045675 16972 net.cpp:425] relu6 <- fc6
I0403 02:30:39.045696 16972 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:39.045718 16972 net.cpp:141] Setting up relu6
I0403 02:30:39.045735 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.045749 16972 net.cpp:156] Memory required for data: 824971200
I0403 02:30:39.045763 16972 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:39.045788 16972 net.cpp:91] Creating Layer drop6
I0403 02:30:39.045802 16972 net.cpp:425] drop6 <- fc6
I0403 02:30:39.045822 16972 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:39.045869 16972 net.cpp:141] Setting up drop6
I0403 02:30:39.045892 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.045907 16972 net.cpp:156] Memory required for data: 826609600
I0403 02:30:39.045922 16972 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:39.045944 16972 net.cpp:91] Creating Layer fc7
I0403 02:30:39.045960 16972 net.cpp:425] fc7 <- fc6
I0403 02:30:39.045979 16972 net.cpp:399] fc7 -> fc7
I0403 02:30:39.663909 16972 net.cpp:141] Setting up fc7
I0403 02:30:39.664007 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.664047 16972 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.664098 16972 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.664127 16972 net.cpp:91] Creating Layer relu7
I0403 02:30:39.664186 16972 net.cpp:425] relu7 <- fc7
I0403 02:30:39.664227 16972 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.664283 16972 net.cpp:141] Setting up relu7
I0403 02:30:39.664314 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.664355 16972 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.664397 16972 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.664475 16972 net.cpp:91] Creating Layer drop7
I0403 02:30:39.664530 16972 net.cpp:425] drop7 <- fc7
I0403 02:30:39.664571 16972 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.664639 16972 net.cpp:141] Setting up drop7
I0403 02:30:39.664686 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.664736 16972 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.664772 16972 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.664819 16972 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.664862 16972 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.664911 16972 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.671648 16972 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.671679 16972 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.671696 16972 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.671716 16972 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.671746 16972 net.cpp:91] Creating Layer loss
I0403 02:30:39.671764 16972 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.671782 16972 net.cpp:425] loss <- label
I0403 02:30:39.671805 16972 net.cpp:399] loss -> loss
I0403 02:30:39.671835 16972 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.671947 16972 net.cpp:141] Setting up loss
I0403 02:30:39.671973 16972 net.cpp:148] Top shape: (1)
I0403 02:30:39.671990 16972 net.cpp:151]     with loss weight 1
I0403 02:30:39.672044 16972 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.672060 16972 net.cpp:217] loss needs backward computation.
I0403 02:30:39.672076 16972 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.672091 16972 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.672106 16972 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.672122 16972 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.672137 16972 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.672152 16972 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.672168 16972 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.672183 16972 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.672199 16972 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.672214 16972 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.672230 16972 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.672245 16972 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.672266 16972 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.672281 16972 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.672297 16972 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.672314 16972 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.672329 16972 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.672344 16972 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.672359 16972 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.672374 16972 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.672389 16972 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.672405 16972 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.672420 16972 net.cpp:219] data does not need backward computation.
I0403 02:30:39.672436 16972 net.cpp:261] This network produces output loss
I0403 02:30:39.672467 16972 net.cpp:274] Network initialization done.
I0403 02:30:39.673647 16972 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.673713 16972 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.674435 16972 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-20-80/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.674608 16972 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.674748 16972 net.cpp:91] Creating Layer data
I0403 02:30:39.674779 16972 net.cpp:399] data -> data
I0403 02:30:39.674806 16972 net.cpp:399] data -> label
I0403 02:30:39.674832 16972 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto
I0403 02:30:39.687788 16985 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-20-80/test_db
I0403 02:30:39.694705 16972 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.896811 16972 net.cpp:141] Setting up data
I0403 02:30:39.896921 16972 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.897063 16972 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.897142 16972 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.897209 16972 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.897294 16972 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.897346 16972 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.897394 16972 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.897469 16972 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.897598 16972 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.897639 16972 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.897691 16972 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.897709 16972 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.897778 16972 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.897850 16972 net.cpp:91] Creating Layer conv1
I0403 02:30:39.897905 16972 net.cpp:425] conv1 <- data
I0403 02:30:39.898032 16972 net.cpp:399] conv1 -> conv1
I0403 02:30:39.901775 16972 net.cpp:141] Setting up conv1
I0403 02:30:39.901865 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.901924 16972 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.901995 16972 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.902071 16972 net.cpp:91] Creating Layer relu1
I0403 02:30:39.902113 16972 net.cpp:425] relu1 <- conv1
I0403 02:30:39.902178 16972 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.902243 16972 net.cpp:141] Setting up relu1
I0403 02:30:39.902321 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.902446 16972 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.902504 16972 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.902580 16972 net.cpp:91] Creating Layer norm1
I0403 02:30:39.902639 16972 net.cpp:425] norm1 <- conv1
I0403 02:30:39.902706 16972 net.cpp:399] norm1 -> norm1
I0403 02:30:39.902856 16972 net.cpp:141] Setting up norm1
I0403 02:30:39.902930 16972 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.902988 16972 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.903038 16972 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.903102 16972 net.cpp:91] Creating Layer pool1
I0403 02:30:39.903162 16972 net.cpp:425] pool1 <- norm1
I0403 02:30:39.903223 16972 net.cpp:399] pool1 -> pool1
I0403 02:30:39.903367 16972 net.cpp:141] Setting up pool1
I0403 02:30:39.903436 16972 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.903484 16972 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.903600 16972 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.903672 16972 net.cpp:91] Creating Layer conv2
I0403 02:30:39.903729 16972 net.cpp:425] conv2 <- pool1
I0403 02:30:39.903791 16972 net.cpp:399] conv2 -> conv2
I0403 02:30:39.917726 16972 net.cpp:141] Setting up conv2
I0403 02:30:39.936698 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.936784 16972 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.936890 16972 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.936997 16972 net.cpp:91] Creating Layer relu2
I0403 02:30:39.937072 16972 net.cpp:425] relu2 <- conv2
I0403 02:30:39.937142 16972 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.937237 16972 net.cpp:141] Setting up relu2
I0403 02:30:39.937335 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.937409 16972 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.937487 16972 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.937567 16972 net.cpp:91] Creating Layer norm2
I0403 02:30:39.937615 16972 net.cpp:425] norm2 <- conv2
I0403 02:30:39.937701 16972 net.cpp:399] norm2 -> norm2
I0403 02:30:39.937858 16972 net.cpp:141] Setting up norm2
I0403 02:30:39.937942 16972 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.938132 16972 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.938174 16972 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.938220 16972 net.cpp:91] Creating Layer pool2
I0403 02:30:39.938328 16972 net.cpp:425] pool2 <- norm2
I0403 02:30:39.938411 16972 net.cpp:399] pool2 -> pool2
I0403 02:30:39.938551 16972 net.cpp:141] Setting up pool2
I0403 02:30:39.938608 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.938644 16972 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.938683 16972 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.938738 16972 net.cpp:91] Creating Layer conv3
I0403 02:30:39.938781 16972 net.cpp:425] conv3 <- pool2
I0403 02:30:39.938832 16972 net.cpp:399] conv3 -> conv3
I0403 02:30:39.979424 16972 net.cpp:141] Setting up conv3
I0403 02:30:39.979471 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.979488 16972 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.979514 16972 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.979537 16972 net.cpp:91] Creating Layer relu3
I0403 02:30:39.979555 16972 net.cpp:425] relu3 <- conv3
I0403 02:30:39.979575 16972 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.979598 16972 net.cpp:141] Setting up relu3
I0403 02:30:39.979616 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.979631 16972 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.979645 16972 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.979668 16972 net.cpp:91] Creating Layer conv4
I0403 02:30:39.979686 16972 net.cpp:425] conv4 <- conv3
I0403 02:30:39.979707 16972 net.cpp:399] conv4 -> conv4
I0403 02:30:40.005970 16972 net.cpp:141] Setting up conv4
I0403 02:30:40.006006 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.006022 16972 net.cpp:156] Memory required for data: 757439200
I0403 02:30:40.006043 16972 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:40.006063 16972 net.cpp:91] Creating Layer relu4
I0403 02:30:40.006080 16972 net.cpp:425] relu4 <- conv4
I0403 02:30:40.006099 16972 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:40.006121 16972 net.cpp:141] Setting up relu4
I0403 02:30:40.006139 16972 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.006155 16972 net.cpp:156] Memory required for data: 783397600
I0403 02:30:40.006170 16972 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:40.006192 16972 net.cpp:91] Creating Layer conv5
I0403 02:30:40.006209 16972 net.cpp:425] conv5 <- conv4
I0403 02:30:40.006229 16972 net.cpp:399] conv5 -> conv5
I0403 02:30:40.023427 16972 net.cpp:141] Setting up conv5
I0403 02:30:40.023460 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.023476 16972 net.cpp:156] Memory required for data: 800703200
I0403 02:30:40.023531 16972 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:40.023555 16972 net.cpp:91] Creating Layer relu5
I0403 02:30:40.023581 16972 net.cpp:425] relu5 <- conv5
I0403 02:30:40.023604 16972 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:40.023633 16972 net.cpp:141] Setting up relu5
I0403 02:30:40.023650 16972 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.023669 16972 net.cpp:156] Memory required for data: 818008800
I0403 02:30:40.023684 16972 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:40.023710 16972 net.cpp:91] Creating Layer pool5
I0403 02:30:40.023730 16972 net.cpp:425] pool5 <- conv5
I0403 02:30:40.023747 16972 net.cpp:399] pool5 -> pool5
I0403 02:30:40.023802 16972 net.cpp:141] Setting up pool5
I0403 02:30:40.023825 16972 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:40.023840 16972 net.cpp:156] Memory required for data: 821695200
I0403 02:30:40.023854 16972 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:40.023877 16972 net.cpp:91] Creating Layer fc6
I0403 02:30:40.023895 16972 net.cpp:425] fc6 <- pool5
I0403 02:30:40.023913 16972 net.cpp:399] fc6 -> fc6
I0403 02:30:41.456569 16972 net.cpp:141] Setting up fc6
I0403 02:30:41.456655 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.456672 16972 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.456696 16972 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.456725 16972 net.cpp:91] Creating Layer relu6
I0403 02:30:41.456745 16972 net.cpp:425] relu6 <- fc6
I0403 02:30:41.456765 16972 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.456789 16972 net.cpp:141] Setting up relu6
I0403 02:30:41.456807 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.456821 16972 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.456835 16972 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.456854 16972 net.cpp:91] Creating Layer drop6
I0403 02:30:41.456871 16972 net.cpp:425] drop6 <- fc6
I0403 02:30:41.456890 16972 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.456930 16972 net.cpp:141] Setting up drop6
I0403 02:30:41.456953 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.456967 16972 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.456982 16972 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.457005 16972 net.cpp:91] Creating Layer fc7
I0403 02:30:41.457021 16972 net.cpp:425] fc7 <- fc6
I0403 02:30:41.457039 16972 net.cpp:399] fc7 -> fc7
I0403 02:30:42.081710 16972 net.cpp:141] Setting up fc7
I0403 02:30:42.081794 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.081815 16972 net.cpp:156] Memory required for data: 828248800
I0403 02:30:42.081840 16972 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:42.081867 16972 net.cpp:91] Creating Layer relu7
I0403 02:30:42.081889 16972 net.cpp:425] relu7 <- fc7
I0403 02:30:42.081912 16972 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:42.081938 16972 net.cpp:141] Setting up relu7
I0403 02:30:42.081959 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.081975 16972 net.cpp:156] Memory required for data: 829887200
I0403 02:30:42.081990 16972 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:42.082015 16972 net.cpp:91] Creating Layer drop7
I0403 02:30:42.082032 16972 net.cpp:425] drop7 <- fc7
I0403 02:30:42.082051 16972 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:42.082095 16972 net.cpp:141] Setting up drop7
I0403 02:30:42.082134 16972 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.082164 16972 net.cpp:156] Memory required for data: 831525600
I0403 02:30:42.082191 16972 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:42.082231 16972 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:42.082267 16972 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:42.082341 16972 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:42.090698 16972 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:42.090737 16972 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.090757 16972 net.cpp:156] Memory required for data: 831540800
I0403 02:30:42.090822 16972 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.090847 16972 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.090895 16972 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:42.090944 16972 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.091015 16972 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.091116 16972 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.091143 16972 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.091161 16972 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.091177 16972 net.cpp:156] Memory required for data: 831571200
I0403 02:30:42.091193 16972 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.091213 16972 net.cpp:91] Creating Layer loss
I0403 02:30:42.091230 16972 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.091248 16972 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:42.091270 16972 net.cpp:399] loss -> loss
I0403 02:30:42.091303 16972 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.091452 16972 net.cpp:141] Setting up loss
I0403 02:30:42.091503 16972 net.cpp:148] Top shape: (1)
I0403 02:30:42.091600 16972 net.cpp:151]     with loss weight 1
I0403 02:30:42.091641 16972 net.cpp:156] Memory required for data: 831571204
I0403 02:30:42.091661 16972 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:42.091686 16972 net.cpp:91] Creating Layer accuracy
I0403 02:30:42.091704 16972 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.091722 16972 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:42.091742 16972 net.cpp:399] accuracy -> accuracy
I0403 02:30:42.091799 16972 net.cpp:141] Setting up accuracy
I0403 02:30:42.091909 16972 net.cpp:148] Top shape: (1)
I0403 02:30:42.091964 16972 net.cpp:156] Memory required for data: 831571208
I0403 02:30:42.091984 16972 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:42.092001 16972 net.cpp:217] loss needs backward computation.
I0403 02:30:42.092039 16972 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:42.092082 16972 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:42.092118 16972 net.cpp:217] drop7 needs backward computation.
I0403 02:30:42.092183 16972 net.cpp:217] relu7 needs backward computation.
I0403 02:30:42.092247 16972 net.cpp:217] fc7 needs backward computation.
I0403 02:30:42.092267 16972 net.cpp:217] drop6 needs backward computation.
I0403 02:30:42.092283 16972 net.cpp:217] relu6 needs backward computation.
I0403 02:30:42.092304 16972 net.cpp:217] fc6 needs backward computation.
I0403 02:30:42.092321 16972 net.cpp:217] pool5 needs backward computation.
I0403 02:30:42.092341 16972 net.cpp:217] relu5 needs backward computation.
I0403 02:30:42.092356 16972 net.cpp:217] conv5 needs backward computation.
I0403 02:30:42.092373 16972 net.cpp:217] relu4 needs backward computation.
I0403 02:30:42.092389 16972 net.cpp:217] conv4 needs backward computation.
I0403 02:30:42.092404 16972 net.cpp:217] relu3 needs backward computation.
I0403 02:30:42.092419 16972 net.cpp:217] conv3 needs backward computation.
I0403 02:30:42.092435 16972 net.cpp:217] pool2 needs backward computation.
I0403 02:30:42.092452 16972 net.cpp:217] norm2 needs backward computation.
I0403 02:30:42.092468 16972 net.cpp:217] relu2 needs backward computation.
I0403 02:30:42.092512 16972 net.cpp:217] conv2 needs backward computation.
I0403 02:30:42.092533 16972 net.cpp:217] pool1 needs backward computation.
I0403 02:30:42.092550 16972 net.cpp:217] norm1 needs backward computation.
I0403 02:30:42.092566 16972 net.cpp:217] relu1 needs backward computation.
I0403 02:30:42.092583 16972 net.cpp:217] conv1 needs backward computation.
I0403 02:30:42.092665 16972 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:42.092691 16972 net.cpp:219] data does not need backward computation.
I0403 02:30:42.092708 16972 net.cpp:261] This network produces output accuracy
I0403 02:30:42.092725 16972 net.cpp:261] This network produces output loss
I0403 02:30:42.092782 16972 net.cpp:274] Network initialization done.
I0403 02:30:42.093044 16972 solver.cpp:60] Solver scaffolding done.
I0403 02:30:42.093971 16972 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.333338 16972 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.333417 16972 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.333439 16972 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.333485 16972 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.772450 16972 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.814638 16972 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.008558 16972 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.008644 16972 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:45.008668 16972 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:45.008720 16972 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.476898 16972 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.518612 16972 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.576244 16972 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.865108 16972 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.497155 16972 parallel.cpp:425] Starting Optimization
I0403 02:30:48.497665 16972 solver.cpp:279] Solving 
I0403 02:30:48.497691 16972 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.497874 16972 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:30.539484 16972 solver.cpp:404]     Test net output #0: accuracy = 0.0307835
I0403 02:32:30.544917 16972 solver.cpp:404]     Test net output #1: loss = 3.9226 (* 1 = 3.9226 loss)
I0403 02:32:31.131871 16972 solver.cpp:228] Iteration 0, loss = 4.32122
I0403 02:32:31.137908 16972 solver.cpp:244]     Train net output #0: loss = 4.32122 (* 1 = 4.32122 loss)
I0403 02:32:31.339694 16972 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:35.014863 16972 solver.cpp:228] Iteration 5, loss = 2.25878
I0403 02:32:35.020881 16972 solver.cpp:244]     Train net output #0: loss = 2.25878 (* 1 = 2.25878 loss)
I0403 02:32:35.213999 16972 sgd_solver.cpp:106] Iteration 5, lr = 0.005
I0403 02:32:38.852740 16972 solver.cpp:228] Iteration 10, loss = 1.62674
I0403 02:32:38.859845 16972 solver.cpp:244]     Train net output #0: loss = 1.62674 (* 1 = 1.62674 loss)
I0403 02:32:39.047420 16972 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:42.807571 16972 solver.cpp:228] Iteration 15, loss = 1.0869
I0403 02:32:42.813500 16972 solver.cpp:244]     Train net output #0: loss = 1.0869 (* 1 = 1.0869 loss)
I0403 02:32:43.058122 16972 sgd_solver.cpp:106] Iteration 15, lr = 0.005
I0403 02:32:46.781538 16972 solver.cpp:228] Iteration 20, loss = 0.969359
I0403 02:32:46.787456 16972 solver.cpp:244]     Train net output #0: loss = 0.969359 (* 1 = 0.969359 loss)
I0403 02:32:46.972692 16972 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:50.623872 16972 solver.cpp:228] Iteration 25, loss = 0.666144
I0403 02:32:50.629336 16972 solver.cpp:244]     Train net output #0: loss = 0.666144 (* 1 = 0.666144 loss)
I0403 02:32:50.816618 16972 sgd_solver.cpp:106] Iteration 25, lr = 0.005
I0403 02:32:54.464431 16972 solver.cpp:228] Iteration 30, loss = 0.520236
I0403 02:32:54.470048 16972 solver.cpp:244]     Train net output #0: loss = 0.520236 (* 1 = 0.520236 loss)
I0403 02:32:54.643168 16972 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:58.429850 16972 solver.cpp:228] Iteration 35, loss = 0.696609
I0403 02:32:58.436859 16972 solver.cpp:244]     Train net output #0: loss = 0.696609 (* 1 = 0.696609 loss)
I0403 02:32:58.608537 16972 sgd_solver.cpp:106] Iteration 35, lr = 0.005
I0403 02:33:02.344270 16972 solver.cpp:228] Iteration 40, loss = 0.420946
I0403 02:33:02.349930 16972 solver.cpp:244]     Train net output #0: loss = 0.420946 (* 1 = 0.420946 loss)
I0403 02:33:02.521069 16972 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:33:06.285871 16972 solver.cpp:228] Iteration 45, loss = 0.608387
I0403 02:33:06.292592 16972 solver.cpp:244]     Train net output #0: loss = 0.608387 (* 1 = 0.608387 loss)
I0403 02:33:06.465649 16972 sgd_solver.cpp:106] Iteration 45, lr = 0.005
I0403 02:33:10.168514 16972 solver.cpp:228] Iteration 50, loss = 0.450815
I0403 02:33:10.172329 16972 solver.cpp:244]     Train net output #0: loss = 0.450815 (* 1 = 0.450815 loss)
I0403 02:33:10.378026 16972 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:33:14.192112 16972 solver.cpp:228] Iteration 55, loss = 0.401895
I0403 02:33:14.198868 16972 solver.cpp:244]     Train net output #0: loss = 0.401895 (* 1 = 0.401895 loss)
I0403 02:33:14.383414 16972 sgd_solver.cpp:106] Iteration 55, lr = 0.005
I0403 02:33:18.090052 16972 solver.cpp:228] Iteration 60, loss = 0.397669
I0403 02:33:18.095187 16972 solver.cpp:244]     Train net output #0: loss = 0.397669 (* 1 = 0.397669 loss)
I0403 02:33:18.281150 16972 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:33:21.969508 16972 solver.cpp:228] Iteration 65, loss = 0.360397
I0403 02:33:21.976595 16972 solver.cpp:244]     Train net output #0: loss = 0.360397 (* 1 = 0.360397 loss)
I0403 02:33:22.162173 16972 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:33:25.941777 16972 solver.cpp:228] Iteration 70, loss = 0.263172
I0403 02:33:25.941864 16972 solver.cpp:244]     Train net output #0: loss = 0.263172 (* 1 = 0.263172 loss)
I0403 02:33:26.143915 16972 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:29.813201 16972 solver.cpp:228] Iteration 75, loss = 0.216612
I0403 02:33:29.813282 16972 solver.cpp:244]     Train net output #0: loss = 0.216612 (* 1 = 0.216612 loss)
I0403 02:33:30.010628 16972 sgd_solver.cpp:106] Iteration 75, lr = 0.005
I0403 02:33:33.676427 16972 solver.cpp:228] Iteration 80, loss = 0.373296
I0403 02:33:33.682642 16972 solver.cpp:244]     Train net output #0: loss = 0.373296 (* 1 = 0.373296 loss)
I0403 02:33:33.865581 16972 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:37.541091 16972 solver.cpp:228] Iteration 85, loss = 0.207592
I0403 02:33:37.547945 16972 solver.cpp:244]     Train net output #0: loss = 0.207592 (* 1 = 0.207592 loss)
I0403 02:33:37.731780 16972 sgd_solver.cpp:106] Iteration 85, lr = 0.005
I0403 02:33:41.414037 16972 solver.cpp:228] Iteration 90, loss = 0.181449
I0403 02:33:41.420614 16972 solver.cpp:244]     Train net output #0: loss = 0.181449 (* 1 = 0.181449 loss)
I0403 02:33:41.564862 16972 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:45.369463 16972 solver.cpp:228] Iteration 95, loss = 0.226273
I0403 02:33:45.376183 16972 solver.cpp:244]     Train net output #0: loss = 0.226273 (* 1 = 0.226273 loss)
I0403 02:33:45.624963 16972 sgd_solver.cpp:106] Iteration 95, lr = 0.005
I0403 02:33:49.281594 16972 solver.cpp:228] Iteration 100, loss = 0.351597
I0403 02:33:49.288346 16972 solver.cpp:244]     Train net output #0: loss = 0.351597 (* 1 = 0.351597 loss)
I0403 02:33:49.475150 16972 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:53.150069 16972 solver.cpp:228] Iteration 105, loss = 0.297438
I0403 02:33:53.156522 16972 solver.cpp:244]     Train net output #0: loss = 0.297438 (* 1 = 0.297438 loss)
I0403 02:33:53.360388 16972 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:33:54.967638 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_108.caffemodel
I0403 02:33:57.908218 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_108.solverstate
I0403 02:33:59.793895 16972 solver.cpp:337] Iteration 108, Testing net (#0)
I0403 02:35:40.879381 16972 solver.cpp:404]     Test net output #0: accuracy = 0.920715
I0403 02:35:40.885581 16972 solver.cpp:404]     Test net output #1: loss = 0.260408 (* 1 = 0.260408 loss)
I0403 02:35:43.031532 16972 solver.cpp:228] Iteration 110, loss = 0.314908
I0403 02:35:43.037853 16972 solver.cpp:244]     Train net output #0: loss = 0.314908 (* 1 = 0.314908 loss)
I0403 02:35:43.231297 16972 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:35:46.857000 16972 solver.cpp:228] Iteration 115, loss = 0.110825
I0403 02:35:46.862444 16972 solver.cpp:244]     Train net output #0: loss = 0.110825 (* 1 = 0.110825 loss)
I0403 02:35:47.045457 16972 sgd_solver.cpp:106] Iteration 115, lr = 0.005
I0403 02:35:50.707769 16972 solver.cpp:228] Iteration 120, loss = 0.261685
I0403 02:35:50.712966 16972 solver.cpp:244]     Train net output #0: loss = 0.261685 (* 1 = 0.261685 loss)
I0403 02:35:50.901046 16972 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:35:54.580957 16972 solver.cpp:228] Iteration 125, loss = 0.0863335
I0403 02:35:54.586750 16972 solver.cpp:244]     Train net output #0: loss = 0.0863334 (* 1 = 0.0863334 loss)
I0403 02:35:54.772357 16972 sgd_solver.cpp:106] Iteration 125, lr = 0.005
I0403 02:35:58.487277 16972 solver.cpp:228] Iteration 130, loss = 0.131446
I0403 02:35:58.492810 16972 solver.cpp:244]     Train net output #0: loss = 0.131446 (* 1 = 0.131446 loss)
I0403 02:35:58.670539 16972 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:36:02.406329 16972 solver.cpp:228] Iteration 135, loss = 0.119435
I0403 02:36:02.412327 16972 solver.cpp:244]     Train net output #0: loss = 0.119435 (* 1 = 0.119435 loss)
I0403 02:36:02.580713 16972 sgd_solver.cpp:106] Iteration 135, lr = 0.005
I0403 02:36:06.333230 16972 solver.cpp:228] Iteration 140, loss = 0.102758
I0403 02:36:06.338645 16972 solver.cpp:244]     Train net output #0: loss = 0.102757 (* 1 = 0.102757 loss)
I0403 02:36:06.511210 16972 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:36:10.306334 16972 solver.cpp:228] Iteration 145, loss = 0.114257
I0403 02:36:10.311722 16972 solver.cpp:244]     Train net output #0: loss = 0.114257 (* 1 = 0.114257 loss)
I0403 02:36:10.497957 16972 sgd_solver.cpp:106] Iteration 145, lr = 0.005
I0403 02:36:14.160094 16972 solver.cpp:228] Iteration 150, loss = 0.0802297
I0403 02:36:14.166533 16972 solver.cpp:244]     Train net output #0: loss = 0.0802297 (* 1 = 0.0802297 loss)
I0403 02:36:14.356456 16972 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:36:18.076609 16972 solver.cpp:228] Iteration 155, loss = 0.36443
I0403 02:36:18.082497 16972 solver.cpp:244]     Train net output #0: loss = 0.36443 (* 1 = 0.36443 loss)
I0403 02:36:18.267166 16972 sgd_solver.cpp:106] Iteration 155, lr = 0.005
I0403 02:36:21.912637 16972 solver.cpp:228] Iteration 160, loss = 0.205129
I0403 02:36:21.917974 16972 solver.cpp:244]     Train net output #0: loss = 0.205129 (* 1 = 0.205129 loss)
I0403 02:36:22.110188 16972 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:36:25.748641 16972 solver.cpp:228] Iteration 165, loss = 0.0952611
I0403 02:36:25.754606 16972 solver.cpp:244]     Train net output #0: loss = 0.0952611 (* 1 = 0.0952611 loss)
I0403 02:36:25.978268 16972 sgd_solver.cpp:106] Iteration 165, lr = 0.005
I0403 02:36:29.670732 16972 solver.cpp:228] Iteration 170, loss = 0.100203
I0403 02:36:29.677073 16972 solver.cpp:244]     Train net output #0: loss = 0.100203 (* 1 = 0.100203 loss)
I0403 02:36:29.880559 16972 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:36:33.669811 16972 solver.cpp:228] Iteration 175, loss = 0.123607
I0403 02:36:33.675350 16972 solver.cpp:244]     Train net output #0: loss = 0.123607 (* 1 = 0.123607 loss)
I0403 02:36:33.864838 16972 sgd_solver.cpp:106] Iteration 175, lr = 0.005
I0403 02:36:37.490504 16972 solver.cpp:228] Iteration 180, loss = 0.0898384
I0403 02:36:37.496021 16972 solver.cpp:244]     Train net output #0: loss = 0.0898384 (* 1 = 0.0898384 loss)
I0403 02:36:37.700705 16972 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:36:41.463244 16972 solver.cpp:228] Iteration 185, loss = 0.244148
I0403 02:36:41.469516 16972 solver.cpp:244]     Train net output #0: loss = 0.244148 (* 1 = 0.244148 loss)
I0403 02:36:41.660786 16972 sgd_solver.cpp:106] Iteration 185, lr = 0.005
I0403 02:36:45.350975 16972 solver.cpp:228] Iteration 190, loss = 0.0493295
I0403 02:36:45.358660 16972 solver.cpp:244]     Train net output #0: loss = 0.0493294 (* 1 = 0.0493294 loss)
I0403 02:36:45.538184 16972 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:36:49.242949 16972 solver.cpp:228] Iteration 195, loss = 0.1373
I0403 02:36:49.249825 16972 solver.cpp:244]     Train net output #0: loss = 0.1373 (* 1 = 0.1373 loss)
I0403 02:36:49.511708 16972 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:36:53.234614 16972 solver.cpp:228] Iteration 200, loss = 0.0541934
I0403 02:36:53.241108 16972 solver.cpp:244]     Train net output #0: loss = 0.0541934 (* 1 = 0.0541934 loss)
I0403 02:36:53.426844 16972 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:36:57.252471 16972 solver.cpp:228] Iteration 205, loss = 0.180973
I0403 02:36:57.259647 16972 solver.cpp:244]     Train net output #0: loss = 0.180973 (* 1 = 0.180973 loss)
I0403 02:36:57.431618 16972 sgd_solver.cpp:106] Iteration 205, lr = 0.005
I0403 02:37:01.203234 16972 solver.cpp:228] Iteration 210, loss = 0.081021
I0403 02:37:01.209406 16972 solver.cpp:244]     Train net output #0: loss = 0.081021 (* 1 = 0.081021 loss)
I0403 02:37:01.399580 16972 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:37:05.018435 16972 solver.cpp:228] Iteration 215, loss = 0.149049
I0403 02:37:05.024461 16972 solver.cpp:244]     Train net output #0: loss = 0.149049 (* 1 = 0.149049 loss)
I0403 02:37:05.217473 16972 sgd_solver.cpp:106] Iteration 215, lr = 0.005
I0403 02:37:05.217721 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_216.caffemodel
I0403 02:37:08.024937 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_216.solverstate
I0403 02:37:10.224901 16972 solver.cpp:337] Iteration 216, Testing net (#0)
I0403 02:38:51.298827 16972 solver.cpp:404]     Test net output #0: accuracy = 0.944793
I0403 02:38:51.306545 16972 solver.cpp:404]     Test net output #1: loss = 0.18168 (* 1 = 0.18168 loss)
I0403 02:38:54.943408 16972 solver.cpp:228] Iteration 220, loss = 0.0624166
I0403 02:38:54.943506 16972 solver.cpp:244]     Train net output #0: loss = 0.0624165 (* 1 = 0.0624165 loss)
I0403 02:38:55.190281 16972 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:38:58.817276 16972 solver.cpp:228] Iteration 225, loss = 0.10609
I0403 02:38:58.817389 16972 solver.cpp:244]     Train net output #0: loss = 0.10609 (* 1 = 0.10609 loss)
I0403 02:38:58.992746 16972 sgd_solver.cpp:106] Iteration 225, lr = 0.005
I0403 02:39:02.685196 16972 solver.cpp:228] Iteration 230, loss = 0.0907924
I0403 02:39:02.685281 16972 solver.cpp:244]     Train net output #0: loss = 0.0907924 (* 1 = 0.0907924 loss)
I0403 02:39:02.866180 16972 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:39:06.537142 16972 solver.cpp:228] Iteration 235, loss = 0.0382032
I0403 02:39:06.537238 16972 solver.cpp:244]     Train net output #0: loss = 0.0382031 (* 1 = 0.0382031 loss)
I0403 02:39:06.759769 16972 sgd_solver.cpp:106] Iteration 235, lr = 0.005
I0403 02:39:10.498549 16972 solver.cpp:228] Iteration 240, loss = 0.146048
I0403 02:39:10.498637 16972 solver.cpp:244]     Train net output #0: loss = 0.146048 (* 1 = 0.146048 loss)
I0403 02:39:10.681634 16972 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:39:14.349303 16972 solver.cpp:228] Iteration 245, loss = 0.108431
I0403 02:39:14.349390 16972 solver.cpp:244]     Train net output #0: loss = 0.108431 (* 1 = 0.108431 loss)
I0403 02:39:14.548537 16972 sgd_solver.cpp:106] Iteration 245, lr = 0.005
I0403 02:39:18.165721 16972 solver.cpp:228] Iteration 250, loss = 0.113632
I0403 02:39:18.165819 16972 solver.cpp:244]     Train net output #0: loss = 0.113631 (* 1 = 0.113631 loss)
I0403 02:39:18.390081 16972 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:39:22.012809 16972 solver.cpp:228] Iteration 255, loss = 0.0849956
I0403 02:39:22.013073 16972 solver.cpp:244]     Train net output #0: loss = 0.0849955 (* 1 = 0.0849955 loss)
I0403 02:39:22.197103 16972 sgd_solver.cpp:106] Iteration 255, lr = 0.005
I0403 02:39:25.996561 16972 solver.cpp:228] Iteration 260, loss = 0.212125
I0403 02:39:25.996646 16972 solver.cpp:244]     Train net output #0: loss = 0.212125 (* 1 = 0.212125 loss)
I0403 02:39:26.193044 16972 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:39:29.920330 16972 solver.cpp:228] Iteration 265, loss = 0.118247
I0403 02:39:29.920416 16972 solver.cpp:244]     Train net output #0: loss = 0.118247 (* 1 = 0.118247 loss)
I0403 02:39:30.097064 16972 sgd_solver.cpp:106] Iteration 265, lr = 0.005
I0403 02:39:33.860810 16972 solver.cpp:228] Iteration 270, loss = 0.0498
I0403 02:39:33.860899 16972 solver.cpp:244]     Train net output #0: loss = 0.0498 (* 1 = 0.0498 loss)
I0403 02:39:34.048117 16972 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:39:37.875007 16972 solver.cpp:228] Iteration 275, loss = 0.153657
I0403 02:39:37.875097 16972 solver.cpp:244]     Train net output #0: loss = 0.153657 (* 1 = 0.153657 loss)
I0403 02:39:38.035897 16972 sgd_solver.cpp:106] Iteration 275, lr = 0.005
I0403 02:39:41.782310 16972 solver.cpp:228] Iteration 280, loss = 0.0488075
I0403 02:39:41.782397 16972 solver.cpp:244]     Train net output #0: loss = 0.0488074 (* 1 = 0.0488074 loss)
I0403 02:39:41.971912 16972 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:39:45.728258 16972 solver.cpp:228] Iteration 285, loss = 0.0600897
I0403 02:39:45.728358 16972 solver.cpp:244]     Train net output #0: loss = 0.0600897 (* 1 = 0.0600897 loss)
I0403 02:39:45.935153 16972 sgd_solver.cpp:106] Iteration 285, lr = 0.005
I0403 02:39:49.629834 16972 solver.cpp:228] Iteration 290, loss = 0.114022
I0403 02:39:49.629925 16972 solver.cpp:244]     Train net output #0: loss = 0.114022 (* 1 = 0.114022 loss)
I0403 02:39:49.825511 16972 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:39:53.513501 16972 solver.cpp:228] Iteration 295, loss = 0.0609389
I0403 02:39:53.513789 16972 solver.cpp:244]     Train net output #0: loss = 0.0609389 (* 1 = 0.0609389 loss)
I0403 02:39:53.716969 16972 sgd_solver.cpp:106] Iteration 295, lr = 0.005
I0403 02:39:57.336277 16972 solver.cpp:228] Iteration 300, loss = 0.0854509
I0403 02:39:57.336366 16972 solver.cpp:244]     Train net output #0: loss = 0.0854509 (* 1 = 0.0854509 loss)
I0403 02:39:57.515558 16972 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:40:01.348629 16972 solver.cpp:228] Iteration 305, loss = 0.0517961
I0403 02:40:01.348717 16972 solver.cpp:244]     Train net output #0: loss = 0.0517961 (* 1 = 0.0517961 loss)
I0403 02:40:01.534965 16972 sgd_solver.cpp:106] Iteration 305, lr = 0.005
I0403 02:40:05.246327 16972 solver.cpp:228] Iteration 310, loss = 0.0609197
I0403 02:40:05.246415 16972 solver.cpp:244]     Train net output #0: loss = 0.0609197 (* 1 = 0.0609197 loss)
I0403 02:40:05.418330 16972 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:40:09.084089 16972 solver.cpp:228] Iteration 315, loss = 0.0842333
I0403 02:40:09.084187 16972 solver.cpp:244]     Train net output #0: loss = 0.0842332 (* 1 = 0.0842332 loss)
I0403 02:40:09.317718 16972 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:40:12.932864 16972 solver.cpp:228] Iteration 320, loss = 0.0431888
I0403 02:40:12.932960 16972 solver.cpp:244]     Train net output #0: loss = 0.0431888 (* 1 = 0.0431888 loss)
I0403 02:40:13.143599 16972 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:40:15.439018 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_324.caffemodel
I0403 02:40:18.215749 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_324.solverstate
I0403 02:40:20.088719 16972 solver.cpp:337] Iteration 324, Testing net (#0)
I0403 02:42:01.151454 16972 solver.cpp:404]     Test net output #0: accuracy = 0.947605
I0403 02:42:01.158947 16972 solver.cpp:404]     Test net output #1: loss = 0.17804 (* 1 = 0.17804 loss)
I0403 02:42:02.471586 16972 solver.cpp:228] Iteration 325, loss = 0.0389718
I0403 02:42:02.476199 16972 solver.cpp:244]     Train net output #0: loss = 0.0389718 (* 1 = 0.0389718 loss)
I0403 02:42:02.647670 16972 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:42:06.396530 16972 solver.cpp:228] Iteration 330, loss = 0.0366763
I0403 02:42:06.402870 16972 solver.cpp:244]     Train net output #0: loss = 0.0366763 (* 1 = 0.0366763 loss)
I0403 02:42:06.591922 16972 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:42:10.203140 16972 solver.cpp:228] Iteration 335, loss = 0.0726501
I0403 02:42:10.208865 16972 solver.cpp:244]     Train net output #0: loss = 0.0726501 (* 1 = 0.0726501 loss)
I0403 02:42:10.400601 16972 sgd_solver.cpp:106] Iteration 335, lr = 0.005
I0403 02:42:14.096910 16972 solver.cpp:228] Iteration 340, loss = 0.0249947
I0403 02:42:14.103144 16972 solver.cpp:244]     Train net output #0: loss = 0.0249947 (* 1 = 0.0249947 loss)
I0403 02:42:14.291118 16972 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:42:17.975530 16972 solver.cpp:228] Iteration 345, loss = 0.137394
I0403 02:42:17.981989 16972 solver.cpp:244]     Train net output #0: loss = 0.137394 (* 1 = 0.137394 loss)
I0403 02:42:18.173977 16972 sgd_solver.cpp:106] Iteration 345, lr = 0.005
I0403 02:42:21.850087 16972 solver.cpp:228] Iteration 350, loss = 0.202079
I0403 02:42:21.855109 16972 solver.cpp:244]     Train net output #0: loss = 0.202079 (* 1 = 0.202079 loss)
I0403 02:42:22.054370 16972 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:42:25.727368 16972 solver.cpp:228] Iteration 355, loss = 0.116256
I0403 02:42:25.733088 16972 solver.cpp:244]     Train net output #0: loss = 0.116256 (* 1 = 0.116256 loss)
I0403 02:42:25.941149 16972 sgd_solver.cpp:106] Iteration 355, lr = 0.005
I0403 02:42:29.770895 16972 solver.cpp:228] Iteration 360, loss = 0.0736687
I0403 02:42:29.777444 16972 solver.cpp:244]     Train net output #0: loss = 0.0736687 (* 1 = 0.0736687 loss)
I0403 02:42:30.003942 16972 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:42:33.903662 16972 solver.cpp:228] Iteration 365, loss = 0.0358597
I0403 02:42:33.909901 16972 solver.cpp:244]     Train net output #0: loss = 0.0358597 (* 1 = 0.0358597 loss)
I0403 02:42:34.133515 16972 sgd_solver.cpp:106] Iteration 365, lr = 0.005
I0403 02:42:37.859973 16972 solver.cpp:228] Iteration 370, loss = 0.022712
I0403 02:42:37.864490 16972 solver.cpp:244]     Train net output #0: loss = 0.022712 (* 1 = 0.022712 loss)
I0403 02:42:38.063412 16972 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:42:41.678007 16972 solver.cpp:228] Iteration 375, loss = 0.0317935
I0403 02:42:41.683415 16972 solver.cpp:244]     Train net output #0: loss = 0.0317935 (* 1 = 0.0317935 loss)
I0403 02:42:41.890677 16972 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0403 02:42:45.530920 16972 solver.cpp:228] Iteration 380, loss = 0.0122688
I0403 02:42:45.537324 16972 solver.cpp:244]     Train net output #0: loss = 0.0122687 (* 1 = 0.0122687 loss)
I0403 02:42:45.740577 16972 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:42:49.383430 16972 solver.cpp:228] Iteration 385, loss = 0.069657
I0403 02:42:49.389621 16972 solver.cpp:244]     Train net output #0: loss = 0.069657 (* 1 = 0.069657 loss)
I0403 02:42:49.581552 16972 sgd_solver.cpp:106] Iteration 385, lr = 0.005
I0403 02:42:53.286005 16972 solver.cpp:228] Iteration 390, loss = 0.0784984
I0403 02:42:53.292768 16972 solver.cpp:244]     Train net output #0: loss = 0.0784984 (* 1 = 0.0784984 loss)
I0403 02:42:53.459630 16972 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:42:57.201257 16972 solver.cpp:228] Iteration 395, loss = 0.00993584
I0403 02:42:57.207475 16972 solver.cpp:244]     Train net output #0: loss = 0.00993582 (* 1 = 0.00993582 loss)
I0403 02:42:57.358439 16972 sgd_solver.cpp:106] Iteration 395, lr = 0.005
I0403 02:43:01.200255 16972 solver.cpp:228] Iteration 400, loss = 0.0822187
I0403 02:43:01.214334 16972 solver.cpp:244]     Train net output #0: loss = 0.0822187 (* 1 = 0.0822187 loss)
I0403 02:43:01.404594 16972 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:43:05.057471 16972 solver.cpp:228] Iteration 405, loss = 0.061147
I0403 02:43:05.063561 16972 solver.cpp:244]     Train net output #0: loss = 0.061147 (* 1 = 0.061147 loss)
I0403 02:43:05.244299 16972 sgd_solver.cpp:106] Iteration 405, lr = 0.005
I0403 02:43:08.958071 16972 solver.cpp:228] Iteration 410, loss = 0.0476618
I0403 02:43:08.964082 16972 solver.cpp:244]     Train net output #0: loss = 0.0476618 (* 1 = 0.0476618 loss)
I0403 02:43:09.151763 16972 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:43:12.830721 16972 solver.cpp:228] Iteration 415, loss = 0.0816658
I0403 02:43:12.835875 16972 solver.cpp:244]     Train net output #0: loss = 0.0816658 (* 1 = 0.0816658 loss)
I0403 02:43:13.004534 16972 sgd_solver.cpp:106] Iteration 415, lr = 0.005
I0403 02:43:16.718091 16972 solver.cpp:228] Iteration 420, loss = 0.00938377
I0403 02:43:16.724071 16972 solver.cpp:244]     Train net output #0: loss = 0.00938375 (* 1 = 0.00938375 loss)
I0403 02:43:16.909004 16972 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:43:20.603986 16972 solver.cpp:228] Iteration 425, loss = 0.0437035
I0403 02:43:20.610319 16972 solver.cpp:244]     Train net output #0: loss = 0.0437034 (* 1 = 0.0437034 loss)
I0403 02:43:20.807997 16972 sgd_solver.cpp:106] Iteration 425, lr = 0.005
I0403 02:43:24.476222 16972 solver.cpp:228] Iteration 430, loss = 0.0962954
I0403 02:43:24.482405 16972 solver.cpp:244]     Train net output #0: loss = 0.0962953 (* 1 = 0.0962953 loss)
I0403 02:43:24.664392 16972 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:43:25.453485 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_432.caffemodel
I0403 02:43:28.335274 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_432.solverstate
I0403 02:43:30.245065 16972 solver.cpp:337] Iteration 432, Testing net (#0)
I0403 02:45:11.328011 16972 solver.cpp:404]     Test net output #0: accuracy = 0.955577
I0403 02:45:11.335515 16972 solver.cpp:404]     Test net output #1: loss = 0.1598 (* 1 = 0.1598 loss)
I0403 02:45:14.262110 16972 solver.cpp:228] Iteration 435, loss = 0.072072
I0403 02:45:14.267509 16972 solver.cpp:244]     Train net output #0: loss = 0.0720719 (* 1 = 0.0720719 loss)
I0403 02:45:14.459554 16972 sgd_solver.cpp:106] Iteration 435, lr = 0.005
I0403 02:45:18.128274 16972 solver.cpp:228] Iteration 440, loss = 0.0117539
I0403 02:45:18.134033 16972 solver.cpp:244]     Train net output #0: loss = 0.0117538 (* 1 = 0.0117538 loss)
I0403 02:45:18.336182 16972 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:45:22.045248 16972 solver.cpp:228] Iteration 445, loss = 0.0814365
I0403 02:45:22.057641 16972 solver.cpp:244]     Train net output #0: loss = 0.0814365 (* 1 = 0.0814365 loss)
I0403 02:45:22.231216 16972 sgd_solver.cpp:106] Iteration 445, lr = 0.005
I0403 02:45:26.017843 16972 solver.cpp:228] Iteration 450, loss = 0.0506159
I0403 02:45:26.024649 16972 solver.cpp:244]     Train net output #0: loss = 0.0506159 (* 1 = 0.0506159 loss)
I0403 02:45:26.202941 16972 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:45:30.020978 16972 solver.cpp:228] Iteration 455, loss = 0.093354
I0403 02:45:30.026737 16972 solver.cpp:244]     Train net output #0: loss = 0.093354 (* 1 = 0.093354 loss)
I0403 02:45:30.214026 16972 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:45:33.907933 16972 solver.cpp:228] Iteration 460, loss = 0.0307873
I0403 02:45:33.914496 16972 solver.cpp:244]     Train net output #0: loss = 0.0307873 (* 1 = 0.0307873 loss)
I0403 02:45:34.103199 16972 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:45:37.719411 16972 solver.cpp:228] Iteration 465, loss = 0.0500989
I0403 02:45:37.725225 16972 solver.cpp:244]     Train net output #0: loss = 0.0500989 (* 1 = 0.0500989 loss)
I0403 02:45:37.929844 16972 sgd_solver.cpp:106] Iteration 465, lr = 0.005
I0403 02:45:41.597471 16972 solver.cpp:228] Iteration 470, loss = 0.0209275
I0403 02:45:41.604063 16972 solver.cpp:244]     Train net output #0: loss = 0.0209274 (* 1 = 0.0209274 loss)
I0403 02:45:41.801172 16972 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:45:45.420671 16972 solver.cpp:228] Iteration 475, loss = 0.049774
I0403 02:45:45.427316 16972 solver.cpp:244]     Train net output #0: loss = 0.049774 (* 1 = 0.049774 loss)
I0403 02:45:45.611232 16972 sgd_solver.cpp:106] Iteration 475, lr = 0.005
I0403 02:45:49.249902 16972 solver.cpp:228] Iteration 480, loss = 0.0476565
I0403 02:45:49.256707 16972 solver.cpp:244]     Train net output #0: loss = 0.0476565 (* 1 = 0.0476565 loss)
I0403 02:45:49.454874 16972 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:45:53.203416 16972 solver.cpp:228] Iteration 485, loss = 0.010219
I0403 02:45:53.208796 16972 solver.cpp:244]     Train net output #0: loss = 0.010219 (* 1 = 0.010219 loss)
I0403 02:45:53.375871 16972 sgd_solver.cpp:106] Iteration 485, lr = 0.005
I0403 02:45:57.071773 16972 solver.cpp:228] Iteration 490, loss = 0.0271583
I0403 02:45:57.077126 16972 solver.cpp:244]     Train net output #0: loss = 0.0271583 (* 1 = 0.0271583 loss)
I0403 02:45:57.264614 16972 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:46:00.922397 16972 solver.cpp:228] Iteration 495, loss = 0.0280411
I0403 02:46:00.929147 16972 solver.cpp:244]     Train net output #0: loss = 0.028041 (* 1 = 0.028041 loss)
I0403 02:46:01.100695 16972 sgd_solver.cpp:106] Iteration 495, lr = 0.005
I0403 02:46:04.876636 16972 solver.cpp:228] Iteration 500, loss = 0.0981274
I0403 02:46:04.882086 16972 solver.cpp:244]     Train net output #0: loss = 0.0981274 (* 1 = 0.0981274 loss)
I0403 02:46:05.062388 16972 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:46:08.835532 16972 solver.cpp:228] Iteration 505, loss = 0.0972627
I0403 02:46:08.839751 16972 solver.cpp:244]     Train net output #0: loss = 0.0972627 (* 1 = 0.0972627 loss)
I0403 02:46:09.015038 16972 sgd_solver.cpp:106] Iteration 505, lr = 0.005
I0403 02:46:12.844383 16972 solver.cpp:228] Iteration 510, loss = 0.0317303
I0403 02:46:12.850564 16972 solver.cpp:244]     Train net output #0: loss = 0.0317302 (* 1 = 0.0317302 loss)
I0403 02:46:13.065062 16972 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:46:16.712920 16972 solver.cpp:228] Iteration 515, loss = 0.00842341
I0403 02:46:16.719291 16972 solver.cpp:244]     Train net output #0: loss = 0.00842336 (* 1 = 0.00842336 loss)
I0403 02:46:16.923895 16972 sgd_solver.cpp:106] Iteration 515, lr = 0.005
I0403 02:46:20.602794 16972 solver.cpp:228] Iteration 520, loss = 0.0429608
I0403 02:46:20.608829 16972 solver.cpp:244]     Train net output #0: loss = 0.0429607 (* 1 = 0.0429607 loss)
I0403 02:46:20.783607 16972 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:46:24.478482 16972 solver.cpp:228] Iteration 525, loss = 0.00637239
I0403 02:46:24.485422 16972 solver.cpp:244]     Train net output #0: loss = 0.00637234 (* 1 = 0.00637234 loss)
I0403 02:46:24.691526 16972 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:46:28.284800 16972 solver.cpp:228] Iteration 530, loss = 0.116775
I0403 02:46:28.291266 16972 solver.cpp:244]     Train net output #0: loss = 0.116775 (* 1 = 0.116775 loss)
I0403 02:46:28.481230 16972 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:46:32.138450 16972 solver.cpp:228] Iteration 535, loss = 0.0241371
I0403 02:46:32.145117 16972 solver.cpp:244]     Train net output #0: loss = 0.0241371 (* 1 = 0.0241371 loss)
I0403 02:46:32.310956 16972 sgd_solver.cpp:106] Iteration 535, lr = 0.005
I0403 02:46:35.492521 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_540.caffemodel
I0403 02:46:38.247505 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_540.solverstate
I0403 02:46:40.137039 16972 solver.cpp:337] Iteration 540, Testing net (#0)
I0403 02:48:21.163651 16972 solver.cpp:404]     Test net output #0: accuracy = 0.956729
I0403 02:48:21.170227 16972 solver.cpp:404]     Test net output #1: loss = 0.161681 (* 1 = 0.161681 loss)
I0403 02:48:21.732781 16972 solver.cpp:228] Iteration 540, loss = 0.0511659
I0403 02:48:21.738586 16972 solver.cpp:244]     Train net output #0: loss = 0.0511658 (* 1 = 0.0511658 loss)
I0403 02:48:21.894618 16972 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:48:25.723410 16972 solver.cpp:228] Iteration 545, loss = 0.0452974
I0403 02:48:25.728582 16972 solver.cpp:244]     Train net output #0: loss = 0.0452974 (* 1 = 0.0452974 loss)
I0403 02:48:25.912611 16972 sgd_solver.cpp:106] Iteration 545, lr = 0.005
I0403 02:48:29.575860 16972 solver.cpp:228] Iteration 550, loss = 0.0133142
I0403 02:48:29.581676 16972 solver.cpp:244]     Train net output #0: loss = 0.0133142 (* 1 = 0.0133142 loss)
I0403 02:48:29.782918 16972 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:48:33.540210 16972 solver.cpp:228] Iteration 555, loss = 0.0427728
I0403 02:48:33.546346 16972 solver.cpp:244]     Train net output #0: loss = 0.0427727 (* 1 = 0.0427727 loss)
I0403 02:48:33.776742 16972 sgd_solver.cpp:106] Iteration 555, lr = 0.005
I0403 02:48:37.392309 16972 solver.cpp:228] Iteration 560, loss = 0.0323368
I0403 02:48:37.398476 16972 solver.cpp:244]     Train net output #0: loss = 0.0323368 (* 1 = 0.0323368 loss)
I0403 02:48:37.592316 16972 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:48:41.188547 16972 solver.cpp:228] Iteration 565, loss = 0.0279747
I0403 02:48:41.195036 16972 solver.cpp:244]     Train net output #0: loss = 0.0279746 (* 1 = 0.0279746 loss)
I0403 02:48:41.397919 16972 sgd_solver.cpp:106] Iteration 565, lr = 0.005
I0403 02:48:45.026880 16972 solver.cpp:228] Iteration 570, loss = 0.0360603
I0403 02:48:45.032452 16972 solver.cpp:244]     Train net output #0: loss = 0.0360603 (* 1 = 0.0360603 loss)
I0403 02:48:45.208173 16972 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:48:48.932140 16972 solver.cpp:228] Iteration 575, loss = 0.0076418
I0403 02:48:48.938489 16972 solver.cpp:244]     Train net output #0: loss = 0.00764174 (* 1 = 0.00764174 loss)
I0403 02:48:49.111189 16972 sgd_solver.cpp:106] Iteration 575, lr = 0.005
I0403 02:48:52.797493 16972 solver.cpp:228] Iteration 580, loss = 0.0815395
I0403 02:48:52.803498 16972 solver.cpp:244]     Train net output #0: loss = 0.0815394 (* 1 = 0.0815394 loss)
I0403 02:48:53.027137 16972 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:48:56.695112 16972 solver.cpp:228] Iteration 585, loss = 0.069737
I0403 02:48:56.701180 16972 solver.cpp:244]     Train net output #0: loss = 0.0697369 (* 1 = 0.0697369 loss)
I0403 02:48:56.918297 16972 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:49:00.596519 16972 solver.cpp:228] Iteration 590, loss = 0.0180501
I0403 02:49:00.601095 16972 solver.cpp:244]     Train net output #0: loss = 0.0180501 (* 1 = 0.0180501 loss)
I0403 02:49:00.797744 16972 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:49:04.455358 16972 solver.cpp:228] Iteration 595, loss = 0.0534765
I0403 02:49:04.461769 16972 solver.cpp:244]     Train net output #0: loss = 0.0534765 (* 1 = 0.0534765 loss)
I0403 02:49:04.647397 16972 sgd_solver.cpp:106] Iteration 595, lr = 0.005
I0403 02:49:08.313127 16972 solver.cpp:228] Iteration 600, loss = 0.0392269
I0403 02:49:08.319309 16972 solver.cpp:244]     Train net output #0: loss = 0.0392269 (* 1 = 0.0392269 loss)
I0403 02:49:08.505048 16972 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:49:12.172791 16972 solver.cpp:228] Iteration 605, loss = 0.0416111
I0403 02:49:12.177119 16972 solver.cpp:244]     Train net output #0: loss = 0.0416111 (* 1 = 0.0416111 loss)
I0403 02:49:12.370908 16972 sgd_solver.cpp:106] Iteration 605, lr = 0.005
I0403 02:49:16.027911 16972 solver.cpp:228] Iteration 610, loss = 0.029122
I0403 02:49:16.033517 16972 solver.cpp:244]     Train net output #0: loss = 0.0291219 (* 1 = 0.0291219 loss)
I0403 02:49:16.220075 16972 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:49:19.930605 16972 solver.cpp:228] Iteration 615, loss = 0.031991
I0403 02:49:19.936580 16972 solver.cpp:244]     Train net output #0: loss = 0.031991 (* 1 = 0.031991 loss)
I0403 02:49:20.103284 16972 sgd_solver.cpp:106] Iteration 615, lr = 0.005
I0403 02:49:23.820338 16972 solver.cpp:228] Iteration 620, loss = 0.00298266
I0403 02:49:23.825872 16972 solver.cpp:244]     Train net output #0: loss = 0.0029826 (* 1 = 0.0029826 loss)
I0403 02:49:24.006288 16972 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:49:27.730242 16972 solver.cpp:228] Iteration 625, loss = 0.00484908
I0403 02:49:27.736181 16972 solver.cpp:244]     Train net output #0: loss = 0.00484902 (* 1 = 0.00484902 loss)
I0403 02:49:27.939018 16972 sgd_solver.cpp:106] Iteration 625, lr = 0.005
I0403 02:49:31.556131 16972 solver.cpp:228] Iteration 630, loss = 0.0281155
I0403 02:49:31.562659 16972 solver.cpp:244]     Train net output #0: loss = 0.0281155 (* 1 = 0.0281155 loss)
I0403 02:49:31.757719 16972 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:49:35.533921 16972 solver.cpp:228] Iteration 635, loss = 0.0449374
I0403 02:49:35.635449 16972 solver.cpp:244]     Train net output #0: loss = 0.0449373 (* 1 = 0.0449373 loss)
I0403 02:49:35.707731 16972 sgd_solver.cpp:106] Iteration 635, lr = 0.005
I0403 02:49:39.460369 16972 solver.cpp:228] Iteration 640, loss = 0.0336964
I0403 02:49:39.467021 16972 solver.cpp:244]     Train net output #0: loss = 0.0336963 (* 1 = 0.0336963 loss)
I0403 02:49:39.661933 16972 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:49:43.290670 16972 solver.cpp:228] Iteration 645, loss = 0.0503729
I0403 02:49:43.296622 16972 solver.cpp:244]     Train net output #0: loss = 0.0503729 (* 1 = 0.0503729 loss)
I0403 02:49:43.483836 16972 sgd_solver.cpp:106] Iteration 645, lr = 0.005
I0403 02:49:45.035004 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_648.caffemodel
I0403 02:49:47.909551 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_648.solverstate
I0403 02:49:49.800382 16972 solver.cpp:337] Iteration 648, Testing net (#0)
I0403 02:51:30.840118 16972 solver.cpp:404]     Test net output #0: accuracy = 0.952973
I0403 02:51:30.851933 16972 solver.cpp:404]     Test net output #1: loss = 0.175271 (* 1 = 0.175271 loss)
I0403 02:51:32.960880 16972 solver.cpp:228] Iteration 650, loss = 0.0116072
I0403 02:51:32.967228 16972 solver.cpp:244]     Train net output #0: loss = 0.0116071 (* 1 = 0.0116071 loss)
I0403 02:51:33.151577 16972 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:51:36.906347 16972 solver.cpp:228] Iteration 655, loss = 0.00890366
I0403 02:51:36.911793 16972 solver.cpp:244]     Train net output #0: loss = 0.0089036 (* 1 = 0.0089036 loss)
I0403 02:51:37.079648 16972 sgd_solver.cpp:106] Iteration 655, lr = 0.005
I0403 02:51:40.790480 16972 solver.cpp:228] Iteration 660, loss = 0.019829
I0403 02:51:40.797219 16972 solver.cpp:244]     Train net output #0: loss = 0.0198289 (* 1 = 0.0198289 loss)
I0403 02:51:40.997619 16972 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:51:44.656177 16972 solver.cpp:228] Iteration 665, loss = 0.0781726
I0403 02:51:44.662706 16972 solver.cpp:244]     Train net output #0: loss = 0.0781726 (* 1 = 0.0781726 loss)
I0403 02:51:44.850240 16972 sgd_solver.cpp:106] Iteration 665, lr = 0.005
I0403 02:51:48.488591 16972 solver.cpp:228] Iteration 670, loss = 0.0456994
I0403 02:51:48.496655 16972 solver.cpp:244]     Train net output #0: loss = 0.0456993 (* 1 = 0.0456993 loss)
I0403 02:51:48.681202 16972 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:51:52.357151 16972 solver.cpp:228] Iteration 675, loss = 0.00429557
I0403 02:51:52.362401 16972 solver.cpp:244]     Train net output #0: loss = 0.00429551 (* 1 = 0.00429551 loss)
I0403 02:51:52.581274 16972 sgd_solver.cpp:106] Iteration 675, lr = 0.005
I0403 02:51:56.370151 16972 solver.cpp:228] Iteration 680, loss = 0.00603857
I0403 02:51:56.376436 16972 solver.cpp:244]     Train net output #0: loss = 0.00603852 (* 1 = 0.00603852 loss)
I0403 02:51:56.563995 16972 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:52:00.212199 16972 solver.cpp:228] Iteration 685, loss = 0.00908482
I0403 02:52:00.218129 16972 solver.cpp:244]     Train net output #0: loss = 0.00908476 (* 1 = 0.00908476 loss)
I0403 02:52:00.401331 16972 sgd_solver.cpp:106] Iteration 685, lr = 0.005
I0403 02:52:04.059448 16972 solver.cpp:228] Iteration 690, loss = 0.00806091
I0403 02:52:04.066401 16972 solver.cpp:244]     Train net output #0: loss = 0.00806086 (* 1 = 0.00806086 loss)
I0403 02:52:04.247195 16972 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:52:08.006948 16972 solver.cpp:228] Iteration 695, loss = 0.0159565
I0403 02:52:08.013402 16972 solver.cpp:244]     Train net output #0: loss = 0.0159564 (* 1 = 0.0159564 loss)
I0403 02:52:08.200873 16972 sgd_solver.cpp:106] Iteration 695, lr = 0.005
I0403 02:52:11.860580 16972 solver.cpp:228] Iteration 700, loss = 0.0171532
I0403 02:52:11.867311 16972 solver.cpp:244]     Train net output #0: loss = 0.0171531 (* 1 = 0.0171531 loss)
I0403 02:52:12.033855 16972 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:52:16.076406 16972 solver.cpp:228] Iteration 705, loss = 0.00499998
I0403 02:52:16.083057 16972 solver.cpp:244]     Train net output #0: loss = 0.00499993 (* 1 = 0.00499993 loss)
I0403 02:52:16.271661 16972 sgd_solver.cpp:106] Iteration 705, lr = 0.005
I0403 02:52:19.967615 16972 solver.cpp:228] Iteration 710, loss = 0.027598
I0403 02:52:19.974222 16972 solver.cpp:244]     Train net output #0: loss = 0.027598 (* 1 = 0.027598 loss)
I0403 02:52:20.187993 16972 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:52:24.050999 16972 solver.cpp:228] Iteration 715, loss = 0.0174508
I0403 02:52:24.058315 16972 solver.cpp:244]     Train net output #0: loss = 0.0174508 (* 1 = 0.0174508 loss)
I0403 02:52:24.272608 16972 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:52:27.831742 16972 solver.cpp:228] Iteration 720, loss = 0.0136801
I0403 02:52:27.837884 16972 solver.cpp:244]     Train net output #0: loss = 0.01368 (* 1 = 0.01368 loss)
I0403 02:52:28.027194 16972 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:52:31.672816 16972 solver.cpp:228] Iteration 725, loss = 0.041098
I0403 02:52:31.679512 16972 solver.cpp:244]     Train net output #0: loss = 0.041098 (* 1 = 0.041098 loss)
I0403 02:52:31.886078 16972 sgd_solver.cpp:106] Iteration 725, lr = 0.005
I0403 02:52:35.546269 16972 solver.cpp:228] Iteration 730, loss = 0.037116
I0403 02:52:35.553261 16972 solver.cpp:244]     Train net output #0: loss = 0.037116 (* 1 = 0.037116 loss)
I0403 02:52:35.744562 16972 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:52:39.420837 16972 solver.cpp:228] Iteration 735, loss = 0.00115202
I0403 02:52:39.427393 16972 solver.cpp:244]     Train net output #0: loss = 0.00115197 (* 1 = 0.00115197 loss)
I0403 02:52:39.670210 16972 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:52:43.497262 16972 solver.cpp:228] Iteration 740, loss = 0.00915538
I0403 02:52:43.503523 16972 solver.cpp:244]     Train net output #0: loss = 0.00915533 (* 1 = 0.00915533 loss)
I0403 02:52:43.673283 16972 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:52:47.400467 16972 solver.cpp:228] Iteration 745, loss = 0.0292264
I0403 02:52:47.407378 16972 solver.cpp:244]     Train net output #0: loss = 0.0292264 (* 1 = 0.0292264 loss)
I0403 02:52:47.593019 16972 sgd_solver.cpp:106] Iteration 745, lr = 0.005
I0403 02:52:51.280077 16972 solver.cpp:228] Iteration 750, loss = 0.046235
I0403 02:52:51.286022 16972 solver.cpp:244]     Train net output #0: loss = 0.0462349 (* 1 = 0.0462349 loss)
I0403 02:52:51.453738 16972 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:52:55.153553 16972 solver.cpp:228] Iteration 755, loss = 0.0556978
I0403 02:52:55.160328 16972 solver.cpp:244]     Train net output #0: loss = 0.0556978 (* 1 = 0.0556978 loss)
I0403 02:52:55.364799 16972 sgd_solver.cpp:106] Iteration 755, lr = 0.005
I0403 02:52:55.371726 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_756.caffemodel
I0403 02:52:58.052126 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_756.solverstate
I0403 02:52:59.873302 16972 solver.cpp:337] Iteration 756, Testing net (#0)
I0403 02:54:40.955216 16972 solver.cpp:404]     Test net output #0: accuracy = 0.962789
I0403 02:54:40.962254 16972 solver.cpp:404]     Test net output #1: loss = 0.152021 (* 1 = 0.152021 loss)
I0403 02:54:44.579213 16972 solver.cpp:228] Iteration 760, loss = 0.013861
I0403 02:54:44.585297 16972 solver.cpp:244]     Train net output #0: loss = 0.0138609 (* 1 = 0.0138609 loss)
I0403 02:54:44.771445 16972 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:54:48.523471 16972 solver.cpp:228] Iteration 765, loss = 0.00647309
I0403 02:54:48.530067 16972 solver.cpp:244]     Train net output #0: loss = 0.00647304 (* 1 = 0.00647304 loss)
I0403 02:54:48.753573 16972 sgd_solver.cpp:106] Iteration 765, lr = 0.005
I0403 02:54:52.446846 16972 solver.cpp:228] Iteration 770, loss = 0.0074619
I0403 02:54:52.455052 16972 solver.cpp:244]     Train net output #0: loss = 0.00746185 (* 1 = 0.00746185 loss)
I0403 02:54:52.605552 16972 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:54:56.395277 16972 solver.cpp:228] Iteration 775, loss = 0.0323936
I0403 02:54:56.401424 16972 solver.cpp:244]     Train net output #0: loss = 0.0323936 (* 1 = 0.0323936 loss)
I0403 02:54:56.628326 16972 sgd_solver.cpp:106] Iteration 775, lr = 0.005
I0403 02:55:00.278192 16972 solver.cpp:228] Iteration 780, loss = 0.0624997
I0403 02:55:00.284286 16972 solver.cpp:244]     Train net output #0: loss = 0.0624997 (* 1 = 0.0624997 loss)
I0403 02:55:00.455780 16972 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:55:04.187894 16972 solver.cpp:228] Iteration 785, loss = 0.0105978
I0403 02:55:04.193650 16972 solver.cpp:244]     Train net output #0: loss = 0.0105977 (* 1 = 0.0105977 loss)
I0403 02:55:04.383929 16972 sgd_solver.cpp:106] Iteration 785, lr = 0.005
I0403 02:55:08.106456 16972 solver.cpp:228] Iteration 790, loss = 0.00569281
I0403 02:55:08.132845 16972 solver.cpp:244]     Train net output #0: loss = 0.00569277 (* 1 = 0.00569277 loss)
I0403 02:55:08.315140 16972 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:55:11.925997 16972 solver.cpp:228] Iteration 795, loss = 0.0103268
I0403 02:55:11.932490 16972 solver.cpp:244]     Train net output #0: loss = 0.0103267 (* 1 = 0.0103267 loss)
I0403 02:55:12.121026 16972 sgd_solver.cpp:106] Iteration 795, lr = 0.005
I0403 02:55:15.970307 16972 solver.cpp:228] Iteration 800, loss = 0.0708596
I0403 02:55:15.977033 16972 solver.cpp:244]     Train net output #0: loss = 0.0708595 (* 1 = 0.0708595 loss)
I0403 02:55:16.177862 16972 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:55:19.801648 16972 solver.cpp:228] Iteration 805, loss = 0.0248829
I0403 02:55:19.808315 16972 solver.cpp:244]     Train net output #0: loss = 0.0248828 (* 1 = 0.0248828 loss)
I0403 02:55:20.028405 16972 sgd_solver.cpp:106] Iteration 805, lr = 0.005
I0403 02:55:23.799235 16972 solver.cpp:228] Iteration 810, loss = 0.0222254
I0403 02:55:23.804725 16972 solver.cpp:244]     Train net output #0: loss = 0.0222253 (* 1 = 0.0222253 loss)
I0403 02:55:24.008988 16972 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:55:27.707396 16972 solver.cpp:228] Iteration 815, loss = 0.0303488
I0403 02:55:27.713809 16972 solver.cpp:244]     Train net output #0: loss = 0.0303487 (* 1 = 0.0303487 loss)
I0403 02:55:27.924841 16972 sgd_solver.cpp:106] Iteration 815, lr = 0.005
I0403 02:55:31.557266 16972 solver.cpp:228] Iteration 820, loss = 0.00836378
I0403 02:55:31.564004 16972 solver.cpp:244]     Train net output #0: loss = 0.00836373 (* 1 = 0.00836373 loss)
I0403 02:55:31.751754 16972 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:55:35.489591 16972 solver.cpp:228] Iteration 825, loss = 0.0103525
I0403 02:55:35.496389 16972 solver.cpp:244]     Train net output #0: loss = 0.0103524 (* 1 = 0.0103524 loss)
I0403 02:55:35.670060 16972 sgd_solver.cpp:106] Iteration 825, lr = 0.005
I0403 02:55:39.399844 16972 solver.cpp:228] Iteration 830, loss = 0.0065251
I0403 02:55:39.406429 16972 solver.cpp:244]     Train net output #0: loss = 0.00652504 (* 1 = 0.00652504 loss)
I0403 02:55:39.557582 16972 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:55:43.286109 16972 solver.cpp:228] Iteration 835, loss = 0.00542533
I0403 02:55:43.292980 16972 solver.cpp:244]     Train net output #0: loss = 0.00542528 (* 1 = 0.00542528 loss)
I0403 02:55:43.480589 16972 sgd_solver.cpp:106] Iteration 835, lr = 0.005
I0403 02:55:47.107107 16972 solver.cpp:228] Iteration 840, loss = 0.00831131
I0403 02:55:47.114718 16972 solver.cpp:244]     Train net output #0: loss = 0.00831126 (* 1 = 0.00831126 loss)
I0403 02:55:47.302602 16972 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:55:50.956387 16972 solver.cpp:228] Iteration 845, loss = 0.0229734
I0403 02:55:50.962633 16972 solver.cpp:244]     Train net output #0: loss = 0.0229734 (* 1 = 0.0229734 loss)
I0403 02:55:51.162266 16972 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:55:54.811758 16972 solver.cpp:228] Iteration 850, loss = 0.0036679
I0403 02:55:54.819197 16972 solver.cpp:244]     Train net output #0: loss = 0.00366784 (* 1 = 0.00366784 loss)
I0403 02:55:55.007218 16972 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:55:58.627521 16972 solver.cpp:228] Iteration 855, loss = 0.0113841
I0403 02:55:58.634513 16972 solver.cpp:244]     Train net output #0: loss = 0.011384 (* 1 = 0.011384 loss)
I0403 02:55:58.826115 16972 sgd_solver.cpp:106] Iteration 855, lr = 0.005
I0403 02:56:02.497956 16972 solver.cpp:228] Iteration 860, loss = 0.0200852
I0403 02:56:02.504344 16972 solver.cpp:244]     Train net output #0: loss = 0.0200851 (* 1 = 0.0200851 loss)
I0403 02:56:02.685932 16972 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:56:05.002454 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_864.caffemodel
I0403 02:56:07.792678 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_864.solverstate
I0403 02:56:09.689860 16972 solver.cpp:337] Iteration 864, Testing net (#0)
I0403 02:57:50.738836 16972 solver.cpp:404]     Test net output #0: accuracy = 0.955162
I0403 02:57:50.745779 16972 solver.cpp:404]     Test net output #1: loss = 0.170751 (* 1 = 0.170751 loss)
I0403 02:57:52.131449 16972 solver.cpp:228] Iteration 865, loss = 0.0323692
I0403 02:57:52.138173 16972 solver.cpp:244]     Train net output #0: loss = 0.0323691 (* 1 = 0.0323691 loss)
I0403 02:57:52.312485 16972 sgd_solver.cpp:106] Iteration 865, lr = 0.005
I0403 02:57:55.967795 16972 solver.cpp:228] Iteration 870, loss = 0.0170346
I0403 02:57:55.973985 16972 solver.cpp:244]     Train net output #0: loss = 0.0170345 (* 1 = 0.0170345 loss)
I0403 02:57:56.141500 16972 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:57:59.873601 16972 solver.cpp:228] Iteration 875, loss = 0.00977903
I0403 02:57:59.880043 16972 solver.cpp:244]     Train net output #0: loss = 0.00977898 (* 1 = 0.00977898 loss)
I0403 02:58:00.080521 16972 sgd_solver.cpp:106] Iteration 875, lr = 0.005
I0403 02:58:03.775684 16972 solver.cpp:228] Iteration 880, loss = 0.0116598
I0403 02:58:03.780902 16972 solver.cpp:244]     Train net output #0: loss = 0.0116597 (* 1 = 0.0116597 loss)
I0403 02:58:03.958117 16972 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:58:07.686336 16972 solver.cpp:228] Iteration 885, loss = 0.0020373
I0403 02:58:07.692929 16972 solver.cpp:244]     Train net output #0: loss = 0.00203725 (* 1 = 0.00203725 loss)
I0403 02:58:07.880728 16972 sgd_solver.cpp:106] Iteration 885, lr = 0.005
I0403 02:58:11.570441 16972 solver.cpp:228] Iteration 890, loss = 0.0119361
I0403 02:58:11.577488 16972 solver.cpp:244]     Train net output #0: loss = 0.011936 (* 1 = 0.011936 loss)
I0403 02:58:11.764245 16972 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:58:15.439774 16972 solver.cpp:228] Iteration 895, loss = 0.00250015
I0403 02:58:15.450870 16972 solver.cpp:244]     Train net output #0: loss = 0.0025001 (* 1 = 0.0025001 loss)
I0403 02:58:15.664507 16972 sgd_solver.cpp:106] Iteration 895, lr = 0.005
I0403 02:58:19.318764 16972 solver.cpp:228] Iteration 900, loss = 0.00977018
I0403 02:58:19.325536 16972 solver.cpp:244]     Train net output #0: loss = 0.00977013 (* 1 = 0.00977013 loss)
I0403 02:58:19.502822 16972 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:58:23.231798 16972 solver.cpp:228] Iteration 905, loss = 0.013605
I0403 02:58:23.237450 16972 solver.cpp:244]     Train net output #0: loss = 0.013605 (* 1 = 0.013605 loss)
I0403 02:58:23.419459 16972 sgd_solver.cpp:106] Iteration 905, lr = 0.005
I0403 02:58:27.233734 16972 solver.cpp:228] Iteration 910, loss = 0.0122178
I0403 02:58:27.240505 16972 solver.cpp:244]     Train net output #0: loss = 0.0122177 (* 1 = 0.0122177 loss)
I0403 02:58:27.461509 16972 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:58:31.163542 16972 solver.cpp:228] Iteration 915, loss = 0.0235521
I0403 02:58:31.169040 16972 solver.cpp:244]     Train net output #0: loss = 0.0235521 (* 1 = 0.0235521 loss)
I0403 02:58:31.297155 16972 sgd_solver.cpp:106] Iteration 915, lr = 0.005
I0403 02:58:35.306151 16972 solver.cpp:228] Iteration 920, loss = 0.0064009
I0403 02:58:35.311528 16972 solver.cpp:244]     Train net output #0: loss = 0.00640086 (* 1 = 0.00640086 loss)
I0403 02:58:35.485242 16972 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:58:39.341433 16972 solver.cpp:228] Iteration 925, loss = 0.0485248
I0403 02:58:39.347033 16972 solver.cpp:244]     Train net output #0: loss = 0.0485248 (* 1 = 0.0485248 loss)
I0403 02:58:39.550427 16972 sgd_solver.cpp:106] Iteration 925, lr = 0.005
I0403 02:58:43.323964 16972 solver.cpp:228] Iteration 930, loss = 0.0346088
I0403 02:58:43.331349 16972 solver.cpp:244]     Train net output #0: loss = 0.0346087 (* 1 = 0.0346087 loss)
I0403 02:58:43.449349 16972 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:58:47.375850 16972 solver.cpp:228] Iteration 935, loss = 0.0133585
I0403 02:58:47.382982 16972 solver.cpp:244]     Train net output #0: loss = 0.0133585 (* 1 = 0.0133585 loss)
I0403 02:58:47.569921 16972 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0403 02:58:51.232959 16972 solver.cpp:228] Iteration 940, loss = 0.0315003
I0403 02:58:51.239348 16972 solver.cpp:244]     Train net output #0: loss = 0.0315003 (* 1 = 0.0315003 loss)
I0403 02:58:51.404829 16972 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:58:55.101547 16972 solver.cpp:228] Iteration 945, loss = 0.0386254
I0403 02:58:55.108096 16972 solver.cpp:244]     Train net output #0: loss = 0.0386253 (* 1 = 0.0386253 loss)
I0403 02:58:55.303652 16972 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:58:58.946630 16972 solver.cpp:228] Iteration 950, loss = 0.0121764
I0403 02:58:58.952533 16972 solver.cpp:244]     Train net output #0: loss = 0.0121763 (* 1 = 0.0121763 loss)
I0403 02:58:59.140888 16972 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:59:02.739768 16972 solver.cpp:228] Iteration 955, loss = 0.00933587
I0403 02:59:02.746960 16972 solver.cpp:244]     Train net output #0: loss = 0.00933582 (* 1 = 0.00933582 loss)
I0403 02:59:02.990849 16972 sgd_solver.cpp:106] Iteration 955, lr = 0.005
I0403 02:59:06.628872 16972 solver.cpp:228] Iteration 960, loss = 0.00784232
I0403 02:59:06.634497 16972 solver.cpp:244]     Train net output #0: loss = 0.00784227 (* 1 = 0.00784227 loss)
I0403 02:59:06.835713 16972 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:59:10.526908 16972 solver.cpp:228] Iteration 965, loss = 0.0101694
I0403 02:59:10.533038 16972 solver.cpp:244]     Train net output #0: loss = 0.0101693 (* 1 = 0.0101693 loss)
I0403 02:59:10.721335 16972 sgd_solver.cpp:106] Iteration 965, lr = 0.005
I0403 02:59:14.376526 16972 solver.cpp:228] Iteration 970, loss = 0.0120589
I0403 02:59:14.382858 16972 solver.cpp:244]     Train net output #0: loss = 0.0120589 (* 1 = 0.0120589 loss)
I0403 02:59:14.608049 16972 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:59:15.352504 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_972.caffemodel
I0403 02:59:18.170728 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_972.solverstate
I0403 02:59:19.970293 16972 solver.cpp:337] Iteration 972, Testing net (#0)
I0403 03:01:01.043438 16972 solver.cpp:404]     Test net output #0: accuracy = 0.959978
I0403 03:01:01.049568 16972 solver.cpp:404]     Test net output #1: loss = 0.14431 (* 1 = 0.14431 loss)
I0403 03:01:04.003938 16972 solver.cpp:228] Iteration 975, loss = 0.00736013
I0403 03:01:04.010864 16972 solver.cpp:244]     Train net output #0: loss = 0.00736009 (* 1 = 0.00736009 loss)
I0403 03:01:04.231137 16972 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 03:01:07.893234 16972 solver.cpp:228] Iteration 980, loss = 0.0644391
I0403 03:01:07.900632 16972 solver.cpp:244]     Train net output #0: loss = 0.0644391 (* 1 = 0.0644391 loss)
I0403 03:01:08.101397 16972 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 03:01:11.721882 16972 solver.cpp:228] Iteration 985, loss = 0.00410429
I0403 03:01:11.727911 16972 solver.cpp:244]     Train net output #0: loss = 0.00410425 (* 1 = 0.00410425 loss)
I0403 03:01:11.944592 16972 sgd_solver.cpp:106] Iteration 985, lr = 0.005
I0403 03:01:15.615660 16972 solver.cpp:228] Iteration 990, loss = 0.0115647
I0403 03:01:15.622519 16972 solver.cpp:244]     Train net output #0: loss = 0.0115647 (* 1 = 0.0115647 loss)
I0403 03:01:15.811653 16972 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 03:01:19.505775 16972 solver.cpp:228] Iteration 995, loss = 0.00799508
I0403 03:01:19.511915 16972 solver.cpp:244]     Train net output #0: loss = 0.00799504 (* 1 = 0.00799504 loss)
I0403 03:01:19.686610 16972 sgd_solver.cpp:106] Iteration 995, lr = 0.005
I0403 03:01:23.369339 16972 solver.cpp:228] Iteration 1000, loss = 0.0363581
I0403 03:01:23.376325 16972 solver.cpp:244]     Train net output #0: loss = 0.0363581 (* 1 = 0.0363581 loss)
I0403 03:01:23.597152 16972 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 03:01:27.209568 16972 solver.cpp:228] Iteration 1005, loss = 0.0100593
I0403 03:01:27.216750 16972 solver.cpp:244]     Train net output #0: loss = 0.0100592 (* 1 = 0.0100592 loss)
I0403 03:01:27.384532 16972 sgd_solver.cpp:106] Iteration 1005, lr = 0.005
I0403 03:01:31.155735 16972 solver.cpp:228] Iteration 1010, loss = 0.0389105
I0403 03:01:31.161568 16972 solver.cpp:244]     Train net output #0: loss = 0.0389105 (* 1 = 0.0389105 loss)
I0403 03:01:31.351475 16972 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 03:01:35.067334 16972 solver.cpp:228] Iteration 1015, loss = 0.0164735
I0403 03:01:35.074515 16972 solver.cpp:244]     Train net output #0: loss = 0.0164735 (* 1 = 0.0164735 loss)
I0403 03:01:35.258410 16972 sgd_solver.cpp:106] Iteration 1015, lr = 0.005
I0403 03:01:39.069869 16972 solver.cpp:228] Iteration 1020, loss = 0.0117031
I0403 03:01:39.075604 16972 solver.cpp:244]     Train net output #0: loss = 0.0117031 (* 1 = 0.0117031 loss)
I0403 03:01:39.252023 16972 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 03:01:42.921886 16972 solver.cpp:228] Iteration 1025, loss = 0.0218306
I0403 03:01:42.928562 16972 solver.cpp:244]     Train net output #0: loss = 0.0218306 (* 1 = 0.0218306 loss)
I0403 03:01:43.114917 16972 sgd_solver.cpp:106] Iteration 1025, lr = 0.005
I0403 03:01:46.947299 16972 solver.cpp:228] Iteration 1030, loss = 0.0278943
I0403 03:01:46.952436 16972 solver.cpp:244]     Train net output #0: loss = 0.0278942 (* 1 = 0.0278942 loss)
I0403 03:01:47.136242 16972 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 03:01:50.790390 16972 solver.cpp:228] Iteration 1035, loss = 0.00728015
I0403 03:01:50.796838 16972 solver.cpp:244]     Train net output #0: loss = 0.00728011 (* 1 = 0.00728011 loss)
I0403 03:01:50.997246 16972 sgd_solver.cpp:106] Iteration 1035, lr = 0.005
I0403 03:01:54.649246 16972 solver.cpp:228] Iteration 1040, loss = 0.0164615
I0403 03:01:54.656118 16972 solver.cpp:244]     Train net output #0: loss = 0.0164615 (* 1 = 0.0164615 loss)
I0403 03:01:54.844969 16972 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 03:01:58.650672 16972 solver.cpp:228] Iteration 1045, loss = 0.0115874
I0403 03:01:58.656937 16972 solver.cpp:244]     Train net output #0: loss = 0.0115873 (* 1 = 0.0115873 loss)
I0403 03:01:58.855710 16972 sgd_solver.cpp:106] Iteration 1045, lr = 0.005
I0403 03:02:02.506326 16972 solver.cpp:228] Iteration 1050, loss = 0.000238188
I0403 03:02:02.513090 16972 solver.cpp:244]     Train net output #0: loss = 0.000238149 (* 1 = 0.000238149 loss)
I0403 03:02:02.748903 16972 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 03:02:06.357358 16972 solver.cpp:228] Iteration 1055, loss = 0.00660999
I0403 03:02:06.363469 16972 solver.cpp:244]     Train net output #0: loss = 0.00660995 (* 1 = 0.00660995 loss)
I0403 03:02:06.551714 16972 sgd_solver.cpp:106] Iteration 1055, lr = 0.005
I0403 03:02:10.281996 16972 solver.cpp:228] Iteration 1060, loss = 0.0134754
I0403 03:02:10.288697 16972 solver.cpp:244]     Train net output #0: loss = 0.0134753 (* 1 = 0.0134753 loss)
I0403 03:02:10.477388 16972 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 03:02:14.142638 16972 solver.cpp:228] Iteration 1065, loss = 0.0155422
I0403 03:02:14.149525 16972 solver.cpp:244]     Train net output #0: loss = 0.0155422 (* 1 = 0.0155422 loss)
I0403 03:02:14.337286 16972 sgd_solver.cpp:106] Iteration 1065, lr = 0.005
I0403 03:02:18.049814 16972 solver.cpp:228] Iteration 1070, loss = 0.00326187
I0403 03:02:18.055533 16972 solver.cpp:244]     Train net output #0: loss = 0.00326183 (* 1 = 0.00326183 loss)
I0403 03:02:18.258965 16972 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 03:02:21.935281 16972 solver.cpp:228] Iteration 1075, loss = 0.00730595
I0403 03:02:21.946244 16972 solver.cpp:244]     Train net output #0: loss = 0.00730591 (* 1 = 0.00730591 loss)
I0403 03:02:22.118764 16972 sgd_solver.cpp:106] Iteration 1075, lr = 0.005
I0403 03:02:25.261535 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1080.caffemodel
I0403 03:02:28.028269 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1080.solverstate
I0403 03:02:29.921090 16972 solver.cpp:337] Iteration 1080, Testing net (#0)
I0403 03:04:10.970001 16972 solver.cpp:404]     Test net output #0: accuracy = 0.964517
I0403 03:04:10.976740 16972 solver.cpp:404]     Test net output #1: loss = 0.141834 (* 1 = 0.141834 loss)
I0403 03:04:11.521626 16972 solver.cpp:228] Iteration 1080, loss = 0.025045
I0403 03:04:11.528671 16972 solver.cpp:244]     Train net output #0: loss = 0.025045 (* 1 = 0.025045 loss)
I0403 03:04:11.703512 16972 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 03:04:15.588812 16972 solver.cpp:228] Iteration 1085, loss = 0.0685563
I0403 03:04:15.595242 16972 solver.cpp:244]     Train net output #0: loss = 0.0685563 (* 1 = 0.0685563 loss)
I0403 03:04:15.782377 16972 sgd_solver.cpp:106] Iteration 1085, lr = 0.0005
I0403 03:04:19.504415 16972 solver.cpp:228] Iteration 1090, loss = 0.0283515
I0403 03:04:19.509974 16972 solver.cpp:244]     Train net output #0: loss = 0.0283514 (* 1 = 0.0283514 loss)
I0403 03:04:19.689471 16972 sgd_solver.cpp:106] Iteration 1090, lr = 0.0005
I0403 03:04:23.376168 16972 solver.cpp:228] Iteration 1095, loss = 0.00627913
I0403 03:04:23.382382 16972 solver.cpp:244]     Train net output #0: loss = 0.0062791 (* 1 = 0.0062791 loss)
I0403 03:04:23.583509 16972 sgd_solver.cpp:106] Iteration 1095, lr = 0.0005
I0403 03:04:27.262022 16972 solver.cpp:228] Iteration 1100, loss = 0.0647819
I0403 03:04:27.267998 16972 solver.cpp:244]     Train net output #0: loss = 0.0647819 (* 1 = 0.0647819 loss)
I0403 03:04:27.439520 16972 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0403 03:04:31.185539 16972 solver.cpp:228] Iteration 1105, loss = 0.00362618
I0403 03:04:31.191767 16972 solver.cpp:244]     Train net output #0: loss = 0.00362615 (* 1 = 0.00362615 loss)
I0403 03:04:31.339710 16972 sgd_solver.cpp:106] Iteration 1105, lr = 0.0005
I0403 03:04:35.100011 16972 solver.cpp:228] Iteration 1110, loss = 0.00126412
I0403 03:04:35.105563 16972 solver.cpp:244]     Train net output #0: loss = 0.00126409 (* 1 = 0.00126409 loss)
I0403 03:04:35.288537 16972 sgd_solver.cpp:106] Iteration 1110, lr = 0.0005
I0403 03:04:38.998675 16972 solver.cpp:228] Iteration 1115, loss = 0.00850964
I0403 03:04:39.005357 16972 solver.cpp:244]     Train net output #0: loss = 0.0085096 (* 1 = 0.0085096 loss)
I0403 03:04:39.186436 16972 sgd_solver.cpp:106] Iteration 1115, lr = 0.0005
I0403 03:04:42.892442 16972 solver.cpp:228] Iteration 1120, loss = 0.059972
I0403 03:04:42.898571 16972 solver.cpp:244]     Train net output #0: loss = 0.059972 (* 1 = 0.059972 loss)
I0403 03:04:43.087437 16972 sgd_solver.cpp:106] Iteration 1120, lr = 0.0005
I0403 03:04:46.810997 16972 solver.cpp:228] Iteration 1125, loss = 0.0100827
I0403 03:04:46.817800 16972 solver.cpp:244]     Train net output #0: loss = 0.0100827 (* 1 = 0.0100827 loss)
I0403 03:04:47.002539 16972 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0403 03:04:50.706660 16972 solver.cpp:228] Iteration 1130, loss = 0.00376898
I0403 03:04:50.713675 16972 solver.cpp:244]     Train net output #0: loss = 0.00376894 (* 1 = 0.00376894 loss)
I0403 03:04:50.913943 16972 sgd_solver.cpp:106] Iteration 1130, lr = 0.0005
I0403 03:04:54.488327 16972 solver.cpp:228] Iteration 1135, loss = 0.00714383
I0403 03:04:54.495126 16972 solver.cpp:244]     Train net output #0: loss = 0.00714379 (* 1 = 0.00714379 loss)
I0403 03:04:54.698463 16972 sgd_solver.cpp:106] Iteration 1135, lr = 0.0005
I0403 03:04:58.272538 16972 solver.cpp:228] Iteration 1140, loss = 0.00509572
I0403 03:04:58.278290 16972 solver.cpp:244]     Train net output #0: loss = 0.00509568 (* 1 = 0.00509568 loss)
I0403 03:04:58.466449 16972 sgd_solver.cpp:106] Iteration 1140, lr = 0.0005
I0403 03:05:02.124853 16972 solver.cpp:228] Iteration 1145, loss = 0.000783545
I0403 03:05:02.131134 16972 solver.cpp:244]     Train net output #0: loss = 0.000783507 (* 1 = 0.000783507 loss)
I0403 03:05:02.312361 16972 sgd_solver.cpp:106] Iteration 1145, lr = 0.0005
I0403 03:05:05.991055 16972 solver.cpp:228] Iteration 1150, loss = 0.0161278
I0403 03:05:05.997006 16972 solver.cpp:244]     Train net output #0: loss = 0.0161277 (* 1 = 0.0161277 loss)
I0403 03:05:06.189635 16972 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0403 03:05:09.848737 16972 solver.cpp:228] Iteration 1155, loss = 0.00746552
I0403 03:05:09.855235 16972 solver.cpp:244]     Train net output #0: loss = 0.00746548 (* 1 = 0.00746548 loss)
I0403 03:05:10.042199 16972 sgd_solver.cpp:106] Iteration 1155, lr = 0.0005
I0403 03:05:13.786087 16972 solver.cpp:228] Iteration 1160, loss = 0.00307998
I0403 03:05:13.792423 16972 solver.cpp:244]     Train net output #0: loss = 0.00307994 (* 1 = 0.00307994 loss)
I0403 03:05:13.981628 16972 sgd_solver.cpp:106] Iteration 1160, lr = 0.0005
I0403 03:05:17.679405 16972 solver.cpp:228] Iteration 1165, loss = 0.00485247
I0403 03:05:17.685958 16972 solver.cpp:244]     Train net output #0: loss = 0.00485243 (* 1 = 0.00485243 loss)
I0403 03:05:17.879129 16972 sgd_solver.cpp:106] Iteration 1165, lr = 0.0005
I0403 03:05:21.458657 16972 solver.cpp:228] Iteration 1170, loss = 0.00376707
I0403 03:05:21.464864 16972 solver.cpp:244]     Train net output #0: loss = 0.00376703 (* 1 = 0.00376703 loss)
I0403 03:05:21.664352 16972 sgd_solver.cpp:106] Iteration 1170, lr = 0.0005
I0403 03:05:25.549981 16972 solver.cpp:228] Iteration 1175, loss = 0.000386234
I0403 03:05:25.556769 16972 solver.cpp:244]     Train net output #0: loss = 0.000386192 (* 1 = 0.000386192 loss)
I0403 03:05:25.734891 16972 sgd_solver.cpp:106] Iteration 1175, lr = 0.0005
I0403 03:05:29.464524 16972 solver.cpp:228] Iteration 1180, loss = 0.00439648
I0403 03:05:29.469486 16972 solver.cpp:244]     Train net output #0: loss = 0.00439644 (* 1 = 0.00439644 loss)
I0403 03:05:29.605837 16972 sgd_solver.cpp:106] Iteration 1180, lr = 0.0005
I0403 03:05:33.391067 16972 solver.cpp:228] Iteration 1185, loss = 0.0117632
I0403 03:05:33.396841 16972 solver.cpp:244]     Train net output #0: loss = 0.0117631 (* 1 = 0.0117631 loss)
I0403 03:05:33.582041 16972 sgd_solver.cpp:106] Iteration 1185, lr = 0.0005
I0403 03:05:35.124689 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1188.caffemodel
I0403 03:05:37.946804 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1188.solverstate
I0403 03:05:39.832315 16972 solver.cpp:337] Iteration 1188, Testing net (#0)
I0403 03:07:20.873116 16972 solver.cpp:404]     Test net output #0: accuracy = 0.97189
I0403 03:07:20.880507 16972 solver.cpp:404]     Test net output #1: loss = 0.113635 (* 1 = 0.113635 loss)
I0403 03:07:23.125422 16972 solver.cpp:228] Iteration 1190, loss = 0.00944306
I0403 03:07:23.132319 16972 solver.cpp:244]     Train net output #0: loss = 0.00944302 (* 1 = 0.00944302 loss)
I0403 03:07:23.314328 16972 sgd_solver.cpp:106] Iteration 1190, lr = 0.0005
I0403 03:07:26.985615 16972 solver.cpp:228] Iteration 1195, loss = 0.00540797
I0403 03:07:26.991716 16972 solver.cpp:244]     Train net output #0: loss = 0.00540793 (* 1 = 0.00540793 loss)
I0403 03:07:27.158455 16972 sgd_solver.cpp:106] Iteration 1195, lr = 0.0005
I0403 03:07:30.968158 16972 solver.cpp:228] Iteration 1200, loss = 0.00174384
I0403 03:07:30.974712 16972 solver.cpp:244]     Train net output #0: loss = 0.0017438 (* 1 = 0.0017438 loss)
I0403 03:07:31.161458 16972 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0403 03:07:34.833050 16972 solver.cpp:228] Iteration 1205, loss = 0.000125746
I0403 03:07:34.839576 16972 solver.cpp:244]     Train net output #0: loss = 0.000125705 (* 1 = 0.000125705 loss)
I0403 03:07:35.060843 16972 sgd_solver.cpp:106] Iteration 1205, lr = 0.0005
I0403 03:07:38.723111 16972 solver.cpp:228] Iteration 1210, loss = 0.00214733
I0403 03:07:38.729346 16972 solver.cpp:244]     Train net output #0: loss = 0.00214729 (* 1 = 0.00214729 loss)
I0403 03:07:38.903802 16972 sgd_solver.cpp:106] Iteration 1210, lr = 0.0005
I0403 03:07:42.638877 16972 solver.cpp:228] Iteration 1215, loss = 0.00138407
I0403 03:07:42.644914 16972 solver.cpp:244]     Train net output #0: loss = 0.00138403 (* 1 = 0.00138403 loss)
I0403 03:07:42.845870 16972 sgd_solver.cpp:106] Iteration 1215, lr = 0.0005
I0403 03:07:46.574957 16972 solver.cpp:228] Iteration 1220, loss = 0.0379589
I0403 03:07:46.581492 16972 solver.cpp:244]     Train net output #0: loss = 0.0379589 (* 1 = 0.0379589 loss)
I0403 03:07:46.771442 16972 sgd_solver.cpp:106] Iteration 1220, lr = 0.0005
I0403 03:07:50.384614 16972 solver.cpp:228] Iteration 1225, loss = 0.00210361
I0403 03:07:50.391227 16972 solver.cpp:244]     Train net output #0: loss = 0.00210357 (* 1 = 0.00210357 loss)
I0403 03:07:50.622653 16972 sgd_solver.cpp:106] Iteration 1225, lr = 0.0005
I0403 03:07:54.384449 16972 solver.cpp:228] Iteration 1230, loss = 0.0142882
I0403 03:07:54.391017 16972 solver.cpp:244]     Train net output #0: loss = 0.0142882 (* 1 = 0.0142882 loss)
I0403 03:07:54.579160 16972 sgd_solver.cpp:106] Iteration 1230, lr = 0.0005
I0403 03:07:58.228679 16972 solver.cpp:228] Iteration 1235, loss = 0.00134457
I0403 03:07:58.235378 16972 solver.cpp:244]     Train net output #0: loss = 0.00134453 (* 1 = 0.00134453 loss)
I0403 03:07:58.421766 16972 sgd_solver.cpp:106] Iteration 1235, lr = 0.0005
I0403 03:08:02.103085 16972 solver.cpp:228] Iteration 1240, loss = 0.0025526
I0403 03:08:02.110390 16972 solver.cpp:244]     Train net output #0: loss = 0.00255256 (* 1 = 0.00255256 loss)
I0403 03:08:02.293062 16972 sgd_solver.cpp:106] Iteration 1240, lr = 0.0005
I0403 03:08:06.068418 16972 solver.cpp:228] Iteration 1245, loss = 0.00709011
I0403 03:08:06.074641 16972 solver.cpp:244]     Train net output #0: loss = 0.00709007 (* 1 = 0.00709007 loss)
I0403 03:08:06.251461 16972 sgd_solver.cpp:106] Iteration 1245, lr = 0.0005
I0403 03:08:09.938575 16972 solver.cpp:228] Iteration 1250, loss = 0.000513797
I0403 03:08:09.944764 16972 solver.cpp:244]     Train net output #0: loss = 0.000513756 (* 1 = 0.000513756 loss)
I0403 03:08:10.151357 16972 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0403 03:08:13.944735 16972 solver.cpp:228] Iteration 1255, loss = 0.000303126
I0403 03:08:13.951289 16972 solver.cpp:244]     Train net output #0: loss = 0.000303085 (* 1 = 0.000303085 loss)
I0403 03:08:14.113796 16972 sgd_solver.cpp:106] Iteration 1255, lr = 0.0005
I0403 03:08:17.869508 16972 solver.cpp:228] Iteration 1260, loss = 0.00199285
I0403 03:08:17.875908 16972 solver.cpp:244]     Train net output #0: loss = 0.00199281 (* 1 = 0.00199281 loss)
I0403 03:08:18.067765 16972 sgd_solver.cpp:106] Iteration 1260, lr = 0.0005
I0403 03:08:21.740265 16972 solver.cpp:228] Iteration 1265, loss = 0.00123308
I0403 03:08:21.746749 16972 solver.cpp:244]     Train net output #0: loss = 0.00123304 (* 1 = 0.00123304 loss)
I0403 03:08:21.950242 16972 sgd_solver.cpp:106] Iteration 1265, lr = 0.0005
I0403 03:08:25.612200 16972 solver.cpp:228] Iteration 1270, loss = 0.00375353
I0403 03:08:25.619025 16972 solver.cpp:244]     Train net output #0: loss = 0.00375349 (* 1 = 0.00375349 loss)
I0403 03:08:25.806980 16972 sgd_solver.cpp:106] Iteration 1270, lr = 0.0005
I0403 03:08:29.459789 16972 solver.cpp:228] Iteration 1275, loss = 0.000411808
I0403 03:08:29.466629 16972 solver.cpp:244]     Train net output #0: loss = 0.000411767 (* 1 = 0.000411767 loss)
I0403 03:08:29.644850 16972 sgd_solver.cpp:106] Iteration 1275, lr = 0.0005
I0403 03:08:33.454430 16972 solver.cpp:228] Iteration 1280, loss = 0.000755509
I0403 03:08:33.461241 16972 solver.cpp:244]     Train net output #0: loss = 0.000755468 (* 1 = 0.000755468 loss)
I0403 03:08:33.579897 16972 sgd_solver.cpp:106] Iteration 1280, lr = 0.0005
I0403 03:08:37.330288 16972 solver.cpp:228] Iteration 1285, loss = 0.00949284
I0403 03:08:37.337705 16972 solver.cpp:244]     Train net output #0: loss = 0.0094928 (* 1 = 0.0094928 loss)
I0403 03:08:37.514003 16972 sgd_solver.cpp:106] Iteration 1285, lr = 0.0005
I0403 03:08:41.262024 16972 solver.cpp:228] Iteration 1290, loss = 0.000185754
I0403 03:08:41.267649 16972 solver.cpp:244]     Train net output #0: loss = 0.000185712 (* 1 = 0.000185712 loss)
I0403 03:08:41.468698 16972 sgd_solver.cpp:106] Iteration 1290, lr = 0.0005
I0403 03:08:45.121929 16972 solver.cpp:228] Iteration 1295, loss = 0.000547148
I0403 03:08:45.128437 16972 solver.cpp:244]     Train net output #0: loss = 0.000547106 (* 1 = 0.000547106 loss)
I0403 03:08:45.316792 16972 sgd_solver.cpp:106] Iteration 1295, lr = 0.0005
I0403 03:08:45.325142 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1296.caffemodel
I0403 03:08:48.122026 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1296.solverstate
I0403 03:08:49.930125 16972 solver.cpp:337] Iteration 1296, Testing net (#0)
I0403 03:10:30.989575 16972 solver.cpp:404]     Test net output #0: accuracy = 0.972881
I0403 03:10:30.997164 16972 solver.cpp:404]     Test net output #1: loss = 0.111627 (* 1 = 0.111627 loss)
I0403 03:10:34.630980 16972 solver.cpp:228] Iteration 1300, loss = 9.16347e-05
I0403 03:10:34.637435 16972 solver.cpp:244]     Train net output #0: loss = 9.15929e-05 (* 1 = 9.15929e-05 loss)
I0403 03:10:34.819197 16972 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0403 03:10:38.506170 16972 solver.cpp:228] Iteration 1305, loss = 0.000396571
I0403 03:10:38.512794 16972 solver.cpp:244]     Train net output #0: loss = 0.000396529 (* 1 = 0.000396529 loss)
I0403 03:10:38.700778 16972 sgd_solver.cpp:106] Iteration 1305, lr = 0.0005
I0403 03:10:42.423861 16972 solver.cpp:228] Iteration 1310, loss = 0.00384002
I0403 03:10:42.431092 16972 solver.cpp:244]     Train net output #0: loss = 0.00383998 (* 1 = 0.00383998 loss)
I0403 03:10:42.640687 16972 sgd_solver.cpp:106] Iteration 1310, lr = 0.0005
I0403 03:10:46.366410 16972 solver.cpp:228] Iteration 1315, loss = 2.6023e-05
I0403 03:10:46.373384 16972 solver.cpp:244]     Train net output #0: loss = 2.59821e-05 (* 1 = 2.59821e-05 loss)
I0403 03:10:46.561501 16972 sgd_solver.cpp:106] Iteration 1315, lr = 0.0005
I0403 03:10:50.340561 16972 solver.cpp:228] Iteration 1320, loss = 0.00149017
I0403 03:10:50.347053 16972 solver.cpp:244]     Train net output #0: loss = 0.00149013 (* 1 = 0.00149013 loss)
I0403 03:10:50.545231 16972 sgd_solver.cpp:106] Iteration 1320, lr = 0.0005
I0403 03:10:54.182520 16972 solver.cpp:228] Iteration 1325, loss = 0.000620228
I0403 03:10:54.189249 16972 solver.cpp:244]     Train net output #0: loss = 0.000620187 (* 1 = 0.000620187 loss)
I0403 03:10:54.376629 16972 sgd_solver.cpp:106] Iteration 1325, lr = 0.0005
I0403 03:10:58.006506 16972 solver.cpp:228] Iteration 1330, loss = 0.00269786
I0403 03:10:58.012660 16972 solver.cpp:244]     Train net output #0: loss = 0.00269782 (* 1 = 0.00269782 loss)
I0403 03:10:58.200673 16972 sgd_solver.cpp:106] Iteration 1330, lr = 0.0005
I0403 03:11:01.976658 16972 solver.cpp:228] Iteration 1335, loss = 0.00218627
I0403 03:11:01.982798 16972 solver.cpp:244]     Train net output #0: loss = 0.00218623 (* 1 = 0.00218623 loss)
I0403 03:11:02.165047 16972 sgd_solver.cpp:106] Iteration 1335, lr = 0.0005
I0403 03:11:05.830296 16972 solver.cpp:228] Iteration 1340, loss = 0.00218518
I0403 03:11:05.836573 16972 solver.cpp:244]     Train net output #0: loss = 0.00218514 (* 1 = 0.00218514 loss)
I0403 03:11:06.022825 16972 sgd_solver.cpp:106] Iteration 1340, lr = 0.0005
I0403 03:11:09.706780 16972 solver.cpp:228] Iteration 1345, loss = 0.000859772
I0403 03:11:09.712359 16972 solver.cpp:244]     Train net output #0: loss = 0.000859731 (* 1 = 0.000859731 loss)
I0403 03:11:09.902297 16972 sgd_solver.cpp:106] Iteration 1345, lr = 0.0005
I0403 03:11:13.642743 16972 solver.cpp:228] Iteration 1350, loss = 0.000435744
I0403 03:11:13.648833 16972 solver.cpp:244]     Train net output #0: loss = 0.000435703 (* 1 = 0.000435703 loss)
I0403 03:11:13.833015 16972 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0403 03:11:17.494845 16972 solver.cpp:228] Iteration 1355, loss = 0.00180295
I0403 03:11:17.501559 16972 solver.cpp:244]     Train net output #0: loss = 0.00180291 (* 1 = 0.00180291 loss)
I0403 03:11:17.691588 16972 sgd_solver.cpp:106] Iteration 1355, lr = 0.0005
I0403 03:11:21.393635 16972 solver.cpp:228] Iteration 1360, loss = 0.00261203
I0403 03:11:21.400810 16972 solver.cpp:244]     Train net output #0: loss = 0.00261199 (* 1 = 0.00261199 loss)
I0403 03:11:21.631357 16972 sgd_solver.cpp:106] Iteration 1360, lr = 0.0005
I0403 03:11:25.269011 16972 solver.cpp:228] Iteration 1365, loss = 0.000908354
I0403 03:11:25.274876 16972 solver.cpp:244]     Train net output #0: loss = 0.000908313 (* 1 = 0.000908313 loss)
I0403 03:11:25.447188 16972 sgd_solver.cpp:106] Iteration 1365, lr = 0.0005
I0403 03:11:29.165673 16972 solver.cpp:228] Iteration 1370, loss = 0.00245314
I0403 03:11:29.175330 16972 solver.cpp:244]     Train net output #0: loss = 0.0024531 (* 1 = 0.0024531 loss)
I0403 03:11:29.336700 16972 sgd_solver.cpp:106] Iteration 1370, lr = 0.0005
I0403 03:11:33.200374 16972 solver.cpp:228] Iteration 1375, loss = 0.000728171
I0403 03:11:33.207370 16972 solver.cpp:244]     Train net output #0: loss = 0.00072813 (* 1 = 0.00072813 loss)
I0403 03:11:33.376549 16972 sgd_solver.cpp:106] Iteration 1375, lr = 0.0005
I0403 03:11:37.088058 16972 solver.cpp:228] Iteration 1380, loss = 0.0251968
I0403 03:11:37.093215 16972 solver.cpp:244]     Train net output #0: loss = 0.0251968 (* 1 = 0.0251968 loss)
I0403 03:11:37.295486 16972 sgd_solver.cpp:106] Iteration 1380, lr = 0.0005
I0403 03:11:40.955123 16972 solver.cpp:228] Iteration 1385, loss = 0.00125882
I0403 03:11:40.961081 16972 solver.cpp:244]     Train net output #0: loss = 0.00125878 (* 1 = 0.00125878 loss)
I0403 03:11:41.162024 16972 sgd_solver.cpp:106] Iteration 1385, lr = 0.0005
I0403 03:11:44.776322 16972 solver.cpp:228] Iteration 1390, loss = 0.00162408
I0403 03:11:44.782804 16972 solver.cpp:244]     Train net output #0: loss = 0.00162404 (* 1 = 0.00162404 loss)
I0403 03:11:44.953889 16972 sgd_solver.cpp:106] Iteration 1390, lr = 0.0005
I0403 03:11:48.622659 16972 solver.cpp:228] Iteration 1395, loss = 0.00012872
I0403 03:11:48.647927 16972 solver.cpp:244]     Train net output #0: loss = 0.00012868 (* 1 = 0.00012868 loss)
I0403 03:11:48.795744 16972 sgd_solver.cpp:106] Iteration 1395, lr = 0.0005
I0403 03:11:52.479343 16972 solver.cpp:228] Iteration 1400, loss = 0.00108513
I0403 03:11:52.485862 16972 solver.cpp:244]     Train net output #0: loss = 0.00108509 (* 1 = 0.00108509 loss)
I0403 03:11:52.691334 16972 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0403 03:11:55.094485 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1404.caffemodel
I0403 03:11:57.890748 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1404.solverstate
I0403 03:11:59.781651 16972 solver.cpp:337] Iteration 1404, Testing net (#0)
I0403 03:13:40.819596 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973066
I0403 03:13:40.827297 16972 solver.cpp:404]     Test net output #1: loss = 0.112683 (* 1 = 0.112683 loss)
I0403 03:13:42.144706 16972 solver.cpp:228] Iteration 1405, loss = 0.00767155
I0403 03:13:42.152494 16972 solver.cpp:244]     Train net output #0: loss = 0.00767151 (* 1 = 0.00767151 loss)
I0403 03:13:42.341275 16972 sgd_solver.cpp:106] Iteration 1405, lr = 0.0005
I0403 03:13:46.016279 16972 solver.cpp:228] Iteration 1410, loss = 0.00157022
I0403 03:13:46.021574 16972 solver.cpp:244]     Train net output #0: loss = 0.00157018 (* 1 = 0.00157018 loss)
I0403 03:13:46.223366 16972 sgd_solver.cpp:106] Iteration 1410, lr = 0.0005
I0403 03:13:49.915112 16972 solver.cpp:228] Iteration 1415, loss = 0.00149721
I0403 03:13:49.922171 16972 solver.cpp:244]     Train net output #0: loss = 0.00149717 (* 1 = 0.00149717 loss)
I0403 03:13:50.090632 16972 sgd_solver.cpp:106] Iteration 1415, lr = 0.0005
I0403 03:13:54.022850 16972 solver.cpp:228] Iteration 1420, loss = 0.000212318
I0403 03:13:54.028210 16972 solver.cpp:244]     Train net output #0: loss = 0.000212278 (* 1 = 0.000212278 loss)
I0403 03:13:54.205078 16972 sgd_solver.cpp:106] Iteration 1420, lr = 0.0005
I0403 03:13:57.903841 16972 solver.cpp:228] Iteration 1425, loss = 0.000578034
I0403 03:13:57.910454 16972 solver.cpp:244]     Train net output #0: loss = 0.000577993 (* 1 = 0.000577993 loss)
I0403 03:13:58.146211 16972 sgd_solver.cpp:106] Iteration 1425, lr = 0.0005
I0403 03:14:01.905481 16972 solver.cpp:228] Iteration 1430, loss = 0.000920567
I0403 03:14:01.913061 16972 solver.cpp:244]     Train net output #0: loss = 0.000920526 (* 1 = 0.000920526 loss)
I0403 03:14:02.117521 16972 sgd_solver.cpp:106] Iteration 1430, lr = 0.0005
I0403 03:14:05.740702 16972 solver.cpp:228] Iteration 1435, loss = 0.000369679
I0403 03:14:05.747309 16972 solver.cpp:244]     Train net output #0: loss = 0.000369638 (* 1 = 0.000369638 loss)
I0403 03:14:05.939972 16972 sgd_solver.cpp:106] Iteration 1435, lr = 0.0005
I0403 03:14:09.597343 16972 solver.cpp:228] Iteration 1440, loss = 0.00143931
I0403 03:14:09.603725 16972 solver.cpp:244]     Train net output #0: loss = 0.00143927 (* 1 = 0.00143927 loss)
I0403 03:14:09.790563 16972 sgd_solver.cpp:106] Iteration 1440, lr = 0.0005
I0403 03:14:13.518590 16972 solver.cpp:228] Iteration 1445, loss = 0.000421019
I0403 03:14:13.524965 16972 solver.cpp:244]     Train net output #0: loss = 0.000420978 (* 1 = 0.000420978 loss)
I0403 03:14:13.725802 16972 sgd_solver.cpp:106] Iteration 1445, lr = 0.0005
I0403 03:14:17.362370 16972 solver.cpp:228] Iteration 1450, loss = 0.00343418
I0403 03:14:17.368543 16972 solver.cpp:244]     Train net output #0: loss = 0.00343414 (* 1 = 0.00343414 loss)
I0403 03:14:17.618650 16972 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0403 03:14:21.248414 16972 solver.cpp:228] Iteration 1455, loss = 0.0138949
I0403 03:14:21.257001 16972 solver.cpp:244]     Train net output #0: loss = 0.0138949 (* 1 = 0.0138949 loss)
I0403 03:14:21.436936 16972 sgd_solver.cpp:106] Iteration 1455, lr = 0.0005
I0403 03:14:25.108444 16972 solver.cpp:228] Iteration 1460, loss = 0.000586137
I0403 03:14:25.114238 16972 solver.cpp:244]     Train net output #0: loss = 0.000586094 (* 1 = 0.000586094 loss)
I0403 03:14:25.308275 16972 sgd_solver.cpp:106] Iteration 1460, lr = 0.0005
I0403 03:14:29.038275 16972 solver.cpp:228] Iteration 1465, loss = 0.00559935
I0403 03:14:29.045014 16972 solver.cpp:244]     Train net output #0: loss = 0.0055993 (* 1 = 0.0055993 loss)
I0403 03:14:29.171952 16972 sgd_solver.cpp:106] Iteration 1465, lr = 0.0005
I0403 03:14:33.053303 16972 solver.cpp:228] Iteration 1470, loss = 0.000636888
I0403 03:14:33.060292 16972 solver.cpp:244]     Train net output #0: loss = 0.000636845 (* 1 = 0.000636845 loss)
I0403 03:14:33.237328 16972 sgd_solver.cpp:106] Iteration 1470, lr = 0.0005
I0403 03:14:36.956944 16972 solver.cpp:228] Iteration 1475, loss = 0.0139702
I0403 03:14:36.963341 16972 solver.cpp:244]     Train net output #0: loss = 0.0139701 (* 1 = 0.0139701 loss)
I0403 03:14:37.152995 16972 sgd_solver.cpp:106] Iteration 1475, lr = 0.0005
I0403 03:14:40.972973 16972 solver.cpp:228] Iteration 1480, loss = 0.000442035
I0403 03:14:40.978761 16972 solver.cpp:244]     Train net output #0: loss = 0.000441992 (* 1 = 0.000441992 loss)
I0403 03:14:41.161584 16972 sgd_solver.cpp:106] Iteration 1480, lr = 0.0005
I0403 03:14:44.841122 16972 solver.cpp:228] Iteration 1485, loss = 0.003227
I0403 03:14:44.846752 16972 solver.cpp:244]     Train net output #0: loss = 0.00322695 (* 1 = 0.00322695 loss)
I0403 03:14:45.041335 16972 sgd_solver.cpp:106] Iteration 1485, lr = 0.0005
I0403 03:14:48.786442 16972 solver.cpp:228] Iteration 1490, loss = 0.00350452
I0403 03:14:48.792438 16972 solver.cpp:244]     Train net output #0: loss = 0.00350448 (* 1 = 0.00350448 loss)
I0403 03:14:48.947935 16972 sgd_solver.cpp:106] Iteration 1490, lr = 0.0005
I0403 03:14:52.656797 16972 solver.cpp:228] Iteration 1495, loss = 0.000238607
I0403 03:14:52.663173 16972 solver.cpp:244]     Train net output #0: loss = 0.000238563 (* 1 = 0.000238563 loss)
I0403 03:14:52.941678 16972 sgd_solver.cpp:106] Iteration 1495, lr = 0.0005
I0403 03:14:56.625480 16972 solver.cpp:228] Iteration 1500, loss = 0.00114479
I0403 03:14:56.632499 16972 solver.cpp:244]     Train net output #0: loss = 0.00114475 (* 1 = 0.00114475 loss)
I0403 03:14:56.807797 16972 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0403 03:15:00.539938 16972 solver.cpp:228] Iteration 1505, loss = 0.000594539
I0403 03:15:00.547369 16972 solver.cpp:244]     Train net output #0: loss = 0.000594495 (* 1 = 0.000594495 loss)
I0403 03:15:00.731261 16972 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I0403 03:15:04.403709 16972 solver.cpp:228] Iteration 1510, loss = 0.000320722
I0403 03:15:04.409816 16972 solver.cpp:244]     Train net output #0: loss = 0.000320678 (* 1 = 0.000320678 loss)
I0403 03:15:04.617589 16972 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I0403 03:15:05.365857 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1512.caffemodel
I0403 03:15:08.159108 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1512.solverstate
I0403 03:15:09.991957 16972 solver.cpp:337] Iteration 1512, Testing net (#0)
I0403 03:16:51.069577 16972 solver.cpp:404]     Test net output #0: accuracy = 0.972973
I0403 03:16:51.076714 16972 solver.cpp:404]     Test net output #1: loss = 0.114639 (* 1 = 0.114639 loss)
I0403 03:16:54.011891 16972 solver.cpp:228] Iteration 1515, loss = 0.000556143
I0403 03:16:54.019289 16972 solver.cpp:244]     Train net output #0: loss = 0.000556099 (* 1 = 0.000556099 loss)
I0403 03:16:54.221065 16972 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I0403 03:16:57.831740 16972 solver.cpp:228] Iteration 1520, loss = 0.000145322
I0403 03:16:57.838816 16972 solver.cpp:244]     Train net output #0: loss = 0.000145279 (* 1 = 0.000145279 loss)
I0403 03:16:58.024596 16972 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I0403 03:17:01.702242 16972 solver.cpp:228] Iteration 1525, loss = 0.000518152
I0403 03:17:01.708276 16972 solver.cpp:244]     Train net output #0: loss = 0.000518109 (* 1 = 0.000518109 loss)
I0403 03:17:01.875679 16972 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I0403 03:17:05.575584 16972 solver.cpp:228] Iteration 1530, loss = 0.000309502
I0403 03:17:05.581383 16972 solver.cpp:244]     Train net output #0: loss = 0.000309458 (* 1 = 0.000309458 loss)
I0403 03:17:05.762480 16972 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I0403 03:17:09.582274 16972 solver.cpp:228] Iteration 1535, loss = 0.00724603
I0403 03:17:09.589092 16972 solver.cpp:244]     Train net output #0: loss = 0.00724598 (* 1 = 0.00724598 loss)
I0403 03:17:09.775987 16972 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I0403 03:17:13.450220 16972 solver.cpp:228] Iteration 1540, loss = 0.00508126
I0403 03:17:13.456130 16972 solver.cpp:244]     Train net output #0: loss = 0.00508122 (* 1 = 0.00508122 loss)
I0403 03:17:13.635375 16972 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I0403 03:17:17.285035 16972 solver.cpp:228] Iteration 1545, loss = 0.000688231
I0403 03:17:17.290884 16972 solver.cpp:244]     Train net output #0: loss = 0.000688187 (* 1 = 0.000688187 loss)
I0403 03:17:17.509454 16972 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I0403 03:17:21.258729 16972 solver.cpp:228] Iteration 1550, loss = 0.005437
I0403 03:17:21.264688 16972 solver.cpp:244]     Train net output #0: loss = 0.00543696 (* 1 = 0.00543696 loss)
I0403 03:17:21.445346 16972 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0403 03:17:25.188156 16972 solver.cpp:228] Iteration 1555, loss = 0.00379859
I0403 03:17:25.195696 16972 solver.cpp:244]     Train net output #0: loss = 0.00379854 (* 1 = 0.00379854 loss)
I0403 03:17:25.447010 16972 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I0403 03:17:29.052763 16972 solver.cpp:228] Iteration 1560, loss = 0.00227576
I0403 03:17:29.057865 16972 solver.cpp:244]     Train net output #0: loss = 0.00227571 (* 1 = 0.00227571 loss)
I0403 03:17:29.270311 16972 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I0403 03:17:32.892884 16972 solver.cpp:228] Iteration 1565, loss = 0.00176835
I0403 03:17:32.898701 16972 solver.cpp:244]     Train net output #0: loss = 0.00176831 (* 1 = 0.00176831 loss)
I0403 03:17:33.070013 16972 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I0403 03:17:36.736969 16972 solver.cpp:228] Iteration 1570, loss = 0.000176339
I0403 03:17:36.744930 16972 solver.cpp:244]     Train net output #0: loss = 0.000176295 (* 1 = 0.000176295 loss)
I0403 03:17:36.941606 16972 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I0403 03:17:40.536396 16972 solver.cpp:228] Iteration 1575, loss = 0.0038413
I0403 03:17:40.543529 16972 solver.cpp:244]     Train net output #0: loss = 0.00384125 (* 1 = 0.00384125 loss)
I0403 03:17:40.768568 16972 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I0403 03:17:44.439718 16972 solver.cpp:228] Iteration 1580, loss = 0.000457257
I0403 03:17:44.446629 16972 solver.cpp:244]     Train net output #0: loss = 0.000457212 (* 1 = 0.000457212 loss)
I0403 03:17:44.634078 16972 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I0403 03:17:48.330490 16972 solver.cpp:228] Iteration 1585, loss = 0.00255246
I0403 03:17:48.337780 16972 solver.cpp:244]     Train net output #0: loss = 0.00255241 (* 1 = 0.00255241 loss)
I0403 03:17:48.535181 16972 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I0403 03:17:52.186424 16972 solver.cpp:228] Iteration 1590, loss = 0.002363
I0403 03:17:52.193114 16972 solver.cpp:244]     Train net output #0: loss = 0.00236296 (* 1 = 0.00236296 loss)
I0403 03:17:52.372418 16972 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I0403 03:17:56.033473 16972 solver.cpp:228] Iteration 1595, loss = 0.000756652
I0403 03:17:56.039571 16972 solver.cpp:244]     Train net output #0: loss = 0.000756608 (* 1 = 0.000756608 loss)
I0403 03:17:56.226017 16972 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I0403 03:17:59.899261 16972 solver.cpp:228] Iteration 1600, loss = 0.00152141
I0403 03:17:59.906008 16972 solver.cpp:244]     Train net output #0: loss = 0.00152137 (* 1 = 0.00152137 loss)
I0403 03:18:00.113432 16972 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0403 03:18:03.730968 16972 solver.cpp:228] Iteration 1605, loss = 0.00970906
I0403 03:18:03.737112 16972 solver.cpp:244]     Train net output #0: loss = 0.00970901 (* 1 = 0.00970901 loss)
I0403 03:18:03.937922 16972 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I0403 03:18:07.569335 16972 solver.cpp:228] Iteration 1610, loss = 0.000632977
I0403 03:18:07.576520 16972 solver.cpp:244]     Train net output #0: loss = 0.000632931 (* 1 = 0.000632931 loss)
I0403 03:18:07.768872 16972 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I0403 03:18:11.410572 16972 solver.cpp:228] Iteration 1615, loss = 0.000179301
I0403 03:18:11.416857 16972 solver.cpp:244]     Train net output #0: loss = 0.000179255 (* 1 = 0.000179255 loss)
I0403 03:18:11.617167 16972 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I0403 03:18:14.718322 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1620.caffemodel
I0403 03:18:17.542376 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1620.solverstate
I0403 03:18:19.369879 16972 solver.cpp:337] Iteration 1620, Testing net (#0)
I0403 03:20:00.443680 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973595
I0403 03:20:00.454864 16972 solver.cpp:404]     Test net output #1: loss = 0.110084 (* 1 = 0.110084 loss)
I0403 03:20:00.988776 16972 solver.cpp:228] Iteration 1620, loss = 0.00168339
I0403 03:20:00.995411 16972 solver.cpp:244]     Train net output #0: loss = 0.00168334 (* 1 = 0.00168334 loss)
I0403 03:20:01.166404 16972 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I0403 03:20:04.872041 16972 solver.cpp:228] Iteration 1625, loss = 0.00121316
I0403 03:20:04.878221 16972 solver.cpp:244]     Train net output #0: loss = 0.00121311 (* 1 = 0.00121311 loss)
I0403 03:20:05.065460 16972 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I0403 03:20:08.719909 16972 solver.cpp:228] Iteration 1630, loss = 0.000708431
I0403 03:20:08.726356 16972 solver.cpp:244]     Train net output #0: loss = 0.000708386 (* 1 = 0.000708386 loss)
I0403 03:20:08.910714 16972 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I0403 03:20:12.620021 16972 solver.cpp:228] Iteration 1635, loss = 0.00173371
I0403 03:20:12.625938 16972 solver.cpp:244]     Train net output #0: loss = 0.00173366 (* 1 = 0.00173366 loss)
I0403 03:20:12.801342 16972 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I0403 03:20:16.502594 16972 solver.cpp:228] Iteration 1640, loss = 0.00487012
I0403 03:20:16.508762 16972 solver.cpp:244]     Train net output #0: loss = 0.00487007 (* 1 = 0.00487007 loss)
I0403 03:20:16.700799 16972 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I0403 03:20:20.407165 16972 solver.cpp:228] Iteration 1645, loss = 0.00140176
I0403 03:20:20.413414 16972 solver.cpp:244]     Train net output #0: loss = 0.00140172 (* 1 = 0.00140172 loss)
I0403 03:20:20.591420 16972 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I0403 03:20:24.338099 16972 solver.cpp:228] Iteration 1650, loss = 0.000527154
I0403 03:20:24.344211 16972 solver.cpp:244]     Train net output #0: loss = 0.000527109 (* 1 = 0.000527109 loss)
I0403 03:20:24.557660 16972 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0403 03:20:28.226989 16972 solver.cpp:228] Iteration 1655, loss = 0.00126929
I0403 03:20:28.232678 16972 solver.cpp:244]     Train net output #0: loss = 0.00126925 (* 1 = 0.00126925 loss)
I0403 03:20:28.421133 16972 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I0403 03:20:32.110293 16972 solver.cpp:228] Iteration 1660, loss = 0.00861593
I0403 03:20:32.117152 16972 solver.cpp:244]     Train net output #0: loss = 0.00861589 (* 1 = 0.00861589 loss)
I0403 03:20:32.290920 16972 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I0403 03:20:35.958852 16972 solver.cpp:228] Iteration 1665, loss = 0.00456694
I0403 03:20:35.965561 16972 solver.cpp:244]     Train net output #0: loss = 0.00456689 (* 1 = 0.00456689 loss)
I0403 03:20:36.163944 16972 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I0403 03:20:39.864614 16972 solver.cpp:228] Iteration 1670, loss = 0.00387529
I0403 03:20:39.871232 16972 solver.cpp:244]     Train net output #0: loss = 0.00387525 (* 1 = 0.00387525 loss)
I0403 03:20:40.042563 16972 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I0403 03:20:43.693402 16972 solver.cpp:228] Iteration 1675, loss = 0.00669306
I0403 03:20:43.699064 16972 solver.cpp:244]     Train net output #0: loss = 0.00669302 (* 1 = 0.00669302 loss)
I0403 03:20:43.900610 16972 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I0403 03:20:47.567596 16972 solver.cpp:228] Iteration 1680, loss = 0.012761
I0403 03:20:47.574069 16972 solver.cpp:244]     Train net output #0: loss = 0.0127609 (* 1 = 0.0127609 loss)
I0403 03:20:47.746404 16972 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I0403 03:20:51.554052 16972 solver.cpp:228] Iteration 1685, loss = 0.000414012
I0403 03:20:51.560549 16972 solver.cpp:244]     Train net output #0: loss = 0.000413966 (* 1 = 0.000413966 loss)
I0403 03:20:51.752414 16972 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I0403 03:20:55.414902 16972 solver.cpp:228] Iteration 1690, loss = 0.00460981
I0403 03:20:55.421530 16972 solver.cpp:244]     Train net output #0: loss = 0.00460976 (* 1 = 0.00460976 loss)
I0403 03:20:55.604683 16972 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I0403 03:20:59.360396 16972 solver.cpp:228] Iteration 1695, loss = 0.000556322
I0403 03:20:59.366089 16972 solver.cpp:244]     Train net output #0: loss = 0.000556277 (* 1 = 0.000556277 loss)
I0403 03:20:59.540503 16972 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I0403 03:21:03.414682 16972 solver.cpp:228] Iteration 1700, loss = 0.00895343
I0403 03:21:03.420092 16972 solver.cpp:244]     Train net output #0: loss = 0.00895339 (* 1 = 0.00895339 loss)
I0403 03:21:03.598727 16972 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0403 03:21:07.358144 16972 solver.cpp:228] Iteration 1705, loss = 0.00399829
I0403 03:21:07.363123 16972 solver.cpp:244]     Train net output #0: loss = 0.00399825 (* 1 = 0.00399825 loss)
I0403 03:21:07.576850 16972 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I0403 03:21:11.147747 16972 solver.cpp:228] Iteration 1710, loss = 0.00113809
I0403 03:21:11.152912 16972 solver.cpp:244]     Train net output #0: loss = 0.00113804 (* 1 = 0.00113804 loss)
I0403 03:21:11.355425 16972 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I0403 03:21:15.001694 16972 solver.cpp:228] Iteration 1715, loss = 0.00350393
I0403 03:21:15.008318 16972 solver.cpp:244]     Train net output #0: loss = 0.00350389 (* 1 = 0.00350389 loss)
I0403 03:21:15.193320 16972 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I0403 03:21:18.867139 16972 solver.cpp:228] Iteration 1720, loss = 0.000305666
I0403 03:21:18.873745 16972 solver.cpp:244]     Train net output #0: loss = 0.000305622 (* 1 = 0.000305622 loss)
I0403 03:21:19.057350 16972 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I0403 03:21:22.759331 16972 solver.cpp:228] Iteration 1725, loss = 0.00230294
I0403 03:21:22.765604 16972 solver.cpp:244]     Train net output #0: loss = 0.0023029 (* 1 = 0.0023029 loss)
I0403 03:21:22.945408 16972 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I0403 03:21:24.521864 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1728.caffemodel
I0403 03:21:27.290308 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1728.solverstate
I0403 03:21:29.184430 16972 solver.cpp:337] Iteration 1728, Testing net (#0)
I0403 03:23:10.251513 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973872
I0403 03:23:10.259223 16972 solver.cpp:404]     Test net output #1: loss = 0.111943 (* 1 = 0.111943 loss)
I0403 03:23:12.391696 16972 solver.cpp:228] Iteration 1730, loss = 0.00077581
I0403 03:23:12.398890 16972 solver.cpp:244]     Train net output #0: loss = 0.000775765 (* 1 = 0.000775765 loss)
I0403 03:23:12.583623 16972 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I0403 03:23:16.285578 16972 solver.cpp:228] Iteration 1735, loss = 0.000507345
I0403 03:23:16.290688 16972 solver.cpp:244]     Train net output #0: loss = 0.0005073 (* 1 = 0.0005073 loss)
I0403 03:23:16.483580 16972 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I0403 03:23:20.128752 16972 solver.cpp:228] Iteration 1740, loss = 0.000232959
I0403 03:23:20.134338 16972 solver.cpp:244]     Train net output #0: loss = 0.000232914 (* 1 = 0.000232914 loss)
I0403 03:23:20.324838 16972 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I0403 03:23:23.970896 16972 solver.cpp:228] Iteration 1745, loss = 0.0180626
I0403 03:23:23.978483 16972 solver.cpp:244]     Train net output #0: loss = 0.0180626 (* 1 = 0.0180626 loss)
I0403 03:23:24.242684 16972 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I0403 03:23:27.890780 16972 solver.cpp:228] Iteration 1750, loss = 0.0110837
I0403 03:23:27.897711 16972 solver.cpp:244]     Train net output #0: loss = 0.0110837 (* 1 = 0.0110837 loss)
I0403 03:23:28.069443 16972 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0403 03:23:31.874478 16972 solver.cpp:228] Iteration 1755, loss = 4.07088e-05
I0403 03:23:31.881233 16972 solver.cpp:244]     Train net output #0: loss = 4.06625e-05 (* 1 = 4.06625e-05 loss)
I0403 03:23:32.051712 16972 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I0403 03:23:35.767761 16972 solver.cpp:228] Iteration 1760, loss = 0.00077617
I0403 03:23:35.773831 16972 solver.cpp:244]     Train net output #0: loss = 0.000776124 (* 1 = 0.000776124 loss)
I0403 03:23:35.957281 16972 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I0403 03:23:39.667554 16972 solver.cpp:228] Iteration 1765, loss = 0.000950043
I0403 03:23:39.674031 16972 solver.cpp:244]     Train net output #0: loss = 0.000949997 (* 1 = 0.000949997 loss)
I0403 03:23:39.853325 16972 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I0403 03:23:43.696108 16972 solver.cpp:228] Iteration 1770, loss = 0.00188779
I0403 03:23:43.703209 16972 solver.cpp:244]     Train net output #0: loss = 0.00188774 (* 1 = 0.00188774 loss)
I0403 03:23:43.886555 16972 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I0403 03:23:47.580888 16972 solver.cpp:228] Iteration 1775, loss = 0.00177995
I0403 03:23:47.590237 16972 solver.cpp:244]     Train net output #0: loss = 0.00177991 (* 1 = 0.00177991 loss)
I0403 03:23:47.784560 16972 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I0403 03:23:51.438624 16972 solver.cpp:228] Iteration 1780, loss = 0.000252512
I0403 03:23:51.445389 16972 solver.cpp:244]     Train net output #0: loss = 0.000252465 (* 1 = 0.000252465 loss)
I0403 03:23:51.621829 16972 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I0403 03:23:55.391618 16972 solver.cpp:228] Iteration 1785, loss = 7.71037e-05
I0403 03:23:55.400208 16972 solver.cpp:244]     Train net output #0: loss = 7.70567e-05 (* 1 = 7.70567e-05 loss)
I0403 03:23:55.586716 16972 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I0403 03:23:59.210597 16972 solver.cpp:228] Iteration 1790, loss = 0.0037852
I0403 03:23:59.218197 16972 solver.cpp:244]     Train net output #0: loss = 0.00378515 (* 1 = 0.00378515 loss)
I0403 03:23:59.437775 16972 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I0403 03:24:03.022894 16972 solver.cpp:228] Iteration 1795, loss = 0.00160343
I0403 03:24:03.029099 16972 solver.cpp:244]     Train net output #0: loss = 0.00160338 (* 1 = 0.00160338 loss)
I0403 03:24:03.240748 16972 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I0403 03:24:06.893548 16972 solver.cpp:228] Iteration 1800, loss = 6.07306e-05
I0403 03:24:06.898928 16972 solver.cpp:244]     Train net output #0: loss = 6.06832e-05 (* 1 = 6.06832e-05 loss)
I0403 03:24:07.084153 16972 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0403 03:24:10.745632 16972 solver.cpp:228] Iteration 1805, loss = 0.000803168
I0403 03:24:10.753897 16972 solver.cpp:244]     Train net output #0: loss = 0.000803121 (* 1 = 0.000803121 loss)
I0403 03:24:10.922433 16972 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I0403 03:24:14.612851 16972 solver.cpp:228] Iteration 1810, loss = 0.00155121
I0403 03:24:14.618996 16972 solver.cpp:244]     Train net output #0: loss = 0.00155116 (* 1 = 0.00155116 loss)
I0403 03:24:14.812227 16972 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I0403 03:24:18.467147 16972 solver.cpp:228] Iteration 1815, loss = 0.00107402
I0403 03:24:18.473613 16972 solver.cpp:244]     Train net output #0: loss = 0.00107397 (* 1 = 0.00107397 loss)
I0403 03:24:18.662147 16972 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I0403 03:24:22.313179 16972 solver.cpp:228] Iteration 1820, loss = 0.000709523
I0403 03:24:22.318900 16972 solver.cpp:244]     Train net output #0: loss = 0.000709475 (* 1 = 0.000709475 loss)
I0403 03:24:22.506602 16972 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I0403 03:24:26.119689 16972 solver.cpp:228] Iteration 1825, loss = 0.000143206
I0403 03:24:26.125972 16972 solver.cpp:244]     Train net output #0: loss = 0.000143158 (* 1 = 0.000143158 loss)
I0403 03:24:26.304421 16972 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I0403 03:24:29.910879 16972 solver.cpp:228] Iteration 1830, loss = 0.00110127
I0403 03:24:29.917711 16972 solver.cpp:244]     Train net output #0: loss = 0.00110122 (* 1 = 0.00110122 loss)
I0403 03:24:30.104595 16972 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I0403 03:24:33.732970 16972 solver.cpp:228] Iteration 1835, loss = 0.00168963
I0403 03:24:33.738396 16972 solver.cpp:244]     Train net output #0: loss = 0.00168959 (* 1 = 0.00168959 loss)
I0403 03:24:33.920685 16972 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I0403 03:24:33.920933 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1836.caffemodel
I0403 03:24:36.756347 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1836.solverstate
I0403 03:24:38.667130 16972 solver.cpp:337] Iteration 1836, Testing net (#0)
I0403 03:26:19.715781 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973917
I0403 03:26:19.723229 16972 solver.cpp:404]     Test net output #1: loss = 0.110038 (* 1 = 0.110038 loss)
I0403 03:26:23.589902 16972 solver.cpp:228] Iteration 1840, loss = 0.00696983
I0403 03:26:23.598213 16972 solver.cpp:244]     Train net output #0: loss = 0.00696978 (* 1 = 0.00696978 loss)
I0403 03:26:23.786155 16972 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I0403 03:26:27.453040 16972 solver.cpp:228] Iteration 1845, loss = 0.00549616
I0403 03:26:27.458822 16972 solver.cpp:244]     Train net output #0: loss = 0.00549611 (* 1 = 0.00549611 loss)
I0403 03:26:27.636921 16972 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I0403 03:26:31.324538 16972 solver.cpp:228] Iteration 1850, loss = 0.000269659
I0403 03:26:31.330776 16972 solver.cpp:244]     Train net output #0: loss = 0.00026961 (* 1 = 0.00026961 loss)
I0403 03:26:31.505460 16972 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0403 03:26:35.340445 16972 solver.cpp:228] Iteration 1855, loss = 0.000601297
I0403 03:26:35.346628 16972 solver.cpp:244]     Train net output #0: loss = 0.000601249 (* 1 = 0.000601249 loss)
I0403 03:26:35.557801 16972 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I0403 03:26:39.262702 16972 solver.cpp:228] Iteration 1860, loss = 0.0139628
I0403 03:26:39.268708 16972 solver.cpp:244]     Train net output #0: loss = 0.0139628 (* 1 = 0.0139628 loss)
I0403 03:26:39.445070 16972 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I0403 03:26:43.263819 16972 solver.cpp:228] Iteration 1865, loss = 0.00337838
I0403 03:26:43.270591 16972 solver.cpp:244]     Train net output #0: loss = 0.00337833 (* 1 = 0.00337833 loss)
I0403 03:26:43.453614 16972 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I0403 03:26:47.155758 16972 solver.cpp:228] Iteration 1870, loss = 0.00210714
I0403 03:26:47.161903 16972 solver.cpp:244]     Train net output #0: loss = 0.00210709 (* 1 = 0.00210709 loss)
I0403 03:26:47.342669 16972 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I0403 03:26:51.120993 16972 solver.cpp:228] Iteration 1875, loss = 0.00576374
I0403 03:26:51.129518 16972 solver.cpp:244]     Train net output #0: loss = 0.0057637 (* 1 = 0.0057637 loss)
I0403 03:26:51.299010 16972 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0403 03:26:55.018223 16972 solver.cpp:228] Iteration 1880, loss = 0.00111132
I0403 03:26:55.026552 16972 solver.cpp:244]     Train net output #0: loss = 0.00111127 (* 1 = 0.00111127 loss)
I0403 03:26:55.212308 16972 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I0403 03:26:58.915817 16972 solver.cpp:228] Iteration 1885, loss = 0.00173038
I0403 03:26:58.922282 16972 solver.cpp:244]     Train net output #0: loss = 0.00173034 (* 1 = 0.00173034 loss)
I0403 03:26:59.134057 16972 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I0403 03:27:02.904557 16972 solver.cpp:228] Iteration 1890, loss = 0.000248791
I0403 03:27:02.910193 16972 solver.cpp:244]     Train net output #0: loss = 0.000248744 (* 1 = 0.000248744 loss)
I0403 03:27:03.085113 16972 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I0403 03:27:06.786165 16972 solver.cpp:228] Iteration 1895, loss = 0.00580838
I0403 03:27:06.791460 16972 solver.cpp:244]     Train net output #0: loss = 0.00580834 (* 1 = 0.00580834 loss)
I0403 03:27:06.977159 16972 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I0403 03:27:10.683738 16972 solver.cpp:228] Iteration 1900, loss = 0.00178815
I0403 03:27:10.690529 16972 solver.cpp:244]     Train net output #0: loss = 0.0017881 (* 1 = 0.0017881 loss)
I0403 03:27:10.863515 16972 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0403 03:27:14.651533 16972 solver.cpp:228] Iteration 1905, loss = 0.000218125
I0403 03:27:14.659838 16972 solver.cpp:244]     Train net output #0: loss = 0.000218077 (* 1 = 0.000218077 loss)
I0403 03:27:14.850481 16972 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I0403 03:27:18.495529 16972 solver.cpp:228] Iteration 1910, loss = 0.00207497
I0403 03:27:18.501054 16972 solver.cpp:244]     Train net output #0: loss = 0.00207492 (* 1 = 0.00207492 loss)
I0403 03:27:18.673689 16972 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I0403 03:27:22.408610 16972 solver.cpp:228] Iteration 1915, loss = 0.0269255
I0403 03:27:22.415722 16972 solver.cpp:244]     Train net output #0: loss = 0.0269254 (* 1 = 0.0269254 loss)
I0403 03:27:22.623082 16972 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I0403 03:27:26.274893 16972 solver.cpp:228] Iteration 1920, loss = 5.51513e-05
I0403 03:27:26.282809 16972 solver.cpp:244]     Train net output #0: loss = 5.51041e-05 (* 1 = 5.51041e-05 loss)
I0403 03:27:26.471917 16972 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I0403 03:27:30.157835 16972 solver.cpp:228] Iteration 1925, loss = 0.00187164
I0403 03:27:30.164438 16972 solver.cpp:244]     Train net output #0: loss = 0.0018716 (* 1 = 0.0018716 loss)
I0403 03:27:30.364725 16972 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I0403 03:27:34.018275 16972 solver.cpp:228] Iteration 1930, loss = 0.0158778
I0403 03:27:34.026834 16972 solver.cpp:244]     Train net output #0: loss = 0.0158778 (* 1 = 0.0158778 loss)
I0403 03:27:34.204488 16972 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I0403 03:27:37.960528 16972 solver.cpp:228] Iteration 1935, loss = 0.0016799
I0403 03:27:37.969835 16972 solver.cpp:244]     Train net output #0: loss = 0.00167986 (* 1 = 0.00167986 loss)
I0403 03:27:38.151011 16972 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I0403 03:27:41.941073 16972 solver.cpp:228] Iteration 1940, loss = 0.000556526
I0403 03:27:41.945531 16972 solver.cpp:244]     Train net output #0: loss = 0.00055648 (* 1 = 0.00055648 loss)
I0403 03:27:42.148357 16972 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I0403 03:27:44.431746 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1944.caffemodel
I0403 03:27:47.218809 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_1944.solverstate
I0403 03:27:49.107522 16972 solver.cpp:337] Iteration 1944, Testing net (#0)
I0403 03:29:30.158805 16972 solver.cpp:404]     Test net output #0: accuracy = 0.974125
I0403 03:29:30.166802 16972 solver.cpp:404]     Test net output #1: loss = 0.110354 (* 1 = 0.110354 loss)
I0403 03:29:31.491390 16972 solver.cpp:228] Iteration 1945, loss = 0.00296764
I0403 03:29:31.498735 16972 solver.cpp:244]     Train net output #0: loss = 0.00296759 (* 1 = 0.00296759 loss)
I0403 03:29:31.671025 16972 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I0403 03:29:35.347983 16972 solver.cpp:228] Iteration 1950, loss = 0.000165313
I0403 03:29:35.355161 16972 solver.cpp:244]     Train net output #0: loss = 0.000165268 (* 1 = 0.000165268 loss)
I0403 03:29:35.541785 16972 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0403 03:29:39.223042 16972 solver.cpp:228] Iteration 1955, loss = 0.000244351
I0403 03:29:39.228466 16972 solver.cpp:244]     Train net output #0: loss = 0.000244305 (* 1 = 0.000244305 loss)
I0403 03:29:39.431104 16972 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I0403 03:29:43.217284 16972 solver.cpp:228] Iteration 1960, loss = 0.00518086
I0403 03:29:43.224405 16972 solver.cpp:244]     Train net output #0: loss = 0.00518082 (* 1 = 0.00518082 loss)
I0403 03:29:43.427731 16972 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I0403 03:29:47.120259 16972 solver.cpp:228] Iteration 1965, loss = 0.0286471
I0403 03:29:47.127239 16972 solver.cpp:244]     Train net output #0: loss = 0.0286471 (* 1 = 0.0286471 loss)
I0403 03:29:47.293705 16972 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I0403 03:29:51.100632 16972 solver.cpp:228] Iteration 1970, loss = 0.000335167
I0403 03:29:51.109469 16972 solver.cpp:244]     Train net output #0: loss = 0.00033512 (* 1 = 0.00033512 loss)
I0403 03:29:51.291574 16972 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I0403 03:29:54.935556 16972 solver.cpp:228] Iteration 1975, loss = 0.000566796
I0403 03:29:54.941654 16972 solver.cpp:244]     Train net output #0: loss = 0.000566748 (* 1 = 0.000566748 loss)
I0403 03:29:55.148039 16972 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I0403 03:29:58.825073 16972 solver.cpp:228] Iteration 1980, loss = 0.0012666
I0403 03:29:58.830945 16972 solver.cpp:244]     Train net output #0: loss = 0.00126655 (* 1 = 0.00126655 loss)
I0403 03:29:59.051638 16972 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I0403 03:30:02.827569 16972 solver.cpp:228] Iteration 1985, loss = 0.00522328
I0403 03:30:02.834003 16972 solver.cpp:244]     Train net output #0: loss = 0.00522323 (* 1 = 0.00522323 loss)
I0403 03:30:03.026677 16972 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I0403 03:30:06.640765 16972 solver.cpp:228] Iteration 1990, loss = 0.000332956
I0403 03:30:06.646040 16972 solver.cpp:244]     Train net output #0: loss = 0.000332909 (* 1 = 0.000332909 loss)
I0403 03:30:06.837481 16972 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I0403 03:30:10.465710 16972 solver.cpp:228] Iteration 1995, loss = 0.000262586
I0403 03:30:10.472262 16972 solver.cpp:244]     Train net output #0: loss = 0.000262539 (* 1 = 0.000262539 loss)
I0403 03:30:10.661828 16972 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I0403 03:30:14.317368 16972 solver.cpp:228] Iteration 2000, loss = 0.00109017
I0403 03:30:14.323879 16972 solver.cpp:244]     Train net output #0: loss = 0.00109012 (* 1 = 0.00109012 loss)
I0403 03:30:14.501482 16972 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0403 03:30:18.239940 16972 solver.cpp:228] Iteration 2005, loss = 0.000274737
I0403 03:30:18.246637 16972 solver.cpp:244]     Train net output #0: loss = 0.00027469 (* 1 = 0.00027469 loss)
I0403 03:30:18.473906 16972 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I0403 03:30:22.124029 16972 solver.cpp:228] Iteration 2010, loss = 0.00185608
I0403 03:30:22.129384 16972 solver.cpp:244]     Train net output #0: loss = 0.00185603 (* 1 = 0.00185603 loss)
I0403 03:30:22.330766 16972 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I0403 03:30:25.967849 16972 solver.cpp:228] Iteration 2015, loss = 0.000352338
I0403 03:30:25.973145 16972 solver.cpp:244]     Train net output #0: loss = 0.000352291 (* 1 = 0.000352291 loss)
I0403 03:30:26.177949 16972 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I0403 03:30:29.845544 16972 solver.cpp:228] Iteration 2020, loss = 0.00226454
I0403 03:30:29.852645 16972 solver.cpp:244]     Train net output #0: loss = 0.00226449 (* 1 = 0.00226449 loss)
I0403 03:30:30.043995 16972 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I0403 03:30:33.720535 16972 solver.cpp:228] Iteration 2025, loss = 0.0012401
I0403 03:30:33.726274 16972 solver.cpp:244]     Train net output #0: loss = 0.00124005 (* 1 = 0.00124005 loss)
I0403 03:30:33.930799 16972 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I0403 03:30:37.609205 16972 solver.cpp:228] Iteration 2030, loss = 0.0123884
I0403 03:30:37.615041 16972 solver.cpp:244]     Train net output #0: loss = 0.0123884 (* 1 = 0.0123884 loss)
I0403 03:30:37.847298 16972 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I0403 03:30:41.581495 16972 solver.cpp:228] Iteration 2035, loss = 0.000127863
I0403 03:30:41.587209 16972 solver.cpp:244]     Train net output #0: loss = 0.000127816 (* 1 = 0.000127816 loss)
I0403 03:30:41.788266 16972 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I0403 03:30:45.414044 16972 solver.cpp:228] Iteration 2040, loss = 0.00348837
I0403 03:30:45.419761 16972 solver.cpp:244]     Train net output #0: loss = 0.00348832 (* 1 = 0.00348832 loss)
I0403 03:30:45.593130 16972 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I0403 03:30:49.325026 16972 solver.cpp:228] Iteration 2045, loss = 0.00249466
I0403 03:30:49.330965 16972 solver.cpp:244]     Train net output #0: loss = 0.00249461 (* 1 = 0.00249461 loss)
I0403 03:30:49.517408 16972 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I0403 03:30:53.184574 16972 solver.cpp:228] Iteration 2050, loss = 0.000631957
I0403 03:30:53.191496 16972 solver.cpp:244]     Train net output #0: loss = 0.00063191 (* 1 = 0.00063191 loss)
I0403 03:30:53.370857 16972 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0403 03:30:54.167163 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2052.caffemodel
I0403 03:30:56.959761 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2052.solverstate
I0403 03:30:58.872539 16972 solver.cpp:337] Iteration 2052, Testing net (#0)
I0403 03:32:39.936844 16972 solver.cpp:404]     Test net output #0: accuracy = 0.974309
I0403 03:32:39.943660 16972 solver.cpp:404]     Test net output #1: loss = 0.110285 (* 1 = 0.110285 loss)
I0403 03:32:42.845852 16972 solver.cpp:228] Iteration 2055, loss = 0.00218216
I0403 03:32:42.852998 16972 solver.cpp:244]     Train net output #0: loss = 0.00218212 (* 1 = 0.00218212 loss)
I0403 03:32:43.020632 16972 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I0403 03:32:46.860429 16972 solver.cpp:228] Iteration 2060, loss = 0.00844197
I0403 03:32:46.866605 16972 solver.cpp:244]     Train net output #0: loss = 0.00844192 (* 1 = 0.00844192 loss)
I0403 03:32:47.062790 16972 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I0403 03:32:50.679939 16972 solver.cpp:228] Iteration 2065, loss = 0.000540163
I0403 03:32:50.686473 16972 solver.cpp:244]     Train net output #0: loss = 0.000540116 (* 1 = 0.000540116 loss)
I0403 03:32:50.948768 16972 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I0403 03:32:54.630133 16972 solver.cpp:228] Iteration 2070, loss = 0.000342369
I0403 03:32:54.638594 16972 solver.cpp:244]     Train net output #0: loss = 0.000342322 (* 1 = 0.000342322 loss)
I0403 03:32:54.787690 16972 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I0403 03:32:58.529500 16972 solver.cpp:228] Iteration 2075, loss = 8.70101e-05
I0403 03:32:58.538260 16972 solver.cpp:244]     Train net output #0: loss = 8.69624e-05 (* 1 = 8.69624e-05 loss)
I0403 03:32:58.722784 16972 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I0403 03:33:02.365645 16972 solver.cpp:228] Iteration 2080, loss = 0.000399279
I0403 03:33:02.372786 16972 solver.cpp:244]     Train net output #0: loss = 0.000399231 (* 1 = 0.000399231 loss)
I0403 03:33:02.551307 16972 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I0403 03:33:06.280998 16972 solver.cpp:228] Iteration 2085, loss = 0.00327475
I0403 03:33:06.286825 16972 solver.cpp:244]     Train net output #0: loss = 0.0032747 (* 1 = 0.0032747 loss)
I0403 03:33:06.462347 16972 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I0403 03:33:10.217612 16972 solver.cpp:228] Iteration 2090, loss = 0.00752495
I0403 03:33:10.224232 16972 solver.cpp:244]     Train net output #0: loss = 0.0075249 (* 1 = 0.0075249 loss)
I0403 03:33:10.424808 16972 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I0403 03:33:14.151149 16972 solver.cpp:228] Iteration 2095, loss = 0.000330482
I0403 03:33:14.157557 16972 solver.cpp:244]     Train net output #0: loss = 0.000330434 (* 1 = 0.000330434 loss)
I0403 03:33:14.365305 16972 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I0403 03:33:18.008651 16972 solver.cpp:228] Iteration 2100, loss = 0.00897289
I0403 03:33:18.015130 16972 solver.cpp:244]     Train net output #0: loss = 0.00897285 (* 1 = 0.00897285 loss)
I0403 03:33:18.200224 16972 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0403 03:33:21.913976 16972 solver.cpp:228] Iteration 2105, loss = 0.00219933
I0403 03:33:21.921212 16972 solver.cpp:244]     Train net output #0: loss = 0.00219929 (* 1 = 0.00219929 loss)
I0403 03:33:22.129050 16972 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I0403 03:33:25.829650 16972 solver.cpp:228] Iteration 2110, loss = 0.00190229
I0403 03:33:25.835813 16972 solver.cpp:244]     Train net output #0: loss = 0.00190224 (* 1 = 0.00190224 loss)
I0403 03:33:25.990207 16972 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I0403 03:33:29.765672 16972 solver.cpp:228] Iteration 2115, loss = 0.0108724
I0403 03:33:29.772567 16972 solver.cpp:244]     Train net output #0: loss = 0.0108724 (* 1 = 0.0108724 loss)
I0403 03:33:29.963315 16972 sgd_solver.cpp:106] Iteration 2115, lr = 0.0005
I0403 03:33:33.602917 16972 solver.cpp:228] Iteration 2120, loss = 0.000384255
I0403 03:33:33.610057 16972 solver.cpp:244]     Train net output #0: loss = 0.000384208 (* 1 = 0.000384208 loss)
I0403 03:33:33.810037 16972 sgd_solver.cpp:106] Iteration 2120, lr = 0.0005
I0403 03:33:37.435132 16972 solver.cpp:228] Iteration 2125, loss = 0.000331183
I0403 03:33:37.441072 16972 solver.cpp:244]     Train net output #0: loss = 0.000331136 (* 1 = 0.000331136 loss)
I0403 03:33:37.616062 16972 sgd_solver.cpp:106] Iteration 2125, lr = 0.0005
I0403 03:33:41.363211 16972 solver.cpp:228] Iteration 2130, loss = 0.001233
I0403 03:33:41.369158 16972 solver.cpp:244]     Train net output #0: loss = 0.00123295 (* 1 = 0.00123295 loss)
I0403 03:33:41.532394 16972 sgd_solver.cpp:106] Iteration 2130, lr = 0.0005
I0403 03:33:45.358476 16972 solver.cpp:228] Iteration 2135, loss = 0.00101295
I0403 03:33:45.366034 16972 solver.cpp:244]     Train net output #0: loss = 0.00101291 (* 1 = 0.00101291 loss)
I0403 03:33:45.546118 16972 sgd_solver.cpp:106] Iteration 2135, lr = 0.0005
I0403 03:33:49.328940 16972 solver.cpp:228] Iteration 2140, loss = 0.000155091
I0403 03:33:49.334936 16972 solver.cpp:244]     Train net output #0: loss = 0.000155046 (* 1 = 0.000155046 loss)
I0403 03:33:49.526631 16972 sgd_solver.cpp:106] Iteration 2140, lr = 0.0005
I0403 03:33:53.211735 16972 solver.cpp:228] Iteration 2145, loss = 0.000903772
I0403 03:33:53.218588 16972 solver.cpp:244]     Train net output #0: loss = 0.000903727 (* 1 = 0.000903727 loss)
I0403 03:33:53.395860 16972 sgd_solver.cpp:106] Iteration 2145, lr = 0.0005
I0403 03:33:57.059316 16972 solver.cpp:228] Iteration 2150, loss = 0.00104832
I0403 03:33:57.059401 16972 solver.cpp:244]     Train net output #0: loss = 0.00104828 (* 1 = 0.00104828 loss)
I0403 03:33:57.250505 16972 sgd_solver.cpp:106] Iteration 2150, lr = 0.0005
I0403 03:34:00.971222 16972 solver.cpp:228] Iteration 2155, loss = 0.00271524
I0403 03:34:00.971313 16972 solver.cpp:244]     Train net output #0: loss = 0.0027152 (* 1 = 0.0027152 loss)
I0403 03:34:01.158512 16972 sgd_solver.cpp:106] Iteration 2155, lr = 0.0005
I0403 03:34:04.260907 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2160.caffemodel
I0403 03:34:09.894502 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2160.solverstate
I0403 03:34:13.213587 16972 solver.cpp:337] Iteration 2160, Testing net (#0)
I0403 03:35:54.269603 16972 solver.cpp:404]     Test net output #0: accuracy = 0.974056
I0403 03:35:54.269903 16972 solver.cpp:404]     Test net output #1: loss = 0.112501 (* 1 = 0.112501 loss)
I0403 03:35:54.801331 16972 solver.cpp:228] Iteration 2160, loss = 0.000338788
I0403 03:35:54.801414 16972 solver.cpp:244]     Train net output #0: loss = 0.000338742 (* 1 = 0.000338742 loss)
I0403 03:35:55.003506 16972 sgd_solver.cpp:106] Iteration 2160, lr = 0.0005
I0403 03:35:58.676025 16972 solver.cpp:228] Iteration 2165, loss = 0.000410954
I0403 03:35:58.676113 16972 solver.cpp:244]     Train net output #0: loss = 0.000410908 (* 1 = 0.000410908 loss)
I0403 03:35:58.870142 16972 sgd_solver.cpp:106] Iteration 2165, lr = 0.0005
I0403 03:36:02.516119 16972 solver.cpp:228] Iteration 2170, loss = 0.00137498
I0403 03:36:02.516204 16972 solver.cpp:244]     Train net output #0: loss = 0.00137493 (* 1 = 0.00137493 loss)
I0403 03:36:02.713135 16972 sgd_solver.cpp:106] Iteration 2170, lr = 5e-05
I0403 03:36:06.447157 16972 solver.cpp:228] Iteration 2175, loss = 0.000149656
I0403 03:36:06.447257 16972 solver.cpp:244]     Train net output #0: loss = 0.00014961 (* 1 = 0.00014961 loss)
I0403 03:36:06.655526 16972 sgd_solver.cpp:106] Iteration 2175, lr = 5e-05
I0403 03:36:10.361240 16972 solver.cpp:228] Iteration 2180, loss = 0.00117905
I0403 03:36:10.361333 16972 solver.cpp:244]     Train net output #0: loss = 0.00117901 (* 1 = 0.00117901 loss)
I0403 03:36:10.556602 16972 sgd_solver.cpp:106] Iteration 2180, lr = 5e-05
I0403 03:36:14.315654 16972 solver.cpp:228] Iteration 2185, loss = 0.000182284
I0403 03:36:14.315743 16972 solver.cpp:244]     Train net output #0: loss = 0.000182238 (* 1 = 0.000182238 loss)
I0403 03:36:14.496798 16972 sgd_solver.cpp:106] Iteration 2185, lr = 5e-05
I0403 03:36:18.241096 16972 solver.cpp:228] Iteration 2190, loss = 0.000272267
I0403 03:36:18.241183 16972 solver.cpp:244]     Train net output #0: loss = 0.000272221 (* 1 = 0.000272221 loss)
I0403 03:36:18.415172 16972 sgd_solver.cpp:106] Iteration 2190, lr = 5e-05
I0403 03:36:22.297683 16972 solver.cpp:228] Iteration 2195, loss = 0.00154268
I0403 03:36:22.297771 16972 solver.cpp:244]     Train net output #0: loss = 0.00154264 (* 1 = 0.00154264 loss)
I0403 03:36:22.475250 16972 sgd_solver.cpp:106] Iteration 2195, lr = 5e-05
I0403 03:36:26.188124 16972 solver.cpp:228] Iteration 2200, loss = 0.000373666
I0403 03:36:26.188452 16972 solver.cpp:244]     Train net output #0: loss = 0.00037362 (* 1 = 0.00037362 loss)
I0403 03:36:26.387873 16972 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0403 03:36:30.057169 16972 solver.cpp:228] Iteration 2205, loss = 0.00183944
I0403 03:36:30.057255 16972 solver.cpp:244]     Train net output #0: loss = 0.0018394 (* 1 = 0.0018394 loss)
I0403 03:36:30.244132 16972 sgd_solver.cpp:106] Iteration 2205, lr = 5e-05
I0403 03:36:33.936215 16972 solver.cpp:228] Iteration 2210, loss = 0.0030699
I0403 03:36:33.936316 16972 solver.cpp:244]     Train net output #0: loss = 0.00306986 (* 1 = 0.00306986 loss)
I0403 03:36:34.121492 16972 sgd_solver.cpp:106] Iteration 2210, lr = 5e-05
I0403 03:36:37.778755 16972 solver.cpp:228] Iteration 2215, loss = 0.00390521
I0403 03:36:37.778849 16972 solver.cpp:244]     Train net output #0: loss = 0.00390516 (* 1 = 0.00390516 loss)
I0403 03:36:37.985435 16972 sgd_solver.cpp:106] Iteration 2215, lr = 5e-05
I0403 03:36:41.649485 16972 solver.cpp:228] Iteration 2220, loss = 0.0223359
I0403 03:36:41.649572 16972 solver.cpp:244]     Train net output #0: loss = 0.0223359 (* 1 = 0.0223359 loss)
I0403 03:36:41.835413 16972 sgd_solver.cpp:106] Iteration 2220, lr = 5e-05
I0403 03:36:45.544529 16972 solver.cpp:228] Iteration 2225, loss = 0.00179201
I0403 03:36:45.544618 16972 solver.cpp:244]     Train net output #0: loss = 0.00179196 (* 1 = 0.00179196 loss)
I0403 03:36:45.728896 16972 sgd_solver.cpp:106] Iteration 2225, lr = 5e-05
I0403 03:36:49.447496 16972 solver.cpp:228] Iteration 2230, loss = 0.000193054
I0403 03:36:49.447585 16972 solver.cpp:244]     Train net output #0: loss = 0.000193008 (* 1 = 0.000193008 loss)
I0403 03:36:49.645813 16972 sgd_solver.cpp:106] Iteration 2230, lr = 5e-05
I0403 03:36:53.313411 16972 solver.cpp:228] Iteration 2235, loss = 0.00132089
I0403 03:36:53.313498 16972 solver.cpp:244]     Train net output #0: loss = 0.00132084 (* 1 = 0.00132084 loss)
I0403 03:36:53.476188 16972 sgd_solver.cpp:106] Iteration 2235, lr = 5e-05
I0403 03:36:57.195507 16972 solver.cpp:228] Iteration 2240, loss = 0.000493786
I0403 03:36:57.195811 16972 solver.cpp:244]     Train net output #0: loss = 0.00049374 (* 1 = 0.00049374 loss)
I0403 03:36:57.380656 16972 sgd_solver.cpp:106] Iteration 2240, lr = 5e-05
I0403 03:37:01.232298 16972 solver.cpp:228] Iteration 2245, loss = 0.00045666
I0403 03:37:01.232388 16972 solver.cpp:244]     Train net output #0: loss = 0.000456615 (* 1 = 0.000456615 loss)
I0403 03:37:01.426070 16972 sgd_solver.cpp:106] Iteration 2245, lr = 5e-05
I0403 03:37:05.195293 16972 solver.cpp:228] Iteration 2250, loss = 0.00216297
I0403 03:37:05.195384 16972 solver.cpp:244]     Train net output #0: loss = 0.00216292 (* 1 = 0.00216292 loss)
I0403 03:37:05.389421 16972 sgd_solver.cpp:106] Iteration 2250, lr = 5e-05
I0403 03:37:09.046761 16972 solver.cpp:228] Iteration 2255, loss = 0.00462171
I0403 03:37:09.046859 16972 solver.cpp:244]     Train net output #0: loss = 0.00462167 (* 1 = 0.00462167 loss)
I0403 03:37:09.354125 16972 sgd_solver.cpp:106] Iteration 2255, lr = 5e-05
I0403 03:37:13.198493 16972 solver.cpp:228] Iteration 2260, loss = 0.00177149
I0403 03:37:13.198581 16972 solver.cpp:244]     Train net output #0: loss = 0.00177145 (* 1 = 0.00177145 loss)
I0403 03:37:13.382746 16972 sgd_solver.cpp:106] Iteration 2260, lr = 5e-05
I0403 03:37:17.098274 16972 solver.cpp:228] Iteration 2265, loss = 0.000986773
I0403 03:37:17.098366 16972 solver.cpp:244]     Train net output #0: loss = 0.000986728 (* 1 = 0.000986728 loss)
I0403 03:37:17.297591 16972 sgd_solver.cpp:106] Iteration 2265, lr = 5e-05
I0403 03:37:18.853977 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2268.caffemodel
I0403 03:37:21.646124 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2268.solverstate
I0403 03:37:23.525287 16972 solver.cpp:337] Iteration 2268, Testing net (#0)
I0403 03:39:04.616773 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973964
I0403 03:39:04.617040 16972 solver.cpp:404]     Test net output #1: loss = 0.112779 (* 1 = 0.112779 loss)
I0403 03:39:06.731109 16972 solver.cpp:228] Iteration 2270, loss = 0.000569638
I0403 03:39:06.731195 16972 solver.cpp:244]     Train net output #0: loss = 0.000569593 (* 1 = 0.000569593 loss)
I0403 03:39:06.935487 16972 sgd_solver.cpp:106] Iteration 2270, lr = 5e-05
I0403 03:39:10.651917 16972 solver.cpp:228] Iteration 2275, loss = 0.000685568
I0403 03:39:10.652005 16972 solver.cpp:244]     Train net output #0: loss = 0.000685522 (* 1 = 0.000685522 loss)
I0403 03:39:10.837630 16972 sgd_solver.cpp:106] Iteration 2275, lr = 5e-05
I0403 03:39:14.547719 16972 solver.cpp:228] Iteration 2280, loss = 0.000774006
I0403 03:39:14.547808 16972 solver.cpp:244]     Train net output #0: loss = 0.000773961 (* 1 = 0.000773961 loss)
I0403 03:39:14.747756 16972 sgd_solver.cpp:106] Iteration 2280, lr = 5e-05
I0403 03:39:18.485600 16972 solver.cpp:228] Iteration 2285, loss = 0.0162167
I0403 03:39:18.485697 16972 solver.cpp:244]     Train net output #0: loss = 0.0162167 (* 1 = 0.0162167 loss)
I0403 03:39:18.706686 16972 sgd_solver.cpp:106] Iteration 2285, lr = 5e-05
I0403 03:39:22.353885 16972 solver.cpp:228] Iteration 2290, loss = 0.000233204
I0403 03:39:22.353974 16972 solver.cpp:244]     Train net output #0: loss = 0.000233161 (* 1 = 0.000233161 loss)
I0403 03:39:22.541481 16972 sgd_solver.cpp:106] Iteration 2290, lr = 5e-05
I0403 03:39:26.193920 16972 solver.cpp:228] Iteration 2295, loss = 0.000381403
I0403 03:39:26.194020 16972 solver.cpp:244]     Train net output #0: loss = 0.000381359 (* 1 = 0.000381359 loss)
I0403 03:39:26.421843 16972 sgd_solver.cpp:106] Iteration 2295, lr = 5e-05
I0403 03:39:30.089584 16972 solver.cpp:228] Iteration 2300, loss = 0.00308178
I0403 03:39:30.089678 16972 solver.cpp:244]     Train net output #0: loss = 0.00308174 (* 1 = 0.00308174 loss)
I0403 03:39:30.303907 16972 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0403 03:39:33.930487 16972 solver.cpp:228] Iteration 2305, loss = 0.000586846
I0403 03:39:33.930575 16972 solver.cpp:244]     Train net output #0: loss = 0.000586802 (* 1 = 0.000586802 loss)
I0403 03:39:34.125715 16972 sgd_solver.cpp:106] Iteration 2305, lr = 5e-05
I0403 03:39:37.834627 16972 solver.cpp:228] Iteration 2310, loss = 0.0100069
I0403 03:39:37.834934 16972 solver.cpp:244]     Train net output #0: loss = 0.0100068 (* 1 = 0.0100068 loss)
I0403 03:39:38.041538 16972 sgd_solver.cpp:106] Iteration 2310, lr = 5e-05
I0403 03:39:41.762821 16972 solver.cpp:228] Iteration 2315, loss = 0.000140094
I0403 03:39:41.762908 16972 solver.cpp:244]     Train net output #0: loss = 0.00014005 (* 1 = 0.00014005 loss)
I0403 03:39:41.958868 16972 sgd_solver.cpp:106] Iteration 2315, lr = 5e-05
I0403 03:39:45.628988 16972 solver.cpp:228] Iteration 2320, loss = 0.000261275
I0403 03:39:45.629073 16972 solver.cpp:244]     Train net output #0: loss = 0.000261231 (* 1 = 0.000261231 loss)
I0403 03:39:45.805517 16972 sgd_solver.cpp:106] Iteration 2320, lr = 5e-05
I0403 03:39:49.496444 16972 solver.cpp:228] Iteration 2325, loss = 0.000146859
I0403 03:39:49.496532 16972 solver.cpp:244]     Train net output #0: loss = 0.000146815 (* 1 = 0.000146815 loss)
I0403 03:39:49.687321 16972 sgd_solver.cpp:106] Iteration 2325, lr = 5e-05
I0403 03:39:53.340301 16972 solver.cpp:228] Iteration 2330, loss = 0.00162437
I0403 03:39:53.340389 16972 solver.cpp:244]     Train net output #0: loss = 0.00162432 (* 1 = 0.00162432 loss)
I0403 03:39:53.525970 16972 sgd_solver.cpp:106] Iteration 2330, lr = 5e-05
I0403 03:39:57.237725 16972 solver.cpp:228] Iteration 2335, loss = 0.00336724
I0403 03:39:57.237812 16972 solver.cpp:244]     Train net output #0: loss = 0.0033672 (* 1 = 0.0033672 loss)
I0403 03:39:57.437217 16972 sgd_solver.cpp:106] Iteration 2335, lr = 5e-05
I0403 03:40:01.154403 16972 solver.cpp:228] Iteration 2340, loss = 0.000486741
I0403 03:40:01.154498 16972 solver.cpp:244]     Train net output #0: loss = 0.000486695 (* 1 = 0.000486695 loss)
I0403 03:40:01.375116 16972 sgd_solver.cpp:106] Iteration 2340, lr = 5e-05
I0403 03:40:05.194458 16972 solver.cpp:228] Iteration 2345, loss = 0.00403469
I0403 03:40:05.194558 16972 solver.cpp:244]     Train net output #0: loss = 0.00403464 (* 1 = 0.00403464 loss)
I0403 03:40:05.425317 16972 sgd_solver.cpp:106] Iteration 2345, lr = 5e-05
I0403 03:40:09.151437 16972 solver.cpp:228] Iteration 2350, loss = 0.000503032
I0403 03:40:09.151777 16972 solver.cpp:244]     Train net output #0: loss = 0.000502986 (* 1 = 0.000502986 loss)
I0403 03:40:09.344333 16972 sgd_solver.cpp:106] Iteration 2350, lr = 5e-05
I0403 03:40:13.000921 16972 solver.cpp:228] Iteration 2355, loss = 0.000146993
I0403 03:40:13.001005 16972 solver.cpp:244]     Train net output #0: loss = 0.000146948 (* 1 = 0.000146948 loss)
I0403 03:40:13.205435 16972 sgd_solver.cpp:106] Iteration 2355, lr = 5e-05
I0403 03:40:16.885841 16972 solver.cpp:228] Iteration 2360, loss = 0.00273979
I0403 03:40:16.885924 16972 solver.cpp:244]     Train net output #0: loss = 0.00273975 (* 1 = 0.00273975 loss)
I0403 03:40:17.076040 16972 sgd_solver.cpp:106] Iteration 2360, lr = 5e-05
I0403 03:40:20.801126 16972 solver.cpp:228] Iteration 2365, loss = 0.000359995
I0403 03:40:20.801208 16972 solver.cpp:244]     Train net output #0: loss = 0.000359949 (* 1 = 0.000359949 loss)
I0403 03:40:20.995939 16972 sgd_solver.cpp:106] Iteration 2365, lr = 5e-05
I0403 03:40:24.727715 16972 solver.cpp:228] Iteration 2370, loss = 0.000519734
I0403 03:40:24.727807 16972 solver.cpp:244]     Train net output #0: loss = 0.000519689 (* 1 = 0.000519689 loss)
I0403 03:40:24.934765 16972 sgd_solver.cpp:106] Iteration 2370, lr = 5e-05
I0403 03:40:28.500486 16972 solver.cpp:228] Iteration 2375, loss = 0.000989385
I0403 03:40:28.500583 16972 solver.cpp:244]     Train net output #0: loss = 0.00098934 (* 1 = 0.00098934 loss)
I0403 03:40:28.712525 16972 sgd_solver.cpp:106] Iteration 2375, lr = 5e-05
I0403 03:40:28.712759 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2376.caffemodel
I0403 03:40:31.432540 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2376.solverstate
I0403 03:40:33.234715 16972 solver.cpp:337] Iteration 2376, Testing net (#0)
I0403 03:42:14.271651 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973757
I0403 03:42:14.272004 16972 solver.cpp:404]     Test net output #1: loss = 0.112692 (* 1 = 0.112692 loss)
I0403 03:42:17.971813 16972 solver.cpp:228] Iteration 2380, loss = 0.00105392
I0403 03:42:17.971900 16972 solver.cpp:244]     Train net output #0: loss = 0.00105388 (* 1 = 0.00105388 loss)
I0403 03:42:18.163074 16972 sgd_solver.cpp:106] Iteration 2380, lr = 5e-05
I0403 03:42:21.917249 16972 solver.cpp:228] Iteration 2385, loss = 0.00106733
I0403 03:42:21.917353 16972 solver.cpp:244]     Train net output #0: loss = 0.00106728 (* 1 = 0.00106728 loss)
I0403 03:42:22.090862 16972 sgd_solver.cpp:106] Iteration 2385, lr = 5e-05
I0403 03:42:25.945998 16972 solver.cpp:228] Iteration 2390, loss = 0.000587134
I0403 03:42:25.946086 16972 solver.cpp:244]     Train net output #0: loss = 0.000587088 (* 1 = 0.000587088 loss)
I0403 03:42:26.150523 16972 sgd_solver.cpp:106] Iteration 2390, lr = 5e-05
I0403 03:42:29.852074 16972 solver.cpp:228] Iteration 2395, loss = 0.000656307
I0403 03:42:29.852164 16972 solver.cpp:244]     Train net output #0: loss = 0.000656261 (* 1 = 0.000656261 loss)
I0403 03:42:30.046386 16972 sgd_solver.cpp:106] Iteration 2395, lr = 5e-05
I0403 03:42:33.777004 16972 solver.cpp:228] Iteration 2400, loss = 6.38297e-05
I0403 03:42:33.777091 16972 solver.cpp:244]     Train net output #0: loss = 6.37843e-05 (* 1 = 6.37843e-05 loss)
I0403 03:42:33.932898 16972 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0403 03:42:37.714545 16972 solver.cpp:228] Iteration 2405, loss = 0.000208341
I0403 03:42:37.714633 16972 solver.cpp:244]     Train net output #0: loss = 0.000208295 (* 1 = 0.000208295 loss)
I0403 03:42:37.903673 16972 sgd_solver.cpp:106] Iteration 2405, lr = 5e-05
I0403 03:42:41.566368 16972 solver.cpp:228] Iteration 2410, loss = 0.000479054
I0403 03:42:41.566457 16972 solver.cpp:244]     Train net output #0: loss = 0.000479008 (* 1 = 0.000479008 loss)
I0403 03:42:41.760733 16972 sgd_solver.cpp:106] Iteration 2410, lr = 5e-05
I0403 03:42:45.659158 16972 solver.cpp:228] Iteration 2415, loss = 0.00928164
I0403 03:42:45.659479 16972 solver.cpp:244]     Train net output #0: loss = 0.00928159 (* 1 = 0.00928159 loss)
I0403 03:42:45.831435 16972 sgd_solver.cpp:106] Iteration 2415, lr = 5e-05
I0403 03:42:49.574196 16972 solver.cpp:228] Iteration 2420, loss = 0.000586393
I0403 03:42:49.574302 16972 solver.cpp:244]     Train net output #0: loss = 0.000586347 (* 1 = 0.000586347 loss)
I0403 03:42:49.798996 16972 sgd_solver.cpp:106] Iteration 2420, lr = 5e-05
I0403 03:42:53.462296 16972 solver.cpp:228] Iteration 2425, loss = 0.000902808
I0403 03:42:53.462393 16972 solver.cpp:244]     Train net output #0: loss = 0.000902762 (* 1 = 0.000902762 loss)
I0403 03:42:53.669176 16972 sgd_solver.cpp:106] Iteration 2425, lr = 5e-05
I0403 03:42:57.332684 16972 solver.cpp:228] Iteration 2430, loss = 0.00279757
I0403 03:42:57.332782 16972 solver.cpp:244]     Train net output #0: loss = 0.00279752 (* 1 = 0.00279752 loss)
I0403 03:42:57.578858 16972 sgd_solver.cpp:106] Iteration 2430, lr = 5e-05
I0403 03:43:01.285552 16972 solver.cpp:228] Iteration 2435, loss = 6.13645e-05
I0403 03:43:01.285650 16972 solver.cpp:244]     Train net output #0: loss = 6.13188e-05 (* 1 = 6.13188e-05 loss)
I0403 03:43:01.501646 16972 sgd_solver.cpp:106] Iteration 2435, lr = 5e-05
I0403 03:43:05.154227 16972 solver.cpp:228] Iteration 2440, loss = 0.000480834
I0403 03:43:05.154325 16972 solver.cpp:244]     Train net output #0: loss = 0.000480788 (* 1 = 0.000480788 loss)
I0403 03:43:05.352329 16972 sgd_solver.cpp:106] Iteration 2440, lr = 5e-05
I0403 03:43:09.227303 16972 solver.cpp:228] Iteration 2445, loss = 0.000504501
I0403 03:43:09.227392 16972 solver.cpp:244]     Train net output #0: loss = 0.000504456 (* 1 = 0.000504456 loss)
I0403 03:43:09.383888 16972 sgd_solver.cpp:106] Iteration 2445, lr = 5e-05
I0403 03:43:13.246636 16972 solver.cpp:228] Iteration 2450, loss = 0.000308756
I0403 03:43:13.246724 16972 solver.cpp:244]     Train net output #0: loss = 0.000308711 (* 1 = 0.000308711 loss)
I0403 03:43:13.424167 16972 sgd_solver.cpp:106] Iteration 2450, lr = 5e-05
I0403 03:43:17.199234 16972 solver.cpp:228] Iteration 2455, loss = 0.00137084
I0403 03:43:17.199542 16972 solver.cpp:244]     Train net output #0: loss = 0.00137079 (* 1 = 0.00137079 loss)
I0403 03:43:17.319473 16972 sgd_solver.cpp:106] Iteration 2455, lr = 5e-05
I0403 03:43:21.076027 16972 solver.cpp:228] Iteration 2460, loss = 0.00270858
I0403 03:43:21.076114 16972 solver.cpp:244]     Train net output #0: loss = 0.00270854 (* 1 = 0.00270854 loss)
I0403 03:43:21.267786 16972 sgd_solver.cpp:106] Iteration 2460, lr = 5e-05
I0403 03:43:24.921496 16972 solver.cpp:228] Iteration 2465, loss = 0.00078752
I0403 03:43:24.921596 16972 solver.cpp:244]     Train net output #0: loss = 0.000787476 (* 1 = 0.000787476 loss)
I0403 03:43:25.155944 16972 sgd_solver.cpp:106] Iteration 2465, lr = 5e-05
I0403 03:43:28.889096 16972 solver.cpp:228] Iteration 2470, loss = 0.0002001
I0403 03:43:28.889181 16972 solver.cpp:244]     Train net output #0: loss = 0.000200056 (* 1 = 0.000200056 loss)
I0403 03:43:29.061012 16972 sgd_solver.cpp:106] Iteration 2470, lr = 5e-05
I0403 03:43:32.697206 16972 solver.cpp:228] Iteration 2475, loss = 0.00182136
I0403 03:43:32.697307 16972 solver.cpp:244]     Train net output #0: loss = 0.00182132 (* 1 = 0.00182132 loss)
I0403 03:43:32.920936 16972 sgd_solver.cpp:106] Iteration 2475, lr = 5e-05
I0403 03:43:36.520969 16972 solver.cpp:228] Iteration 2480, loss = 0.000792364
I0403 03:43:36.521066 16972 solver.cpp:244]     Train net output #0: loss = 0.00079232 (* 1 = 0.00079232 loss)
I0403 03:43:36.727955 16972 sgd_solver.cpp:106] Iteration 2480, lr = 5e-05
I0403 03:43:39.015226 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2484.caffemodel
I0403 03:43:41.756492 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2484.solverstate
I0403 03:43:43.589109 16972 solver.cpp:337] Iteration 2484, Testing net (#0)
I0403 03:45:24.632949 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973756
I0403 03:45:24.633278 16972 solver.cpp:404]     Test net output #1: loss = 0.112956 (* 1 = 0.112956 loss)
I0403 03:45:25.998656 16972 solver.cpp:228] Iteration 2485, loss = 0.000345074
I0403 03:45:25.998752 16972 solver.cpp:244]     Train net output #0: loss = 0.00034503 (* 1 = 0.00034503 loss)
I0403 03:45:26.205587 16972 sgd_solver.cpp:106] Iteration 2485, lr = 5e-05
I0403 03:45:29.840243 16972 solver.cpp:228] Iteration 2490, loss = 0.00050368
I0403 03:45:29.840335 16972 solver.cpp:244]     Train net output #0: loss = 0.000503636 (* 1 = 0.000503636 loss)
I0403 03:45:30.025714 16972 sgd_solver.cpp:106] Iteration 2490, lr = 5e-05
I0403 03:45:34.011469 16972 solver.cpp:228] Iteration 2495, loss = 0.000251836
I0403 03:45:34.011567 16972 solver.cpp:244]     Train net output #0: loss = 0.000251792 (* 1 = 0.000251792 loss)
I0403 03:45:34.247134 16972 sgd_solver.cpp:106] Iteration 2495, lr = 5e-05
I0403 03:45:37.896792 16972 solver.cpp:228] Iteration 2500, loss = 0.000127001
I0403 03:45:37.896880 16972 solver.cpp:244]     Train net output #0: loss = 0.000126957 (* 1 = 0.000126957 loss)
I0403 03:45:38.088544 16972 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0403 03:45:41.773838 16972 solver.cpp:228] Iteration 2505, loss = 0.00690042
I0403 03:45:41.773937 16972 solver.cpp:244]     Train net output #0: loss = 0.00690037 (* 1 = 0.00690037 loss)
I0403 03:45:41.995239 16972 sgd_solver.cpp:106] Iteration 2505, lr = 5e-05
I0403 03:45:45.660922 16972 solver.cpp:228] Iteration 2510, loss = 0.000246659
I0403 03:45:45.661010 16972 solver.cpp:244]     Train net output #0: loss = 0.000246615 (* 1 = 0.000246615 loss)
I0403 03:45:45.843298 16972 sgd_solver.cpp:106] Iteration 2510, lr = 5e-05
I0403 03:45:49.578485 16972 solver.cpp:228] Iteration 2515, loss = 0.00112929
I0403 03:45:49.578572 16972 solver.cpp:244]     Train net output #0: loss = 0.00112925 (* 1 = 0.00112925 loss)
I0403 03:45:49.755332 16972 sgd_solver.cpp:106] Iteration 2515, lr = 5e-05
I0403 03:45:53.472964 16972 solver.cpp:228] Iteration 2520, loss = 0.000246937
I0403 03:45:53.473052 16972 solver.cpp:244]     Train net output #0: loss = 0.000246893 (* 1 = 0.000246893 loss)
I0403 03:45:53.652467 16972 sgd_solver.cpp:106] Iteration 2520, lr = 5e-05
I0403 03:45:57.480832 16972 solver.cpp:228] Iteration 2525, loss = 0.000596938
I0403 03:45:57.481133 16972 solver.cpp:244]     Train net output #0: loss = 0.000596893 (* 1 = 0.000596893 loss)
I0403 03:45:57.688009 16972 sgd_solver.cpp:106] Iteration 2525, lr = 5e-05
I0403 03:46:01.335724 16972 solver.cpp:228] Iteration 2530, loss = 0.0010011
I0403 03:46:01.335813 16972 solver.cpp:244]     Train net output #0: loss = 0.00100106 (* 1 = 0.00100106 loss)
I0403 03:46:01.515136 16972 sgd_solver.cpp:106] Iteration 2530, lr = 5e-05
I0403 03:46:05.212309 16972 solver.cpp:228] Iteration 2535, loss = 0.00533547
I0403 03:46:05.212407 16972 solver.cpp:244]     Train net output #0: loss = 0.00533543 (* 1 = 0.00533543 loss)
I0403 03:46:05.419431 16972 sgd_solver.cpp:106] Iteration 2535, lr = 5e-05
I0403 03:46:09.044798 16972 solver.cpp:228] Iteration 2540, loss = 4.52842e-05
I0403 03:46:09.044886 16972 solver.cpp:244]     Train net output #0: loss = 4.52402e-05 (* 1 = 4.52402e-05 loss)
I0403 03:46:09.237782 16972 sgd_solver.cpp:106] Iteration 2540, lr = 5e-05
I0403 03:46:13.046475 16972 solver.cpp:228] Iteration 2545, loss = 0.000465357
I0403 03:46:13.046563 16972 solver.cpp:244]     Train net output #0: loss = 0.000465313 (* 1 = 0.000465313 loss)
I0403 03:46:13.225500 16972 sgd_solver.cpp:106] Iteration 2545, lr = 5e-05
I0403 03:46:16.962712 16972 solver.cpp:228] Iteration 2550, loss = 0.000758592
I0403 03:46:16.962795 16972 solver.cpp:244]     Train net output #0: loss = 0.000758548 (* 1 = 0.000758548 loss)
I0403 03:46:17.161448 16972 sgd_solver.cpp:106] Iteration 2550, lr = 5e-05
I0403 03:46:20.776659 16972 solver.cpp:228] Iteration 2555, loss = 0.000895502
I0403 03:46:20.776754 16972 solver.cpp:244]     Train net output #0: loss = 0.000895458 (* 1 = 0.000895458 loss)
I0403 03:46:20.987593 16972 sgd_solver.cpp:106] Iteration 2555, lr = 5e-05
I0403 03:46:24.677958 16972 solver.cpp:228] Iteration 2560, loss = 0.000277315
I0403 03:46:24.678061 16972 solver.cpp:244]     Train net output #0: loss = 0.000277272 (* 1 = 0.000277272 loss)
I0403 03:46:24.892069 16972 sgd_solver.cpp:106] Iteration 2560, lr = 5e-05
I0403 03:46:28.557342 16972 solver.cpp:228] Iteration 2565, loss = 0.000430481
I0403 03:46:28.557674 16972 solver.cpp:244]     Train net output #0: loss = 0.000430438 (* 1 = 0.000430438 loss)
I0403 03:46:28.792879 16972 sgd_solver.cpp:106] Iteration 2565, lr = 5e-05
I0403 03:46:32.451871 16972 solver.cpp:228] Iteration 2570, loss = 0.000233067
I0403 03:46:32.451956 16972 solver.cpp:244]     Train net output #0: loss = 0.000233024 (* 1 = 0.000233024 loss)
I0403 03:46:32.630384 16972 sgd_solver.cpp:106] Iteration 2570, lr = 5e-05
I0403 03:46:36.317970 16972 solver.cpp:228] Iteration 2575, loss = 5.78382e-05
I0403 03:46:36.318071 16972 solver.cpp:244]     Train net output #0: loss = 5.77956e-05 (* 1 = 5.77956e-05 loss)
I0403 03:46:36.541191 16972 sgd_solver.cpp:106] Iteration 2575, lr = 5e-05
I0403 03:46:40.166633 16972 solver.cpp:228] Iteration 2580, loss = 9.02938e-05
I0403 03:46:40.166729 16972 solver.cpp:244]     Train net output #0: loss = 9.02512e-05 (* 1 = 9.02512e-05 loss)
I0403 03:46:40.373608 16972 sgd_solver.cpp:106] Iteration 2580, lr = 5e-05
I0403 03:46:44.126914 16972 solver.cpp:228] Iteration 2585, loss = 0.00115474
I0403 03:46:44.127002 16972 solver.cpp:244]     Train net output #0: loss = 0.0011547 (* 1 = 0.0011547 loss)
I0403 03:46:44.314823 16972 sgd_solver.cpp:106] Iteration 2585, lr = 5e-05
I0403 03:46:48.003914 16972 solver.cpp:228] Iteration 2590, loss = 0.000169824
I0403 03:46:48.004004 16972 solver.cpp:244]     Train net output #0: loss = 0.000169782 (* 1 = 0.000169782 loss)
I0403 03:46:48.186055 16972 sgd_solver.cpp:106] Iteration 2590, lr = 5e-05
I0403 03:46:49.023041 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2592.caffemodel
I0403 03:46:51.823452 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2592.solverstate
I0403 03:46:53.680968 16972 solver.cpp:337] Iteration 2592, Testing net (#0)
I0403 03:48:34.715867 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973549
I0403 03:48:34.716162 16972 solver.cpp:404]     Test net output #1: loss = 0.113081 (* 1 = 0.113081 loss)
I0403 03:48:37.594007 16972 solver.cpp:228] Iteration 2595, loss = 0.00136244
I0403 03:48:37.594097 16972 solver.cpp:244]     Train net output #0: loss = 0.0013624 (* 1 = 0.0013624 loss)
I0403 03:48:37.791430 16972 sgd_solver.cpp:106] Iteration 2595, lr = 5e-05
I0403 03:48:41.456274 16972 solver.cpp:228] Iteration 2600, loss = 0.000139784
I0403 03:48:41.456359 16972 solver.cpp:244]     Train net output #0: loss = 0.000139742 (* 1 = 0.000139742 loss)
I0403 03:48:41.651114 16972 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0403 03:48:45.275019 16972 solver.cpp:228] Iteration 2605, loss = 0.00195831
I0403 03:48:45.284682 16972 solver.cpp:244]     Train net output #0: loss = 0.00195827 (* 1 = 0.00195827 loss)
I0403 03:48:45.491943 16972 sgd_solver.cpp:106] Iteration 2605, lr = 5e-05
I0403 03:48:49.336855 16972 solver.cpp:228] Iteration 2610, loss = 0.00270928
I0403 03:48:49.336942 16972 solver.cpp:244]     Train net output #0: loss = 0.00270924 (* 1 = 0.00270924 loss)
I0403 03:48:49.512156 16972 sgd_solver.cpp:106] Iteration 2610, lr = 5e-05
I0403 03:48:53.430179 16972 solver.cpp:228] Iteration 2615, loss = 0.013593
I0403 03:48:53.430275 16972 solver.cpp:244]     Train net output #0: loss = 0.0135929 (* 1 = 0.0135929 loss)
I0403 03:48:53.614984 16972 sgd_solver.cpp:106] Iteration 2615, lr = 5e-05
I0403 03:48:57.417031 16972 solver.cpp:228] Iteration 2620, loss = 0.000356818
I0403 03:48:57.417115 16972 solver.cpp:244]     Train net output #0: loss = 0.000356775 (* 1 = 0.000356775 loss)
I0403 03:48:57.610889 16972 sgd_solver.cpp:106] Iteration 2620, lr = 5e-05
I0403 03:49:01.296314 16972 solver.cpp:228] Iteration 2625, loss = 0.000326452
I0403 03:49:01.296416 16972 solver.cpp:244]     Train net output #0: loss = 0.000326409 (* 1 = 0.000326409 loss)
I0403 03:49:01.520755 16972 sgd_solver.cpp:106] Iteration 2625, lr = 5e-05
I0403 03:49:05.133615 16972 solver.cpp:228] Iteration 2630, loss = 0.000414919
I0403 03:49:05.133930 16972 solver.cpp:244]     Train net output #0: loss = 0.000414875 (* 1 = 0.000414875 loss)
I0403 03:49:05.327107 16972 sgd_solver.cpp:106] Iteration 2630, lr = 5e-05
I0403 03:49:08.987895 16972 solver.cpp:228] Iteration 2635, loss = 0.00025763
I0403 03:49:08.987992 16972 solver.cpp:244]     Train net output #0: loss = 0.000257587 (* 1 = 0.000257587 loss)
I0403 03:49:09.221159 16972 sgd_solver.cpp:106] Iteration 2635, lr = 5e-05
I0403 03:49:12.823213 16972 solver.cpp:228] Iteration 2640, loss = 0.00471425
I0403 03:49:12.823328 16972 solver.cpp:244]     Train net output #0: loss = 0.00471421 (* 1 = 0.00471421 loss)
I0403 03:49:13.031517 16972 sgd_solver.cpp:106] Iteration 2640, lr = 5e-05
I0403 03:49:16.677876 16972 solver.cpp:228] Iteration 2645, loss = 0.000206115
I0403 03:49:16.677964 16972 solver.cpp:244]     Train net output #0: loss = 0.000206072 (* 1 = 0.000206072 loss)
I0403 03:49:16.858206 16972 sgd_solver.cpp:106] Iteration 2645, lr = 5e-05
I0403 03:49:20.564918 16972 solver.cpp:228] Iteration 2650, loss = 0.00018276
I0403 03:49:20.565021 16972 solver.cpp:244]     Train net output #0: loss = 0.000182716 (* 1 = 0.000182716 loss)
I0403 03:49:20.777817 16972 sgd_solver.cpp:106] Iteration 2650, lr = 5e-05
I0403 03:49:24.473763 16972 solver.cpp:228] Iteration 2655, loss = 0.000445948
I0403 03:49:24.473850 16972 solver.cpp:244]     Train net output #0: loss = 0.000445905 (* 1 = 0.000445905 loss)
I0403 03:49:24.661317 16972 sgd_solver.cpp:106] Iteration 2655, lr = 5e-05
I0403 03:49:28.376807 16972 solver.cpp:228] Iteration 2660, loss = 0.000266453
I0403 03:49:28.376895 16972 solver.cpp:244]     Train net output #0: loss = 0.00026641 (* 1 = 0.00026641 loss)
I0403 03:49:28.560855 16972 sgd_solver.cpp:106] Iteration 2660, lr = 5e-05
I0403 03:49:32.280120 16972 solver.cpp:228] Iteration 2665, loss = 0.0016884
I0403 03:49:32.280210 16972 solver.cpp:244]     Train net output #0: loss = 0.00168836 (* 1 = 0.00168836 loss)
I0403 03:49:32.473996 16972 sgd_solver.cpp:106] Iteration 2665, lr = 5e-05
I0403 03:49:36.197643 16972 solver.cpp:228] Iteration 2670, loss = 0.00063056
I0403 03:49:36.197939 16972 solver.cpp:244]     Train net output #0: loss = 0.000630517 (* 1 = 0.000630517 loss)
I0403 03:49:36.384919 16972 sgd_solver.cpp:106] Iteration 2670, lr = 5e-05
I0403 03:49:40.046942 16972 solver.cpp:228] Iteration 2675, loss = 0.00186857
I0403 03:49:40.047042 16972 solver.cpp:244]     Train net output #0: loss = 0.00186852 (* 1 = 0.00186852 loss)
I0403 03:49:40.268725 16972 sgd_solver.cpp:106] Iteration 2675, lr = 5e-05
I0403 03:49:43.953346 16972 solver.cpp:228] Iteration 2680, loss = 0.000313264
I0403 03:49:43.954282 16972 solver.cpp:244]     Train net output #0: loss = 0.000313221 (* 1 = 0.000313221 loss)
I0403 03:49:44.127789 16972 sgd_solver.cpp:106] Iteration 2680, lr = 5e-05
I0403 03:49:47.966850 16972 solver.cpp:228] Iteration 2685, loss = 0.000342273
I0403 03:49:47.966936 16972 solver.cpp:244]     Train net output #0: loss = 0.00034223 (* 1 = 0.00034223 loss)
I0403 03:49:48.157234 16972 sgd_solver.cpp:106] Iteration 2685, lr = 5e-05
I0403 03:49:51.833914 16972 solver.cpp:228] Iteration 2690, loss = 0.000396905
I0403 03:49:51.834004 16972 solver.cpp:244]     Train net output #0: loss = 0.000396863 (* 1 = 0.000396863 loss)
I0403 03:49:52.038085 16972 sgd_solver.cpp:106] Iteration 2690, lr = 5e-05
I0403 03:49:55.676565 16972 solver.cpp:228] Iteration 2695, loss = 0.000395553
I0403 03:49:55.676666 16972 solver.cpp:244]     Train net output #0: loss = 0.000395511 (* 1 = 0.000395511 loss)
I0403 03:49:55.893661 16972 sgd_solver.cpp:106] Iteration 2695, lr = 5e-05
I0403 03:49:58.955914 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2700.caffemodel
I0403 03:50:01.617641 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2700.solverstate
I0403 03:50:03.399073 16972 solver.cpp:337] Iteration 2700, Testing net (#0)
I0403 03:51:44.472695 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973803
I0403 03:51:44.473018 16972 solver.cpp:404]     Test net output #1: loss = 0.112966 (* 1 = 0.112966 loss)
I0403 03:51:45.029749 16972 solver.cpp:228] Iteration 2700, loss = 0.00072144
I0403 03:51:45.029831 16972 solver.cpp:244]     Train net output #0: loss = 0.000721398 (* 1 = 0.000721398 loss)
I0403 03:51:45.207090 16972 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0403 03:51:48.965255 16972 solver.cpp:228] Iteration 2705, loss = 0.000306822
I0403 03:51:48.965355 16972 solver.cpp:244]     Train net output #0: loss = 0.00030678 (* 1 = 0.00030678 loss)
I0403 03:51:49.188325 16972 sgd_solver.cpp:106] Iteration 2705, lr = 5e-05
I0403 03:51:52.918066 16972 solver.cpp:228] Iteration 2710, loss = 0.000637629
I0403 03:51:52.918153 16972 solver.cpp:244]     Train net output #0: loss = 0.000637586 (* 1 = 0.000637586 loss)
I0403 03:51:53.112010 16972 sgd_solver.cpp:106] Iteration 2710, lr = 5e-05
I0403 03:51:56.735908 16972 solver.cpp:228] Iteration 2715, loss = 5.53318e-05
I0403 03:51:56.736006 16972 solver.cpp:244]     Train net output #0: loss = 5.52891e-05 (* 1 = 5.52891e-05 loss)
I0403 03:51:56.929998 16972 sgd_solver.cpp:106] Iteration 2715, lr = 5e-05
I0403 03:52:00.626622 16972 solver.cpp:228] Iteration 2720, loss = 0.00374697
I0403 03:52:00.626710 16972 solver.cpp:244]     Train net output #0: loss = 0.00374693 (* 1 = 0.00374693 loss)
I0403 03:52:00.821713 16972 sgd_solver.cpp:106] Iteration 2720, lr = 5e-05
I0403 03:52:04.576709 16972 solver.cpp:228] Iteration 2725, loss = 0.00278509
I0403 03:52:04.576797 16972 solver.cpp:244]     Train net output #0: loss = 0.00278504 (* 1 = 0.00278504 loss)
I0403 03:52:04.715075 16972 sgd_solver.cpp:106] Iteration 2725, lr = 5e-05
I0403 03:52:08.545495 16972 solver.cpp:228] Iteration 2730, loss = 7.70511e-05
I0403 03:52:08.545594 16972 solver.cpp:244]     Train net output #0: loss = 7.70087e-05 (* 1 = 7.70087e-05 loss)
I0403 03:52:08.752310 16972 sgd_solver.cpp:106] Iteration 2730, lr = 5e-05
I0403 03:52:12.367996 16972 solver.cpp:228] Iteration 2735, loss = 0.000325754
I0403 03:52:12.368084 16972 solver.cpp:244]     Train net output #0: loss = 0.000325712 (* 1 = 0.000325712 loss)
I0403 03:52:12.563432 16972 sgd_solver.cpp:106] Iteration 2735, lr = 5e-05
I0403 03:52:16.317196 16972 solver.cpp:228] Iteration 2740, loss = 0.00534145
I0403 03:52:16.317500 16972 solver.cpp:244]     Train net output #0: loss = 0.00534141 (* 1 = 0.00534141 loss)
I0403 03:52:16.505538 16972 sgd_solver.cpp:106] Iteration 2740, lr = 5e-05
I0403 03:52:20.229203 16972 solver.cpp:228] Iteration 2745, loss = 0.000162233
I0403 03:52:20.229297 16972 solver.cpp:244]     Train net output #0: loss = 0.000162191 (* 1 = 0.000162191 loss)
I0403 03:52:20.405725 16972 sgd_solver.cpp:106] Iteration 2745, lr = 5e-05
I0403 03:52:24.084790 16972 solver.cpp:228] Iteration 2750, loss = 0.000190042
I0403 03:52:24.084877 16972 solver.cpp:244]     Train net output #0: loss = 0.000189999 (* 1 = 0.000189999 loss)
I0403 03:52:24.279376 16972 sgd_solver.cpp:106] Iteration 2750, lr = 5e-05
I0403 03:52:28.070968 16972 solver.cpp:228] Iteration 2755, loss = 0.000317092
I0403 03:52:28.071055 16972 solver.cpp:244]     Train net output #0: loss = 0.000317048 (* 1 = 0.000317048 loss)
I0403 03:52:28.262661 16972 sgd_solver.cpp:106] Iteration 2755, lr = 5e-05
I0403 03:52:32.029106 16972 solver.cpp:228] Iteration 2760, loss = 3.06828e-05
I0403 03:52:32.029203 16972 solver.cpp:244]     Train net output #0: loss = 3.06395e-05 (* 1 = 3.06395e-05 loss)
I0403 03:52:32.251034 16972 sgd_solver.cpp:106] Iteration 2760, lr = 5e-05
I0403 03:52:35.931748 16972 solver.cpp:228] Iteration 2765, loss = 0.00152454
I0403 03:52:35.931836 16972 solver.cpp:244]     Train net output #0: loss = 0.0015245 (* 1 = 0.0015245 loss)
I0403 03:52:36.113958 16972 sgd_solver.cpp:106] Iteration 2765, lr = 5e-05
I0403 03:52:39.828147 16972 solver.cpp:228] Iteration 2770, loss = 0.00136161
I0403 03:52:39.828238 16972 solver.cpp:244]     Train net output #0: loss = 0.00136157 (* 1 = 0.00136157 loss)
I0403 03:52:40.021225 16972 sgd_solver.cpp:106] Iteration 2770, lr = 5e-05
I0403 03:52:43.673549 16972 solver.cpp:228] Iteration 2775, loss = 0.0032528
I0403 03:52:43.673648 16972 solver.cpp:244]     Train net output #0: loss = 0.00325276 (* 1 = 0.00325276 loss)
I0403 03:52:43.880717 16972 sgd_solver.cpp:106] Iteration 2775, lr = 5e-05
I0403 03:52:47.538203 16972 solver.cpp:228] Iteration 2780, loss = 0.000410892
I0403 03:52:47.538558 16972 solver.cpp:244]     Train net output #0: loss = 0.000410849 (* 1 = 0.000410849 loss)
I0403 03:52:47.709884 16972 sgd_solver.cpp:106] Iteration 2780, lr = 5e-05
I0403 03:52:51.431217 16972 solver.cpp:228] Iteration 2785, loss = 0.000634709
I0403 03:52:51.431309 16972 solver.cpp:244]     Train net output #0: loss = 0.000634666 (* 1 = 0.000634666 loss)
I0403 03:52:51.620122 16972 sgd_solver.cpp:106] Iteration 2785, lr = 5e-05
I0403 03:52:55.291484 16972 solver.cpp:228] Iteration 2790, loss = 0.00197114
I0403 03:52:55.291584 16972 solver.cpp:244]     Train net output #0: loss = 0.0019711 (* 1 = 0.0019711 loss)
I0403 03:52:55.511512 16972 sgd_solver.cpp:106] Iteration 2790, lr = 5e-05
I0403 03:52:59.248039 16972 solver.cpp:228] Iteration 2795, loss = 0.00103028
I0403 03:52:59.248131 16972 solver.cpp:244]     Train net output #0: loss = 0.00103024 (* 1 = 0.00103024 loss)
I0403 03:52:59.443672 16972 sgd_solver.cpp:106] Iteration 2795, lr = 5e-05
I0403 03:53:03.118667 16972 solver.cpp:228] Iteration 2800, loss = 0.000830605
I0403 03:53:03.118764 16972 solver.cpp:244]     Train net output #0: loss = 0.000830562 (* 1 = 0.000830562 loss)
I0403 03:53:03.327788 16972 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0403 03:53:07.109078 16972 solver.cpp:228] Iteration 2805, loss = 0.000633543
I0403 03:53:07.109179 16972 solver.cpp:244]     Train net output #0: loss = 0.0006335 (* 1 = 0.0006335 loss)
I0403 03:53:07.336212 16972 sgd_solver.cpp:106] Iteration 2805, lr = 5e-05
I0403 03:53:08.888275 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2808.caffemodel
I0403 03:53:11.628852 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2808.solverstate
I0403 03:53:13.490655 16972 solver.cpp:337] Iteration 2808, Testing net (#0)
I0403 03:54:54.535224 16972 solver.cpp:404]     Test net output #0: accuracy = 0.97378
I0403 03:54:54.535564 16972 solver.cpp:404]     Test net output #1: loss = 0.113014 (* 1 = 0.113014 loss)
I0403 03:54:56.672823 16972 solver.cpp:228] Iteration 2810, loss = 0.000278246
I0403 03:54:56.672910 16972 solver.cpp:244]     Train net output #0: loss = 0.000278203 (* 1 = 0.000278203 loss)
I0403 03:54:56.833009 16972 sgd_solver.cpp:106] Iteration 2810, lr = 5e-05
I0403 03:55:00.592083 16972 solver.cpp:228] Iteration 2815, loss = 0.00010078
I0403 03:55:00.592170 16972 solver.cpp:244]     Train net output #0: loss = 0.000100738 (* 1 = 0.000100738 loss)
I0403 03:55:00.776238 16972 sgd_solver.cpp:106] Iteration 2815, lr = 5e-05
I0403 03:55:04.546659 16972 solver.cpp:228] Iteration 2820, loss = 0.00079319
I0403 03:55:04.553408 16972 solver.cpp:244]     Train net output #0: loss = 0.000793147 (* 1 = 0.000793147 loss)
I0403 03:55:04.733305 16972 sgd_solver.cpp:106] Iteration 2820, lr = 5e-05
I0403 03:55:08.474575 16972 solver.cpp:228] Iteration 2825, loss = 0.00224521
I0403 03:55:08.474665 16972 solver.cpp:244]     Train net output #0: loss = 0.00224517 (* 1 = 0.00224517 loss)
I0403 03:55:08.634629 16972 sgd_solver.cpp:106] Iteration 2825, lr = 5e-05
I0403 03:55:12.356722 16972 solver.cpp:228] Iteration 2830, loss = 0.00586179
I0403 03:55:12.356823 16972 solver.cpp:244]     Train net output #0: loss = 0.00586175 (* 1 = 0.00586175 loss)
I0403 03:55:12.589565 16972 sgd_solver.cpp:106] Iteration 2830, lr = 5e-05
I0403 03:55:16.304252 16972 solver.cpp:228] Iteration 2835, loss = 0.00544326
I0403 03:55:16.304344 16972 solver.cpp:244]     Train net output #0: loss = 0.00544321 (* 1 = 0.00544321 loss)
I0403 03:55:16.502249 16972 sgd_solver.cpp:106] Iteration 2835, lr = 5e-05
I0403 03:55:20.233903 16972 solver.cpp:228] Iteration 2840, loss = 0.000264418
I0403 03:55:20.233991 16972 solver.cpp:244]     Train net output #0: loss = 0.000264374 (* 1 = 0.000264374 loss)
I0403 03:55:20.411231 16972 sgd_solver.cpp:106] Iteration 2840, lr = 5e-05
I0403 03:55:24.073282 16972 solver.cpp:228] Iteration 2845, loss = 0.000391698
I0403 03:55:24.092680 16972 solver.cpp:244]     Train net output #0: loss = 0.000391654 (* 1 = 0.000391654 loss)
I0403 03:55:24.282104 16972 sgd_solver.cpp:106] Iteration 2845, lr = 5e-05
I0403 03:55:27.918285 16972 solver.cpp:228] Iteration 2850, loss = 0.000295461
I0403 03:55:27.923887 16972 solver.cpp:244]     Train net output #0: loss = 0.000295419 (* 1 = 0.000295419 loss)
I0403 03:55:28.095183 16972 sgd_solver.cpp:106] Iteration 2850, lr = 5e-05
I0403 03:55:31.880376 16972 solver.cpp:228] Iteration 2855, loss = 6.7861e-05
I0403 03:55:31.885926 16972 solver.cpp:244]     Train net output #0: loss = 6.78184e-05 (* 1 = 6.78184e-05 loss)
I0403 03:55:32.085297 16972 sgd_solver.cpp:106] Iteration 2855, lr = 5e-05
I0403 03:55:35.763859 16972 solver.cpp:228] Iteration 2860, loss = 0.000588909
I0403 03:55:35.763947 16972 solver.cpp:244]     Train net output #0: loss = 0.000588866 (* 1 = 0.000588866 loss)
I0403 03:55:35.956737 16972 sgd_solver.cpp:106] Iteration 2860, lr = 5e-05
I0403 03:55:39.786725 16972 solver.cpp:228] Iteration 2865, loss = 0.000782063
I0403 03:55:39.786826 16972 solver.cpp:244]     Train net output #0: loss = 0.00078202 (* 1 = 0.00078202 loss)
I0403 03:55:40.018739 16972 sgd_solver.cpp:106] Iteration 2865, lr = 5e-05
I0403 03:55:43.771194 16972 solver.cpp:228] Iteration 2870, loss = 0.000245391
I0403 03:55:43.771297 16972 solver.cpp:244]     Train net output #0: loss = 0.000245348 (* 1 = 0.000245348 loss)
I0403 03:55:43.978310 16972 sgd_solver.cpp:106] Iteration 2870, lr = 5e-05
I0403 03:55:47.636042 16972 solver.cpp:228] Iteration 2875, loss = 6.85479e-05
I0403 03:55:47.636137 16972 solver.cpp:244]     Train net output #0: loss = 6.85051e-05 (* 1 = 6.85051e-05 loss)
I0403 03:55:47.843698 16972 sgd_solver.cpp:106] Iteration 2875, lr = 5e-05
I0403 03:55:51.500934 16972 solver.cpp:228] Iteration 2880, loss = 0.000239991
I0403 03:55:51.501020 16972 solver.cpp:244]     Train net output #0: loss = 0.000239948 (* 1 = 0.000239948 loss)
I0403 03:55:51.686091 16972 sgd_solver.cpp:106] Iteration 2880, lr = 5e-05
I0403 03:55:55.385763 16972 solver.cpp:228] Iteration 2885, loss = 0.000364073
I0403 03:55:55.386811 16972 solver.cpp:244]     Train net output #0: loss = 0.00036403 (* 1 = 0.00036403 loss)
I0403 03:55:55.588414 16972 sgd_solver.cpp:106] Iteration 2885, lr = 5e-05
I0403 03:55:59.379925 16972 solver.cpp:228] Iteration 2890, loss = 0.000346213
I0403 03:55:59.380198 16972 solver.cpp:244]     Train net output #0: loss = 0.00034617 (* 1 = 0.00034617 loss)
I0403 03:55:59.579871 16972 sgd_solver.cpp:106] Iteration 2890, lr = 5e-05
I0403 03:56:03.232431 16972 solver.cpp:228] Iteration 2895, loss = 0.000493094
I0403 03:56:03.232522 16972 solver.cpp:244]     Train net output #0: loss = 0.000493051 (* 1 = 0.000493051 loss)
I0403 03:56:03.427286 16972 sgd_solver.cpp:106] Iteration 2895, lr = 5e-05
I0403 03:56:07.079810 16972 solver.cpp:228] Iteration 2900, loss = 0.000153635
I0403 03:56:07.079916 16972 solver.cpp:244]     Train net output #0: loss = 0.000153592 (* 1 = 0.000153592 loss)
I0403 03:56:07.263303 16972 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0403 03:56:10.972594 16972 solver.cpp:228] Iteration 2905, loss = 7.11032e-05
I0403 03:56:10.972687 16972 solver.cpp:244]     Train net output #0: loss = 7.10605e-05 (* 1 = 7.10605e-05 loss)
I0403 03:56:11.188664 16972 sgd_solver.cpp:106] Iteration 2905, lr = 5e-05
I0403 03:56:14.811367 16972 solver.cpp:228] Iteration 2910, loss = 0.00114637
I0403 03:56:14.811463 16972 solver.cpp:244]     Train net output #0: loss = 0.00114632 (* 1 = 0.00114632 loss)
I0403 03:56:15.006067 16972 sgd_solver.cpp:106] Iteration 2910, lr = 5e-05
I0403 03:56:18.672567 16972 solver.cpp:228] Iteration 2915, loss = 0.00174033
I0403 03:56:18.672657 16972 solver.cpp:244]     Train net output #0: loss = 0.00174029 (* 1 = 0.00174029 loss)
I0403 03:56:18.870988 16972 sgd_solver.cpp:106] Iteration 2915, lr = 5e-05
I0403 03:56:18.871222 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2916.caffemodel
I0403 03:56:21.655845 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_2916.solverstate
I0403 03:56:23.538769 16972 solver.cpp:337] Iteration 2916, Testing net (#0)
I0403 03:58:04.615901 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973849
I0403 03:58:04.616201 16972 solver.cpp:404]     Test net output #1: loss = 0.113136 (* 1 = 0.113136 loss)
I0403 03:58:08.243144 16972 solver.cpp:228] Iteration 2920, loss = 0.00501611
I0403 03:58:08.243230 16972 solver.cpp:244]     Train net output #0: loss = 0.00501606 (* 1 = 0.00501606 loss)
I0403 03:58:08.425446 16972 sgd_solver.cpp:106] Iteration 2920, lr = 5e-05
I0403 03:58:12.113095 16972 solver.cpp:228] Iteration 2925, loss = 8.54854e-05
I0403 03:58:12.113195 16972 solver.cpp:244]     Train net output #0: loss = 8.5442e-05 (* 1 = 8.5442e-05 loss)
I0403 03:58:12.357906 16972 sgd_solver.cpp:106] Iteration 2925, lr = 5e-05
I0403 03:58:15.949815 16972 solver.cpp:228] Iteration 2930, loss = 0.000331237
I0403 03:58:15.949903 16972 solver.cpp:244]     Train net output #0: loss = 0.000331194 (* 1 = 0.000331194 loss)
I0403 03:58:16.134274 16972 sgd_solver.cpp:106] Iteration 2930, lr = 5e-05
I0403 03:58:19.788842 16972 solver.cpp:228] Iteration 2935, loss = 0.0232698
I0403 03:58:19.788931 16972 solver.cpp:244]     Train net output #0: loss = 0.0232697 (* 1 = 0.0232697 loss)
I0403 03:58:19.973515 16972 sgd_solver.cpp:106] Iteration 2935, lr = 5e-05
I0403 03:58:23.692764 16972 solver.cpp:228] Iteration 2940, loss = 0.000646089
I0403 03:58:23.692852 16972 solver.cpp:244]     Train net output #0: loss = 0.000646047 (* 1 = 0.000646047 loss)
I0403 03:58:23.884382 16972 sgd_solver.cpp:106] Iteration 2940, lr = 5e-05
I0403 03:58:27.583112 16972 solver.cpp:228] Iteration 2945, loss = 0.000135541
I0403 03:58:27.583210 16972 solver.cpp:244]     Train net output #0: loss = 0.000135499 (* 1 = 0.000135499 loss)
I0403 03:58:27.800918 16972 sgd_solver.cpp:106] Iteration 2945, lr = 5e-05
I0403 03:58:31.475546 16972 solver.cpp:228] Iteration 2950, loss = 0.00191978
I0403 03:58:31.476256 16972 solver.cpp:244]     Train net output #0: loss = 0.00191974 (* 1 = 0.00191974 loss)
I0403 03:58:31.670264 16972 sgd_solver.cpp:106] Iteration 2950, lr = 5e-05
I0403 03:58:35.371084 16972 solver.cpp:228] Iteration 2955, loss = 0.000227056
I0403 03:58:35.371400 16972 solver.cpp:244]     Train net output #0: loss = 0.000227014 (* 1 = 0.000227014 loss)
I0403 03:58:35.577623 16972 sgd_solver.cpp:106] Iteration 2955, lr = 5e-05
I0403 03:58:39.232817 16972 solver.cpp:228] Iteration 2960, loss = 0.0577645
I0403 03:58:39.232905 16972 solver.cpp:244]     Train net output #0: loss = 0.0577644 (* 1 = 0.0577644 loss)
I0403 03:58:39.409487 16972 sgd_solver.cpp:106] Iteration 2960, lr = 5e-05
I0403 03:58:43.164728 16972 solver.cpp:228] Iteration 2965, loss = 0.00015079
I0403 03:58:43.164813 16972 solver.cpp:244]     Train net output #0: loss = 0.00015075 (* 1 = 0.00015075 loss)
I0403 03:58:43.356971 16972 sgd_solver.cpp:106] Iteration 2965, lr = 5e-05
I0403 03:58:47.032656 16972 solver.cpp:228] Iteration 2970, loss = 0.00273923
I0403 03:58:47.032755 16972 solver.cpp:244]     Train net output #0: loss = 0.00273919 (* 1 = 0.00273919 loss)
I0403 03:58:47.239722 16972 sgd_solver.cpp:106] Iteration 2970, lr = 5e-05
I0403 03:58:50.917279 16972 solver.cpp:228] Iteration 2975, loss = 0.00464409
I0403 03:58:50.917372 16972 solver.cpp:244]     Train net output #0: loss = 0.00464405 (* 1 = 0.00464405 loss)
I0403 03:58:51.101253 16972 sgd_solver.cpp:106] Iteration 2975, lr = 5e-05
I0403 03:58:54.812363 16972 solver.cpp:228] Iteration 2980, loss = 0.000176365
I0403 03:58:54.812453 16972 solver.cpp:244]     Train net output #0: loss = 0.000176324 (* 1 = 0.000176324 loss)
I0403 03:58:54.996197 16972 sgd_solver.cpp:106] Iteration 2980, lr = 5e-05
I0403 03:58:58.681879 16972 solver.cpp:228] Iteration 2985, loss = 0.00340608
I0403 03:58:58.681967 16972 solver.cpp:244]     Train net output #0: loss = 0.00340604 (* 1 = 0.00340604 loss)
I0403 03:58:58.878065 16972 sgd_solver.cpp:106] Iteration 2985, lr = 5e-05
I0403 03:59:02.579387 16972 solver.cpp:228] Iteration 2990, loss = 0.000537166
I0403 03:59:02.579474 16972 solver.cpp:244]     Train net output #0: loss = 0.000537125 (* 1 = 0.000537125 loss)
I0403 03:59:02.772059 16972 sgd_solver.cpp:106] Iteration 2990, lr = 5e-05
I0403 03:59:06.441572 16972 solver.cpp:228] Iteration 2995, loss = 0.000156806
I0403 03:59:06.441872 16972 solver.cpp:244]     Train net output #0: loss = 0.000156765 (* 1 = 0.000156765 loss)
I0403 03:59:06.634516 16972 sgd_solver.cpp:106] Iteration 2995, lr = 5e-05
I0403 03:59:10.380897 16972 solver.cpp:228] Iteration 3000, loss = 0.000188347
I0403 03:59:10.380985 16972 solver.cpp:244]     Train net output #0: loss = 0.000188307 (* 1 = 0.000188307 loss)
I0403 03:59:10.574978 16972 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0403 03:59:14.291925 16972 solver.cpp:228] Iteration 3005, loss = 0.028246
I0403 03:59:14.292024 16972 solver.cpp:244]     Train net output #0: loss = 0.028246 (* 1 = 0.028246 loss)
I0403 03:59:14.501830 16972 sgd_solver.cpp:106] Iteration 3005, lr = 5e-05
I0403 03:59:18.121100 16972 solver.cpp:228] Iteration 3010, loss = 0.00113572
I0403 03:59:18.121187 16972 solver.cpp:244]     Train net output #0: loss = 0.00113568 (* 1 = 0.00113568 loss)
I0403 03:59:18.315085 16972 sgd_solver.cpp:106] Iteration 3010, lr = 5e-05
I0403 03:59:21.907668 16972 solver.cpp:228] Iteration 3015, loss = 0.000361493
I0403 03:59:21.907766 16972 solver.cpp:244]     Train net output #0: loss = 0.000361453 (* 1 = 0.000361453 loss)
I0403 03:59:22.128448 16972 sgd_solver.cpp:106] Iteration 3015, lr = 5e-05
I0403 03:59:25.697763 16972 solver.cpp:228] Iteration 3020, loss = 0.000247315
I0403 03:59:25.697863 16972 solver.cpp:244]     Train net output #0: loss = 0.000247275 (* 1 = 0.000247275 loss)
I0403 03:59:25.922675 16972 sgd_solver.cpp:106] Iteration 3020, lr = 5e-05
I0403 03:59:28.224512 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3024.caffemodel
I0403 03:59:31.049556 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3024.solverstate
I0403 03:59:32.839134 16972 solver.cpp:337] Iteration 3024, Testing net (#0)
I0403 04:01:13.906075 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973964
I0403 04:01:13.906386 16972 solver.cpp:404]     Test net output #1: loss = 0.11254 (* 1 = 0.11254 loss)
I0403 04:01:15.288264 16972 solver.cpp:228] Iteration 3025, loss = 0.000622671
I0403 04:01:15.288354 16972 solver.cpp:244]     Train net output #0: loss = 0.000622631 (* 1 = 0.000622631 loss)
I0403 04:01:15.478055 16972 sgd_solver.cpp:106] Iteration 3025, lr = 5e-05
I0403 04:01:19.128520 16972 solver.cpp:228] Iteration 3030, loss = 0.000306068
I0403 04:01:19.128607 16972 solver.cpp:244]     Train net output #0: loss = 0.000306027 (* 1 = 0.000306027 loss)
I0403 04:01:19.338316 16972 sgd_solver.cpp:106] Iteration 3030, lr = 5e-05
I0403 04:01:22.947439 16972 solver.cpp:228] Iteration 3035, loss = 0.000485585
I0403 04:01:22.947540 16972 solver.cpp:244]     Train net output #0: loss = 0.000485545 (* 1 = 0.000485545 loss)
I0403 04:01:23.168195 16972 sgd_solver.cpp:106] Iteration 3035, lr = 5e-05
I0403 04:01:26.883965 16972 solver.cpp:228] Iteration 3040, loss = 0.000200005
I0403 04:01:26.884049 16972 solver.cpp:244]     Train net output #0: loss = 0.000199965 (* 1 = 0.000199965 loss)
I0403 04:01:27.066642 16972 sgd_solver.cpp:106] Iteration 3040, lr = 5e-05
I0403 04:01:30.851969 16972 solver.cpp:228] Iteration 3045, loss = 0.000497075
I0403 04:01:30.852054 16972 solver.cpp:244]     Train net output #0: loss = 0.000497035 (* 1 = 0.000497035 loss)
I0403 04:01:31.036955 16972 sgd_solver.cpp:106] Iteration 3045, lr = 5e-05
I0403 04:01:34.793365 16972 solver.cpp:228] Iteration 3050, loss = 0.0104241
I0403 04:01:34.793452 16972 solver.cpp:244]     Train net output #0: loss = 0.010424 (* 1 = 0.010424 loss)
I0403 04:01:34.974918 16972 sgd_solver.cpp:106] Iteration 3050, lr = 5e-05
I0403 04:01:38.726495 16972 solver.cpp:228] Iteration 3055, loss = 7.02975e-05
I0403 04:01:38.726583 16972 solver.cpp:244]     Train net output #0: loss = 7.02571e-05 (* 1 = 7.02571e-05 loss)
I0403 04:01:38.916287 16972 sgd_solver.cpp:106] Iteration 3055, lr = 5e-05
I0403 04:01:42.562674 16972 solver.cpp:228] Iteration 3060, loss = 7.55207e-05
I0403 04:01:42.562774 16972 solver.cpp:244]     Train net output #0: loss = 7.54802e-05 (* 1 = 7.54802e-05 loss)
I0403 04:01:42.777902 16972 sgd_solver.cpp:106] Iteration 3060, lr = 5e-05
I0403 04:01:46.446408 16972 solver.cpp:228] Iteration 3065, loss = 0.000395741
I0403 04:01:46.446705 16972 solver.cpp:244]     Train net output #0: loss = 0.000395701 (* 1 = 0.000395701 loss)
I0403 04:01:46.642724 16972 sgd_solver.cpp:106] Iteration 3065, lr = 5e-05
I0403 04:01:50.299238 16972 solver.cpp:228] Iteration 3070, loss = 0.00133166
I0403 04:01:50.299340 16972 solver.cpp:244]     Train net output #0: loss = 0.00133162 (* 1 = 0.00133162 loss)
I0403 04:01:50.513658 16972 sgd_solver.cpp:106] Iteration 3070, lr = 5e-05
I0403 04:01:54.180234 16972 solver.cpp:228] Iteration 3075, loss = 0.000376775
I0403 04:01:54.180323 16972 solver.cpp:244]     Train net output #0: loss = 0.000376735 (* 1 = 0.000376735 loss)
I0403 04:01:54.375633 16972 sgd_solver.cpp:106] Iteration 3075, lr = 5e-05
I0403 04:01:58.046416 16972 solver.cpp:228] Iteration 3080, loss = 0.00413677
I0403 04:01:58.046502 16972 solver.cpp:244]     Train net output #0: loss = 0.00413673 (* 1 = 0.00413673 loss)
I0403 04:01:58.244551 16972 sgd_solver.cpp:106] Iteration 3080, lr = 5e-05
I0403 04:02:01.929770 16972 solver.cpp:228] Iteration 3085, loss = 0.00108187
I0403 04:02:01.929859 16972 solver.cpp:244]     Train net output #0: loss = 0.00108183 (* 1 = 0.00108183 loss)
I0403 04:02:02.128221 16972 sgd_solver.cpp:106] Iteration 3085, lr = 5e-05
I0403 04:02:05.840891 16972 solver.cpp:228] Iteration 3090, loss = 0.000735357
I0403 04:02:05.840980 16972 solver.cpp:244]     Train net output #0: loss = 0.000735316 (* 1 = 0.000735316 loss)
I0403 04:02:06.034831 16972 sgd_solver.cpp:106] Iteration 3090, lr = 5e-05
I0403 04:02:09.715025 16972 solver.cpp:228] Iteration 3095, loss = 0.000148728
I0403 04:02:09.715114 16972 solver.cpp:244]     Train net output #0: loss = 0.000148688 (* 1 = 0.000148688 loss)
I0403 04:02:09.901813 16972 sgd_solver.cpp:106] Iteration 3095, lr = 5e-05
I0403 04:02:13.578591 16972 solver.cpp:228] Iteration 3100, loss = 0.00103063
I0403 04:02:13.578693 16972 solver.cpp:244]     Train net output #0: loss = 0.00103059 (* 1 = 0.00103059 loss)
I0403 04:02:13.790141 16972 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0403 04:02:17.461485 16972 solver.cpp:228] Iteration 3105, loss = 0.000455252
I0403 04:02:17.461834 16972 solver.cpp:244]     Train net output #0: loss = 0.000455213 (* 1 = 0.000455213 loss)
I0403 04:02:17.714156 16972 sgd_solver.cpp:106] Iteration 3105, lr = 5e-05
I0403 04:02:21.380781 16972 solver.cpp:228] Iteration 3110, loss = 0.00175734
I0403 04:02:21.380870 16972 solver.cpp:244]     Train net output #0: loss = 0.00175731 (* 1 = 0.00175731 loss)
I0403 04:02:21.563829 16972 sgd_solver.cpp:106] Iteration 3110, lr = 5e-05
I0403 04:02:25.267979 16972 solver.cpp:228] Iteration 3115, loss = 0.00152098
I0403 04:02:25.268069 16972 solver.cpp:244]     Train net output #0: loss = 0.00152094 (* 1 = 0.00152094 loss)
I0403 04:02:25.453510 16972 sgd_solver.cpp:106] Iteration 3115, lr = 5e-05
I0403 04:02:29.172116 16972 solver.cpp:228] Iteration 3120, loss = 0.000265377
I0403 04:02:29.172197 16972 solver.cpp:244]     Train net output #0: loss = 0.000265339 (* 1 = 0.000265339 loss)
I0403 04:02:29.366118 16972 sgd_solver.cpp:106] Iteration 3120, lr = 5e-05
I0403 04:02:33.193691 16972 solver.cpp:228] Iteration 3125, loss = 0.000101953
I0403 04:02:33.193776 16972 solver.cpp:244]     Train net output #0: loss = 0.000101914 (* 1 = 0.000101914 loss)
I0403 04:02:33.375069 16972 sgd_solver.cpp:106] Iteration 3125, lr = 5e-05
I0403 04:02:37.329715 16972 solver.cpp:228] Iteration 3130, loss = 0.00200373
I0403 04:02:37.329804 16972 solver.cpp:244]     Train net output #0: loss = 0.0020037 (* 1 = 0.0020037 loss)
I0403 04:02:37.522088 16972 sgd_solver.cpp:106] Iteration 3130, lr = 5e-05
I0403 04:02:38.286070 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3132.caffemodel
I0403 04:02:41.101750 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3132.solverstate
I0403 04:02:42.980700 16972 solver.cpp:337] Iteration 3132, Testing net (#0)
I0403 04:04:24.047664 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973895
I0403 04:04:24.047966 16972 solver.cpp:404]     Test net output #1: loss = 0.112606 (* 1 = 0.112606 loss)
I0403 04:04:27.022910 16972 solver.cpp:228] Iteration 3135, loss = 0.00116465
I0403 04:04:27.022994 16972 solver.cpp:244]     Train net output #0: loss = 0.00116461 (* 1 = 0.00116461 loss)
I0403 04:04:27.216469 16972 sgd_solver.cpp:106] Iteration 3135, lr = 5e-05
I0403 04:04:30.962920 16972 solver.cpp:228] Iteration 3140, loss = 0.000381627
I0403 04:04:30.963016 16972 solver.cpp:244]     Train net output #0: loss = 0.000381589 (* 1 = 0.000381589 loss)
I0403 04:04:31.184418 16972 sgd_solver.cpp:106] Iteration 3140, lr = 5e-05
I0403 04:04:34.803450 16972 solver.cpp:228] Iteration 3145, loss = 0.000176723
I0403 04:04:34.803539 16972 solver.cpp:244]     Train net output #0: loss = 0.000176685 (* 1 = 0.000176685 loss)
I0403 04:04:35.003525 16972 sgd_solver.cpp:106] Iteration 3145, lr = 5e-05
I0403 04:04:38.638281 16972 solver.cpp:228] Iteration 3150, loss = 0.00120284
I0403 04:04:38.638371 16972 solver.cpp:244]     Train net output #0: loss = 0.0012028 (* 1 = 0.0012028 loss)
I0403 04:04:38.832957 16972 sgd_solver.cpp:106] Iteration 3150, lr = 5e-05
I0403 04:04:42.465406 16972 solver.cpp:228] Iteration 3155, loss = 0.00609583
I0403 04:04:42.465495 16972 solver.cpp:244]     Train net output #0: loss = 0.00609579 (* 1 = 0.00609579 loss)
I0403 04:04:42.655077 16972 sgd_solver.cpp:106] Iteration 3155, lr = 5e-05
I0403 04:04:46.356457 16972 solver.cpp:228] Iteration 3160, loss = 0.000346188
I0403 04:04:46.356544 16972 solver.cpp:244]     Train net output #0: loss = 0.00034615 (* 1 = 0.00034615 loss)
I0403 04:04:46.537518 16972 sgd_solver.cpp:106] Iteration 3160, lr = 5e-05
I0403 04:04:50.238066 16972 solver.cpp:228] Iteration 3165, loss = 0.000436473
I0403 04:04:50.238154 16972 solver.cpp:244]     Train net output #0: loss = 0.000436435 (* 1 = 0.000436435 loss)
I0403 04:04:50.433152 16972 sgd_solver.cpp:106] Iteration 3165, lr = 5e-05
I0403 04:04:54.213915 16972 solver.cpp:228] Iteration 3170, loss = 0.000154265
I0403 04:04:54.214234 16972 solver.cpp:244]     Train net output #0: loss = 0.000154227 (* 1 = 0.000154227 loss)
I0403 04:04:54.379112 16972 sgd_solver.cpp:106] Iteration 3170, lr = 5e-05
I0403 04:04:58.170218 16972 solver.cpp:228] Iteration 3175, loss = 0.00305996
I0403 04:04:58.170306 16972 solver.cpp:244]     Train net output #0: loss = 0.00305993 (* 1 = 0.00305993 loss)
I0403 04:04:58.354200 16972 sgd_solver.cpp:106] Iteration 3175, lr = 5e-05
I0403 04:05:02.100566 16972 solver.cpp:228] Iteration 3180, loss = 0.000151164
I0403 04:05:02.100651 16972 solver.cpp:244]     Train net output #0: loss = 0.000151127 (* 1 = 0.000151127 loss)
I0403 04:05:02.290849 16972 sgd_solver.cpp:106] Iteration 3180, lr = 5e-05
I0403 04:05:05.954697 16972 solver.cpp:228] Iteration 3185, loss = 0.000407505
I0403 04:05:05.954785 16972 solver.cpp:244]     Train net output #0: loss = 0.000407467 (* 1 = 0.000407467 loss)
I0403 04:05:06.131181 16972 sgd_solver.cpp:106] Iteration 3185, lr = 5e-05
I0403 04:05:09.909289 16972 solver.cpp:228] Iteration 3190, loss = 0.0161977
I0403 04:05:09.909378 16972 solver.cpp:244]     Train net output #0: loss = 0.0161977 (* 1 = 0.0161977 loss)
I0403 04:05:10.101172 16972 sgd_solver.cpp:106] Iteration 3190, lr = 5e-05
I0403 04:05:13.847803 16972 solver.cpp:228] Iteration 3195, loss = 0.000664643
I0403 04:05:13.847892 16972 solver.cpp:244]     Train net output #0: loss = 0.000664605 (* 1 = 0.000664605 loss)
I0403 04:05:14.042816 16972 sgd_solver.cpp:106] Iteration 3195, lr = 5e-05
I0403 04:05:17.787544 16972 solver.cpp:228] Iteration 3200, loss = 4.96969e-05
I0403 04:05:17.787631 16972 solver.cpp:244]     Train net output #0: loss = 4.96592e-05 (* 1 = 4.96592e-05 loss)
I0403 04:05:17.964787 16972 sgd_solver.cpp:106] Iteration 3200, lr = 5e-05
I0403 04:05:21.771114 16972 solver.cpp:228] Iteration 3205, loss = 0.000496328
I0403 04:05:21.771212 16972 solver.cpp:244]     Train net output #0: loss = 0.00049629 (* 1 = 0.00049629 loss)
I0403 04:05:21.977988 16972 sgd_solver.cpp:106] Iteration 3205, lr = 5e-05
I0403 04:05:25.631839 16972 solver.cpp:228] Iteration 3210, loss = 0.00427441
I0403 04:05:25.632143 16972 solver.cpp:244]     Train net output #0: loss = 0.00427437 (* 1 = 0.00427437 loss)
I0403 04:05:25.816329 16972 sgd_solver.cpp:106] Iteration 3210, lr = 5e-05
I0403 04:05:29.540105 16972 solver.cpp:228] Iteration 3215, loss = 0.000965303
I0403 04:05:29.540194 16972 solver.cpp:244]     Train net output #0: loss = 0.000965266 (* 1 = 0.000965266 loss)
I0403 04:05:29.733085 16972 sgd_solver.cpp:106] Iteration 3215, lr = 5e-05
I0403 04:05:33.404093 16972 solver.cpp:228] Iteration 3220, loss = 0.00591143
I0403 04:05:33.404182 16972 solver.cpp:244]     Train net output #0: loss = 0.00591139 (* 1 = 0.00591139 loss)
I0403 04:05:33.601030 16972 sgd_solver.cpp:106] Iteration 3220, lr = 5e-05
I0403 04:05:37.333811 16972 solver.cpp:228] Iteration 3225, loss = 0.000146707
I0403 04:05:37.333911 16972 solver.cpp:244]     Train net output #0: loss = 0.00014667 (* 1 = 0.00014667 loss)
I0403 04:05:37.577101 16972 sgd_solver.cpp:106] Iteration 3225, lr = 5e-05
I0403 04:05:41.179285 16972 solver.cpp:228] Iteration 3230, loss = 0.000166532
I0403 04:05:41.179371 16972 solver.cpp:244]     Train net output #0: loss = 0.000166496 (* 1 = 0.000166496 loss)
I0403 04:05:41.366905 16972 sgd_solver.cpp:106] Iteration 3230, lr = 5e-05
I0403 04:05:45.093873 16972 solver.cpp:228] Iteration 3235, loss = 0.000207174
I0403 04:05:45.094707 16972 solver.cpp:244]     Train net output #0: loss = 0.000207137 (* 1 = 0.000207137 loss)
I0403 04:05:45.300940 16972 sgd_solver.cpp:106] Iteration 3235, lr = 5e-05
I0403 04:05:48.348211 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3240.caffemodel
I0403 04:05:51.193341 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3240.solverstate
I0403 04:05:53.056900 16972 solver.cpp:337] Iteration 3240, Testing net (#0)
I0403 04:07:34.120206 16972 solver.cpp:404]     Test net output #0: accuracy = 0.973756
I0403 04:07:34.120527 16972 solver.cpp:404]     Test net output #1: loss = 0.112999 (* 1 = 0.112999 loss)
I0403 04:07:34.681450 16972 solver.cpp:228] Iteration 3240, loss = 0.000843296
I0403 04:07:34.681535 16972 solver.cpp:244]     Train net output #0: loss = 0.00084326 (* 1 = 0.00084326 loss)
I0403 04:07:34.849684 16972 sgd_solver.cpp:106] Iteration 3240, lr = 5e-05
I0403 04:07:38.581666 16972 solver.cpp:228] Iteration 3245, loss = 0.000298242
I0403 04:07:38.581764 16972 solver.cpp:244]     Train net output #0: loss = 0.000298206 (* 1 = 0.000298206 loss)
I0403 04:07:38.798564 16972 sgd_solver.cpp:106] Iteration 3245, lr = 5e-05
I0403 04:07:42.418264 16972 solver.cpp:228] Iteration 3250, loss = 4.27989e-05
I0403 04:07:42.418367 16972 solver.cpp:244]     Train net output #0: loss = 4.27627e-05 (* 1 = 4.27627e-05 loss)
I0403 04:07:42.635862 16972 sgd_solver.cpp:106] Iteration 3250, lr = 5e-06
I0403 04:07:42.636176 16972 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3251.caffemodel
I0403 04:07:45.419106 16972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_finetune/snapshots__iter_3251.solverstate
I0403 04:07:47.314334 16972 solver.cpp:322] Optimization Done.
I0403 04:07:47.425792 16972 caffe.cpp:222] Optimization Done.
